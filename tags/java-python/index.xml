<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Java Python on Chase the Devil</title>
    <link>http://chasethedevil.github.io/tags/java-python/</link>
    <description>Recent content in Java Python on Chase the Devil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Apr 2013 14:24:00 +0000</lastBuildDate>
    <atom:link href="http://chasethedevil.github.io/tags/java-python/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>From Double Precision Normal Density to Double Precision Cumulative Normal Distribution</title>
      <link>http://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</link>
      <pubDate>Tue, 02 Apr 2013 14:24:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</guid>
      <description>&lt;p&gt;Marsaglia in &lt;a href=&#34;http://www.jstatsoft.org/v11/a05/paper&#34;&gt;his paper on Normal Distribution&lt;/a&gt; made the same mistake I initially did while trying to verify &lt;a href=&#34;http://chasethedevil.blogspot.fr/2013/03/cracking-double-precision-gaussian.html&#34;&gt;the accuracy of the normal density&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;In his table of values comparing the true value computed by Maple for some values of x to the values computed by Sun or Ooura erfc, he actually does not really use the same input for the comparison. One example is the last number: 16.6. 16.6 does not have an exact representation in double precision, even though it is displayed as 16.6 because of the truncation at machine epsilon precision. Using Python mpmath, one can see that:&lt;br /&gt;&lt;br /&gt;&lt;span style=&#34;font-size: x-small;&#34;&gt;&lt;span style=&#34;font-family: &amp;quot;Courier New&amp;quot;,Courier,monospace;&#34;&gt;&amp;gt;&amp;gt;&amp;gt; mpf(-16.6)&lt;br /&gt;mpf(&amp;lsquo;-16.6000000000000014210854715202004&amp;rsquo;)&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;This is the more accurate representation if one goes beyond double precision (here 30 digits). And the value of the cumulative normal distribution is:&lt;br /&gt;&lt;span style=&#34;font-family: &amp;quot;Courier New&amp;quot;,Courier,monospace;&#34;&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style=&#34;font-size: x-small;&#34;&gt;&lt;span style=&#34;font-family: &amp;quot;Courier New&amp;quot;,Courier,monospace;&#34;&gt;&amp;gt;&amp;gt;&amp;gt; ncdf(-16.6)&lt;br /&gt;mpf(&amp;lsquo;3.4845465199503256054808152068743e-62&amp;rsquo;)&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;It is different from:&lt;br /&gt;&lt;br /&gt;&lt;span style=&#34;font-size: x-small;&#34;&gt;&lt;span style=&#34;font-family: &amp;quot;Courier New&amp;quot;,Courier,monospace;&#34;&gt;&amp;gt;&amp;gt;&amp;gt; ncdf(mpf(&amp;ldquo;-16.6&amp;rdquo;))&lt;br /&gt;mpf(&amp;lsquo;3.48454651995040810217553910503186e-62&amp;rsquo;)&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;where in this case it is really evaluated around -16.6 (up to 30 digits precision). Marsaglia gives this second number as reference. But all the other algorithms will actually take as input the first input. It is more meaningful to compare results using the exact same input. Using human readable but computer truncated numbers is not the best.  The cumulative normal distribution will often be computed using some output of some calculation where one does not have an exact human readable input.&lt;br /&gt;&lt;br /&gt;The standard code for Ooura and Schonfelder (as well as Marsaglia) algorithms for the cumulative normal distribution don&amp;rsquo;t use Cody&amp;rsquo;s trick to evaluate the exp(-x*x). This function appears in all those implementations because it is part of the dominant term in the usual expansions. Out of curiosity, I replaced this part with Cody trick. For Ooura I also made minor changes to make it work directly on the CND instead of going through the error function erfc indirection. Here are the results without the Cody trick (except for Cody):&lt;br /&gt;&lt;div class=&#34;separator&#34; style=&#34;clear: both; text-align: center;&#34;&gt;&lt;a href=&#34;http://4.bp.blogspot.com/-mNamXn3QlGQ/UVrMEkkqrWI/AAAAAAAAGUU/1hihN6pqiC4/s1600/Screenshot+from+2013-04-02+14:15:51.png&#34; imageanchor=&#34;1&#34; style=&#34;margin-left: 1em; margin-right: 1em;&#34;&gt;&lt;img border=&#34;0&#34; height=&#34;307&#34; src=&#34;http://4.bp.blogspot.com/-mNamXn3QlGQ/UVrMEkkqrWI/AAAAAAAAGUU/1hihN6pqiC4/s640/Screenshot+from+2013-04-02+14:15:51.png&#34; width=&#34;640&#34; /&gt;&lt;/a&gt;&lt;/div&gt;and with it:&lt;br /&gt;&lt;br /&gt;&lt;div class=&#34;separator&#34; style=&#34;clear: both; text-align: center;&#34;&gt;&lt;a href=&#34;http://4.bp.blogspot.com/-bFq5HVfCCOs/UVrMEjJbuJI/AAAAAAAAGUQ/uyHKMbEsmco/s1600/Screenshot+from+2013-04-02+14:14:02.png&#34; imageanchor=&#34;1&#34; style=&#34;margin-left: 1em; margin-right: 1em;&#34;&gt;&lt;img border=&#34;0&#34; height=&#34;307&#34; src=&#34;http://4.bp.blogspot.com/-bFq5HVfCCOs/UVrMEjJbuJI/AAAAAAAAGUQ/uyHKMbEsmco/s640/Screenshot+from+2013-04-02+14:14:02.png&#34; width=&#34;640&#34; /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;All 3 algorithms are now of similiar accuracy (note the difference of scale compared to the previous graph), with Schonfelder being a bit worse, especially for x &amp;gt;= -20. If one uses only easily representable numbers (for example -37, -36,75, -36,5, &amp;hellip;) in double precision then, of course, Cody trick importance won&amp;rsquo;t be visible and here is how the 3 algorithms would fare with or without Cody trick:&lt;br /&gt;&lt;br /&gt;&lt;div class=&#34;separator&#34; style=&#34;clear: both; text-align: center;&#34;&gt;&lt;a href=&#34;http://1.bp.blogspot.com/-zOHn3Lp96zY/UVrM8iOtgaI/AAAAAAAAGUg/7GdvJ534F60/s1600/Screenshot+from+2013-04-02+11:24:08.png&#34; imageanchor=&#34;1&#34; style=&#34;margin-left: 1em; margin-right: 1em;&#34;&gt;&lt;img border=&#34;0&#34; height=&#34;301&#34; src=&#34;http://1.bp.blogspot.com/-zOHn3Lp96zY/UVrM8iOtgaI/AAAAAAAAGUg/7GdvJ534F60/s400/Screenshot+from+2013-04-02+11:24:08.png&#34; width=&#34;400&#34; /&gt;&lt;/a&gt;&lt;/div&gt;Schonfelder looks now worse than it actually is compared to Cody and Ooura.&lt;br /&gt;&lt;br /&gt;To conclude, if someone claims that a cumulative normal distribution is up to double precision accuracy and it does not use any tricks to compute exp(-x*x), then beware, it probably is quite a bit less than double precision.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trying Google AppEngine</title>
      <link>http://chasethedevil.github.io/post/trying-google-appengine/</link>
      <pubDate>Tue, 17 Jun 2008 19:26:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/trying-google-appengine/</guid>
      <description>&lt;p&gt;I finally took some time to try &lt;a href=&#34;http://code.google.com/appengine/&#34;&gt;Google AppEngine&lt;/a&gt;. It used to be easy to find free PHP hosting around 2000. It became a rarity. So writing small experiments for free on the web was difficult. Experiments are back thanks to Google with their AppEngine. Many aspects of it are quite interesting and show where they focus.&lt;br /&gt;&lt;br /&gt;First it is all Python. It makes sense as I believe Guido v Rossum, Python creator, works for Google. Some people believe in a future Java application hosting. I don&amp;rsquo;t see any reason why it could not become a reality. Making something like AppEngine is a big task, changing implementation language is not. In the meantime, it is not an excuse not to try it, as the Python standard library is fairly rich and Google provides additional libraries on top of it.&lt;br /&gt;&lt;br /&gt;AppEngine offers the basic bricks for building web apps:&lt;br /&gt;&lt;ul&gt;&lt;li&gt;Persistence: they rolled out their own persistence layer. Is it because it is stored in BigTable? It is quite basic (no join), maybe again for the same reason. Still it is enough to write prototypes or do fun stuff.&lt;/li&gt;&lt;li&gt;View: one can use Django templates. They are not perfect but better done than what we have in the java world for templating.&lt;/li&gt;&lt;li&gt;Authentication: Google provide their authentication system transparently. It is amazingly simple to setup authenticated sites/pages.&lt;/li&gt;&lt;li&gt;URL Fetch: points toward service oriented architecture. Without it, making services and calling them would not be possible.&lt;/li&gt;&lt;li&gt;Other useful stuff like Mail, cache.&lt;br /&gt;&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;With such a list of libraries, one can easily imagine the server side of future apps for Android running on AppEngine.&lt;br /&gt;&lt;br /&gt;The way code updates are pushed to the google servers is a bit reminiscent of Java web application deployment. However it is done with much finer granularity (file).&lt;br /&gt;&lt;br /&gt;Overall I am happy with AppEngine. Yes it is similar to old PHP hosting, but  it adds a lot of value by bringing few easy to use libraries, and natural integration with Google infrastructure. Compared to a PHP hosting, I think the biggest improvement is the database (dev use and admin use). For the dev it is integrated to the code. For the admin, it can be done transparently on the web. The most interesting is that it&amp;rsquo;s FREE.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>