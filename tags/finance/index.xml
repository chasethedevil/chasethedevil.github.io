<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Finance on Chase the Devil</title>
    <link>http://chasethedevil.github.io/tags/finance/</link>
    <description>Recent content in Finance on Chase the Devil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</copyright>
    <lastBuildDate>Tue, 30 Apr 2013 17:05:00 +0000</lastBuildDate>
    <atom:link href="/tags/finance/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Upper Bounds in American Monte-Carlo</title>
      <link>http://chasethedevil.github.io/post/upper-bounds-in-american-monte-carlo/</link>
      <pubDate>Tue, 30 Apr 2013 17:05:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/upper-bounds-in-american-monte-carlo/</guid>
      <description>Glasserman and Yu (GY) give a relatively simple algorithm to compute lower and upper bounds of a the price of a Bermudan Option through Monte-Carlo.
I always thought it was very computer intensive to produce an upper bound, and that the standard Longstaff Schwartz algorithm was quite precise already. GY algorithm is not much slower than the Longstaff-Schwartz algorithm, but what&amp;rsquo;s a bit tricky is the choice of basis functions: they have to be Martingales. <a href="/post/upper-bounds-in-american-monte-carlo/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Quasi Monte-Carlo &amp; Longstaff-Schwartz American Option price</title>
      <link>http://chasethedevil.github.io/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/</link>
      <pubDate>Mon, 22 Apr 2013 18:00:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/</guid>
      <description>In the book Monte Carlo Methods in Financial Engineering, Glasserman explains that if one reuses the paths used in the optimization procedure for the parameters of the exercise boundary (in this case the result of the regression in Longstaff-Schwartz method) to compute the Monte-Carlo mean value, we will introduce a bias: the estimate will be biased high because it will include knowledge about future paths.
However Longstaff and Schwartz seem to just reuse the paths in their paper, and Glasserman himself, when presenting Longstaff-Schwartz method later in the book just use the same paths for the regression and to compute the Monte-Carlo mean value. <a href="/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>A Fast Exponential Function in Java</title>
      <link>http://chasethedevil.github.io/post/a-fast-exponential-function-in-java/</link>
      <pubDate>Fri, 19 Apr 2013 16:48:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/a-fast-exponential-function-in-java/</guid>
      <description>In finance, because one often dicretize the log process instead of the direct process for Monte-Carlo simulation, the Math.exp function can be called a lot (millions of times for a simulation) and can be a bottleneck. I have noticed that the simpler Euler discretization was for local volatility Monte-Carlo around 30% faster, because it avoids the use of Math.exp.
Can we improve the speed of exp over the JDK one? At first it would seem that the JDK would just call either the processor exp using an intrinsic function call and that should be difficult to beat. <a href="/post/a-fast-exponential-function-in-java/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>From Double Precision Normal Density to Double Precision Cumulative Normal Distribution</title>
      <link>http://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</link>
      <pubDate>Tue, 02 Apr 2013 14:24:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</guid>
      <description>Marsaglia in his paper on Normal Distribution made the same mistake I initially did while trying to verify the accuracy of the normal density.
In his table of values comparing the true value computed by Maple for some values of x to the values computed by Sun or Ooura erfc, he actually does not really use the same input for the comparison. One example is the last number: 16.6. 16.6 does not have an exact representation in double precision, even though it is displayed as 16. <a href="/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Cracking the Double Precision Gaussian Puzzle</title>
      <link>http://chasethedevil.github.io/post/cracking-the-double-precision-gaussian-puzzle/</link>
      <pubDate>Fri, 22 Mar 2013 12:20:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/cracking-the-double-precision-gaussian-puzzle/</guid>
      <description>In my previous post, I stated that some library (SPECFUN by W.D. Cody) computes $$e^{-\frac{x^2}{2}}$$ the following way:
xsq = fint(x * 1.6) / 1.6;
del = (x - xsq) * (x + xsq);
result = exp(-xsq * xsq * 0.5) * exp(-del &amp;nbsp;0.5);
where fint(z) computes the floor of z.
1. Why 1.6?
An integer divided by 1.6 will be an exact representation of the corresponding number in double: 1. <a href="/post/cracking-the-double-precision-gaussian-puzzle/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Local Volatility Delta &amp; Dynamic</title>
      <link>http://chasethedevil.github.io/post/local-volatility-delta--dynamic/</link>
      <pubDate>Thu, 29 Nov 2012 12:30:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/local-volatility-delta--dynamic/</guid>
      <description>This will be a very technical post, I am not sure that it will be very understandable by people not familiar with the implied volatility surface.

Something one notices when computing an option price under local volatility using a PDE solver, is how different is the Delta from the standard Black-Scholes Delta, even though the price will be very close for a Vanilla option. In deed, the Finite difference grid will have a different local volatility at each point and the Delta will take into account a change in local volatility as well. <a href="/post/local-volatility-delta--dynamic/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>GPU computing in Finance</title>
      <link>http://chasethedevil.github.io/post/gpu-computing-in-finance/</link>
      <pubDate>Mon, 15 Oct 2012 16:14:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/gpu-computing-in-finance/</guid>
      <description>Very interesting presentation from Murex about their GPU computing. Some points were:
- GPU demand for mostly exotics pricing &amp;amp; greeks
- Local vol main model for EQD exotics. Local vol calibrated via PDE approach.
- Markov functional model becoming main model for IRD.
- Use of local regression instead of Longstaff Schwartz (or worse CVA like sim of sim).
- philox RNG from DE Shaw. But the presenter does not seem to know RNGs very well (recommended Brownian Bridge for Mersenne Twister! <a href="/post/gpu-computing-in-finance/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Binary Voting</title>
      <link>http://chasethedevil.github.io/post/binary-voting/</link>
      <pubDate>Fri, 07 Sep 2012 17:21:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/binary-voting/</guid>
      <description>How many reports have you had to fill up with a number of stars to choose? How much useless time is spent on figuring the this number just because it is always very ambiguous?
Some blogger wrote an interesting entry on Why I Hate Five Stars Reviews. Basically he advocates binary voting instead via like/dislike. Maybe a ternary system via like/dislike/don&amp;rsquo;t care would be ok too.
One coworker used to advocate the same for a similar reason: people reading those reports only pay attention to the extremes: the 5 stars or the 0 stars. <a href="/post/binary-voting/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Adaptive Quadrature for Pricing European Option with Heston</title>
      <link>http://chasethedevil.github.io/post/adaptive-quadrature-for-pricing-european-option-with-heston/</link>
      <pubDate>Mon, 25 Jun 2012 12:50:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/adaptive-quadrature-for-pricing-european-option-with-heston/</guid>
      <description>The Quantlib code to evaluate the Heston integral for European options is quite nice. It proposes Kahl &amp;amp; Jaeckel method as well as Gatheral method for the complex logarithm. It also contains expansions where it matters so that the resulting code is very robust. One minor issue is that it does not integrate both parts at the same time, and also does not propose Attari method for the Heston integral that is supposed to be more stable. <a href="/post/adaptive-quadrature-for-pricing-european-option-with-heston/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
    <item>
      <title>Why primitive arrays matter in Java</title>
      <link>http://chasethedevil.github.io/post/why-primitive-arrays-matter-in-java/</link>
      <pubDate>Wed, 29 Feb 2012 10:01:00 +0000</pubDate>
      
      <guid>http://chasethedevil.github.io/post/why-primitive-arrays-matter-in-java/</guid>
      <description>In the past, I have seen that one could greatly improve performance of some Monte-Carlo simulation by using as much as possible double[][] instead of arrays of objects.
It was interesting to read this blog post explaining why that happens: it is all about memory access. <a href="/post/why-primitive-arrays-matter-in-java/">Read More…</a> <p>Copyright 2006-2016 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</p></description>
    </item>
    
  </channel>
</rss>
