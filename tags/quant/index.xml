<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>quant on Chase the Devil</title>
    <link>https://chasethedevil.github.io/tags/quant/</link>
    <description>Recent content in quant on Chase the Devil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright 2006-2018 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</copyright>
    <lastBuildDate>Sun, 29 Sep 2024 12:56:42 +0100</lastBuildDate>
    <atom:link href="https://chasethedevil.github.io/tags/quant/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Monotonicity of the Black-Scholes Option Prices in Practice</title>
      <link>https://chasethedevil.github.io/post/vol_monotonicity_in_practice/</link>
      <pubDate>Sun, 29 Sep 2024 12:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/vol_monotonicity_in_practice/</guid>
      <description>It is well known that vanilla option prices must increase when we increase the implied volatility. Recently, a post on the Wilmott forums wondered about the true accuracy of Peter Jaeckel implied volatility solver, whether it was truely IEEE 754 compliant. In fact, the author noticed some inaccuracy in the option price itself. Unfortunately I can not reply to the forum, its login process does not seem to be working anymore.</description>
    </item>
    <item>
      <title>Copilot vs ChatGPT on the Optimal Finite Difference Step-Size</title>
      <link>https://chasethedevil.github.io/post/copilot_vs_chatgpt_optimal_step_size/</link>
      <pubDate>Thu, 25 Jul 2024 12:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/copilot_vs_chatgpt_optimal_step_size/</guid>
      <description>When computing the derivative of a function by finite difference, which step size is optimal? The answer depends on the kind of difference (forward, backward or central), and the degree of the derivative (first or second typically for finance).&#xA;For the first derivative, the result is very quick to find (it&amp;rsquo;s on wikipedia). For the second derivative, it&amp;rsquo;s more challenging. The Lecture Notes of Karen Kopecky provide an answer. I wonder if Copilot or ChatGPT would find a good solution to the question:</description>
    </item>
    <item>
      <title>News on the COS Method Truncation</title>
      <link>https://chasethedevil.github.io/post/cos_method_truncation/</link>
      <pubDate>Mon, 13 May 2024 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/cos_method_truncation/</guid>
      <description>The COS method is a fast way to price vanilla European options under stochastic volatility models with a known characteristic function. There are alternatives, explored in previous blog posts. A main advantage of the COS method is its simplicity. But this comes at the expense of finding the correct values for the truncation level and the (associated) number of terms.&#xA;A related issue of the COS method, or its more fancy wavelet cousin the SWIFT method, is to require a huge (&amp;gt;65K) number of points to reach a reasonable accuracy for some somewhat extreme choices of Heston parameters.</description>
    </item>
    <item>
      <title>Variance Swap Term-Structure under Schobel-Zhu</title>
      <link>https://chasethedevil.github.io/post/unrealistic_variance_swaps_under_schobel_zhu/</link>
      <pubDate>Tue, 26 Mar 2024 12:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/unrealistic_variance_swaps_under_schobel_zhu/</guid>
      <description>I never paid too much attention to it, but the term-structure of variance swaps is not always realistic under the Schobel-Zhu stochastic volatility model.&#xA;This is not fundamentally the case with the Heston model, the Heston model is merely extremely limited to produce either a flat shape or a downward sloping exponential shape.&#xA;Under the Schobel-Zhu model, the price of a newly issued variance swap reads $$&#x9;V(T) = \left[\left(v_0-\theta\right)^2-\frac{\eta^2}{2\kappa}\right]\frac{1-e^{-2\kappa T}}{2\kappa T}+2\theta(v_0-\theta)\frac{1-e^{-\kappa T}}{\kappa T}+\theta^2+\frac{\eta^2}{2\kappa},,$$ where \( \eta \) is the vol of vol.</description>
    </item>
    <item>
      <title>New Basket Expansions and Cash Dividends</title>
      <link>https://chasethedevil.github.io/post/new_basket_approximation_and_cash_dividends/</link>
      <pubDate>Sat, 23 Mar 2024 09:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/new_basket_approximation_and_cash_dividends/</guid>
      <description>In the previous post, I presented a new stochastic expansion for the prices of Asian options. The stochastic expansion is generalized to basket options in the paper, and can thus be applied on the problem of pricing vanilla options with cash dividends.&#xA;I have updated the paper with comparisons to more direct stochastic expansions for pricing vanilla options with cash dividends, such as the one of Etor√© and Gobet, and my own refinement on it.</description>
    </item>
    <item>
      <title>New Approximations for the Prices of Asian and basket Options</title>
      <link>https://chasethedevil.github.io/post/new_asian_approximation/</link>
      <pubDate>Sun, 17 Mar 2024 12:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/new_asian_approximation/</guid>
      <description>Many years ago, I had applied the stochastic expansion technique of Etore and Gobet to a refined proxy, in order to produce more accurate prices for vanilla options with cash dividends under the Black-Scholes model with deterministic jumps at the dividend dates. Any approximation for vanilla basket option prices can also be applied on this problem, and the sophisticated Curran geometric conditioning was found to be particularly competitive in The Pricing of Vanilla Options with Cash Dividends as a Classic Vanilla Basket Option Problem.</description>
    </item>
    <item>
      <title>Easy Mistake With the Log-Euler Discretization On Black-Scholes</title>
      <link>https://chasethedevil.github.io/post/logeuler_not_exact/</link>
      <pubDate>Mon, 11 Mar 2024 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/logeuler_not_exact/</guid>
      <description>In the Black-Scholes model with a term-structure of volatilities, the Log-Euler Monte-Carlo scheme is not necessarily exact.&#xA;This happens if you have two assets \(S_1\) and \(S_2\), with two different time varying volatilities \(\sigma_1(t), \sigma_2(t) \). The covariance from the Ito isometry from \(t=t_0\) to \(t=t_1\) reads $$ \int_{t_0}^{t_1} \sigma_1(s)\sigma_2(s) \rho ds, $$ while a naive log-Euler discretization may use $$ \rho \bar\sigma_1(t_0) \bar\sigma_2(t_0) (t_1-t_0). $$ In practice, the \( \bar\sigma_i(t_0) \) are calibrated such that the vanilla option prices are exact, meaning $$ \bar{\sigma}_i^2(t_0)(t_1-t_0) = \int_{t_0}^{t_1} \sigma_i^2(s) ds.</description>
    </item>
    <item>
      <title>Roughness of Pure Jumps</title>
      <link>https://chasethedevil.github.io/post/roughness_of_jumps/</link>
      <pubDate>Mon, 18 Dec 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/roughness_of_jumps/</guid>
      <description>In my previous blog post, I looked at the roughness of the SVCJ stochastic volatility model with jumps (in the volatility). In this model, the jumps occur randomly, but at discrete times. And with typical parameters used in the litterature, the jumps are not so frequent. It is thus more interesting to look at the roughness of pure jump processes, such as the CGMY process.&#xA;The CGMY process is more challenging to simulate.</description>
    </item>
    <item>
      <title>Roughness of Stochastic Volatility with Jumps</title>
      <link>https://chasethedevil.github.io/post/roughness_of_stochastic_volatility/</link>
      <pubDate>Thu, 07 Dec 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/roughness_of_stochastic_volatility/</guid>
      <description>I was wondering if adding jumps to stochastic volatility, as is done in the SVCJ model of Duffie, Singleton and Pan &amp;ldquo;Transform Analysis and Asset Pricing for Affine Jump-Diffusion&amp;rdquo; also in Broadie and Kaya &amp;ldquo;Exact simulation of stochastic volatility and other affine jump diffusion processes&amp;rdquo;, would lead to rougher paths, or if it would mislead the roughness estimators.&#xA;The answer to the first question can almost be answered visually: The parameters used are the one from Broadie and Kaya: v0=0.</description>
    </item>
    <item>
      <title>Measuring Roughness with Julia</title>
      <link>https://chasethedevil.github.io/post/measuring_roughness_with_julia/</link>
      <pubDate>Tue, 07 Nov 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/measuring_roughness_with_julia/</guid>
      <description>I received a few e-mails asking me for the code I used to measure roughness in my preprint on the roughness of the implied volatility. Unfortunately, the code I wrote for this paper is not in a good state, it&amp;rsquo;s all in one long file line by line, not necessarily in order of execution, with comments that are only meaningful to myself.&#xA;In this post I will present the code relevant to measuring the oxford man institute roughness with Julia.</description>
    </item>
    <item>
      <title>Black with Bachelier</title>
      <link>https://chasethedevil.github.io/post/black_with_bachelier/</link>
      <pubDate>Tue, 03 Oct 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/black_with_bachelier/</guid>
      <description>I was experimenting with the recent SABR basket approximation of Hagan. The approximation only works for the normal SABR model, meaning beta=0 in SABR combined with the Bachelier option formula.&#xA;I was wondering how good the approximation would be for two flat smiles (in terms of Black volatilities). I then noticed something that escaped me before: the normal SABR model is able to fit the pure Black model (with constant vols) extremely well.</description>
    </item>
    <item>
      <title>Clenshaw-Curtis Quadrature Implementation by FFT in Practice</title>
      <link>https://chasethedevil.github.io/post/clenshaw_fft_implementation/</link>
      <pubDate>Wed, 27 Sep 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/clenshaw_fft_implementation/</guid>
      <description>The Clenshaw-Curtis quadrature is known to be competitive with Gauss quadratures. It has several advantages:&#xA;the weights are easy and fast to compute. adaptive / doubling quadratures are possible with when the Chebyshev polynomial of the second kind is used for the quadrature. the Chebyshev nodes may also be used to interpolate some costly function. The wikipedia article has a relatively detailed description on how to compute the quadrature weights corresponding to the Chebyshev polynomial of the second kind (where the points -1 and 1 are included), via a type-I DCT.</description>
    </item>
    <item>
      <title>Ghost Vacations</title>
      <link>https://chasethedevil.github.io/post/ghost_vacations/</link>
      <pubDate>Sun, 20 Aug 2023 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/ghost_vacations/</guid>
      <description>During my vacation, I don&amp;rsquo;t know why, but I looked at some stability issue with ghost points and the explicit method. I was initially trying out ghost points with the explicit runge kutta Chebyshev/Legendre/Gegenbauer technique and noticed some explosion in some cases.&#xA;I cornered it down to a stability issue of the standard explicit Euler method with ghost (or fictitious) points. The technique is described in the book &amp;ldquo;Paul Wilmott on Quantitative Finance&amp;rdquo; (also in Paul Wilmott introduces quantitative finance), which I find quite good, although I have some friends who are not much fond of it.</description>
    </item>
    <item>
      <title>Maximum Implied Variance Slope</title>
      <link>https://chasethedevil.github.io/post/maximum_implied_variance_slope/</link>
      <pubDate>Mon, 22 May 2023 23:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/maximum_implied_variance_slope/</guid>
      <description>The paper The Moment Formula for Implied Volatility at Extreme Strikes by Roger Lee redefined how practioners extrapolate the implied volatility, by showing that the total implied variance can be at most linear in the wings, with a slope below 2.&#xA;Shortly after, the SVI model of Jim Gatheral, with its linear wings, started to become popular.&#xA;In a recent paper in collaboration with Winfried Koller, we show that the asymptotic bounds are usually overly optimistic.</description>
    </item>
    <item>
      <title>The Return of the Arbitrage in the Perfect Volatility Surface</title>
      <link>https://chasethedevil.github.io/post/the_return_of_the_arbitrage/</link>
      <pubDate>Wed, 29 Mar 2023 23:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/the_return_of_the_arbitrage/</guid>
      <description>In a Wilmott article from 2018 (Wilmott magazine no. 97) titled &amp;ldquo;Arbitrage in the perfect volatility surface&amp;rdquo;, Uwe Wystup points out some interesting issues on seemingly innocuous FX volatility surfaces:&#xA;a cubic spline tends to produce artificial peaks/modes in the density. SVI not arbitrage-free even on seemingly trivial input. The examples provided are indeed great and the remarks very valid. There is more to it however:&#xA;a cubic spline on strikes or log-moneyness does not produce the artificial peak.</description>
    </item>
    <item>
      <title>Princeton Fintech and Quant conference of December 2022</title>
      <link>https://chasethedevil.github.io/post/princeton_fintech_conference/</link>
      <pubDate>Sun, 04 Dec 2022 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/princeton_fintech_conference/</guid>
      <description>I recently presented my latest published paper On the Bachelier implied volatility at extreme strikes at the Princeton Fintech and Quant conference. The presenters were of quite various backgrounds. The first presentations were much more business oriented with lots of AI keywords, but relatively little technical content while the last presentation was about parallel programming. Many were a pitch to recruit to employees.&#xA;The diversity was interesting: it was refreshing to hear about quantitative finance from vastly different perspectives.</description>
    </item>
    <item>
      <title>Roughness of the Implied Volatility</title>
      <link>https://chasethedevil.github.io/post/implied_volatility_roughness/</link>
      <pubDate>Sat, 09 Jul 2022 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/implied_volatility_roughness/</guid>
      <description>This is a follow up of my previous post on rough volatility. I recently tried to reproduce the results of the paper Rough Volatility: Fact or Artefact? as I was curious to apply the technique using different inputs. The 5-minutes SPX realized volatility is freely available in CSV format at the Oxford-Man Institute of Quantitative Finance and it is thus relatively straightforward to reproduce the numbers presented in the paper.</description>
    </item>
    <item>
      <title>Volatility: Rough or Not? A Short Review</title>
      <link>https://chasethedevil.github.io/post/rough-volatility-or-not-a-review/</link>
      <pubDate>Tue, 10 May 2022 17:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/rough-volatility-or-not-a-review/</guid>
      <description>It is well-known that the assumption of constant volatility in the Black-Scholes model for pricing financial contracts is wrong and may lead to serious mispricing, especially for any exotic derivative contracts. A classic approach is to use a deterministic local volatility model to take into account the variation both in the time dimension and in the underlying asset price dimension. But the model is still not realistic in terms of forward smile (the implied volatilities of forward starting options).</description>
    </item>
    <item>
      <title>Monte-Carlo Parallelization: to vectorize or not?</title>
      <link>https://chasethedevil.github.io/post/monte-carlo-vectorization-or-not/</link>
      <pubDate>Sat, 09 Apr 2022 21:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/monte-carlo-vectorization-or-not/</guid>
      <description>When writing a Monte-Carlo simulation to price financial derivative contracts, the most straightforward is to code a loop over the number of paths, in which each path is fully calculated. Inside the loop, a payoff function takes this path to compute the present value of the contract on the given path. The present values are recorded to lead to the Monte-Carlo statistics (mean, standard deviation). I ignore here any eventual callability of the payoff which may still be addressed with some work-arounds in this setup.</description>
    </item>
    <item>
      <title>More Automatic Differentiation Awkwardness</title>
      <link>https://chasethedevil.github.io/post/more-automatic-differentiation-awkwardness/</link>
      <pubDate>Tue, 04 Jan 2022 21:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/more-automatic-differentiation-awkwardness/</guid>
      <description>This blog post from Jherek Healy presents some not so obvious behavior of automatic differentiation, when a function is decomposed into the product of two parts where one part goes to infinity and the other to zero, and we know the overall result must go to zero (or to some other specific number). This decomposition may be relatively simple to handle for the value of the function, but becomes far less trivial to think of in advance, at the derivative level.</description>
    </item>
    <item>
      <title>Quadprog in Julia</title>
      <link>https://chasethedevil.github.io/post/quadprog-in-julia/</link>
      <pubDate>Sun, 21 Nov 2021 13:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/quadprog-in-julia/</guid>
      <description>As described on wikipedia, a quadratic programming problem with n variables and m constraints is of the form $$ \min(-d^T x + 1/2 x^T D x) $$ with the constraints \( A^T x \geq b_0 \), were \(D\) is a \(n \times n\)-dimensional real symmetric matrix, \(A\) is a \(n \times m\)-dimensional real matrix, \( b_0 \) is a \(m\)-dimensional vector of constraints, \( d \) is a \(n\)-dimensional vector, and the variable \(x\) is a \(n\)-dimensional vector.</description>
    </item>
    <item>
      <title>Positive Stochastic Collocation</title>
      <link>https://chasethedevil.github.io/post/positive_stochastic_collocation/</link>
      <pubDate>Tue, 31 Aug 2021 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/positive_stochastic_collocation/</guid>
      <description>In the context of my thesis, I explored the use of stochastic collocation to capture the marginal densities of a positive asset. Indeed, most financial asset prices must be non-negative. But the classic stochastic collocation towards the normally distributed random variable, is not.&#xA;A simple tweak, proposed early on by Grzelak, is to assume absorption and use the put-call parity to price put options (which otherwise depend on the left tail).</description>
    </item>
    <item>
      <title>Remarkable Coincidences, Bad Book?</title>
      <link>https://chasethedevil.github.io/post/reghai_remarkable_coincidences/</link>
      <pubDate>Sat, 21 Nov 2020 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/reghai_remarkable_coincidences/</guid>
      <description>I stumbled upon a new short book Financial Models in Production from O. Kettani and A. Reghai. A page attracted my attention&#xA;A page from Kettani and Reghai&amp;#39;s book. This is the same example as I used on my blog, where I also present the Li&amp;rsquo;s SOR method combined with the good initial guess from Stefanica. The idea has also been expanded on in Jherek Healy&amp;rsquo;s book. What is shocking is that, beside reusing my example, they reuse my timing for J√§ckel and my implementation is in Google Go, with a timing done on some older laptop.</description>
    </item>
    <item>
      <title>More on random number generators</title>
      <link>https://chasethedevil.github.io/post/more-on-random-number-generators/</link>
      <pubDate>Sat, 10 Oct 2020 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/more-on-random-number-generators/</guid>
      <description>My previous post described the recent view on random number generators, with a focus on the Mersenne-Twister war.&#xA;Since, I have noticed another front in the war of the random number generators:&#xA;An example in dimension 121 from K Savvidy where L&amp;rsquo;Ecuyer MRG32k3a fails to compute the correct result, regardless of the seed. This is a manufactured example, such that the vector, used in the example, falls in the dual lattice of the generator.</description>
    </item>
    <item>
      <title>The war of the random number generators</title>
      <link>https://chasethedevil.github.io/post/war-of-the-random-number-generators/</link>
      <pubDate>Thu, 17 Sep 2020 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/war-of-the-random-number-generators/</guid>
      <description>These days, there seems to be some sort of small war to define what is a modern good random number generators to advise for simulations. Historically, the Mersenne-Twister (MT thereafter) won this war. It is used by default in many scientific libraries and software, even if there has been a few issues with it:&#xA;A bad initial seed may make it generate a sequence of low quality for at least as many as 700K numbers.</description>
    </item>
    <item>
      <title>Sobol with 64-bits integers</title>
      <link>https://chasethedevil.github.io/post/sobol-64-bits/</link>
      <pubDate>Wed, 09 Sep 2020 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/sobol-64-bits/</guid>
      <description>A while ago, I wondered how to make some implementation of Sobol support 64-bits integers (long) and double floating points. Sobol is the most used quasi random number generator (QRNG) for (quasi) Monte-Carlo simulations.&#xA;The standard Sobol algorithms are all coded with 32-bits integers and lead to double floating point numbers which can not be smaller than \( 2^{-31} \). I was recently looking back at the internals at Sobol generators, and noticed that generating with 64-bits integers would not help much.</description>
    </item>
    <item>
      <title>March 9, 2020 crash - where will CAC40 go?</title>
      <link>https://chasethedevil.github.io/post/mar9-cac40-crash/</link>
      <pubDate>Mon, 09 Mar 2020 21:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/mar9-cac40-crash/</guid>
      <description>The stock market crashed by more than 7% on March 9, 2020. It is one of the most important drop since September 2001. I looked at BNP warrant prices on the CAC40 French index, with a maturity of March 20, 2020 , to see what they would tell about the market direction on the day of the crash. This is really a not-so-scientific experiment.&#xA;The quotes I got were quite noisy.</description>
    </item>
    <item>
      <title>Numba, Pypy Overrated?</title>
      <link>https://chasethedevil.github.io/post/python-numba-overrated/</link>
      <pubDate>Tue, 12 Feb 2019 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/python-numba-overrated/</guid>
      <description>Many benchmarks show impressive performance gains with the use of Numba or Pypy. Numba allows to compile just-in-time some specific methods, while Pypy takes the approach of compiling/optimizing the full python program: you use it just like the standard python runtime. From those benchmarks, I imagined that those tools would improve my 2D Heston PDE solver performance easily. The initialization part of my program contains embedded for loops over several 10Ks elements.</description>
    </item>
    <item>
      <title>Fixing NaNs in Quadprog</title>
      <link>https://chasethedevil.github.io/post/quadprog-nans/</link>
      <pubDate>Sun, 07 Oct 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/quadprog-nans/</guid>
      <description>Out of curiosity, I tried quadprog as open-source quadratic programming convex optimizer, as it is looks fast, and the code stays relatively simple. I however stumbled on cases where the algorithm would return NaNs even though my inputs seemed straighforward. Other libraries such as CVXOPT did not have any issues with those inputs.&#xA;Searching on the web, I found that I was not the only one to stumble on this kind of issue with quadprog.</description>
    </item>
    <item>
      <title>On the Probability of a Netflix Stock Crash</title>
      <link>https://chasethedevil.github.io/post/nflx-stock-crash-probability/</link>
      <pubDate>Thu, 12 Jul 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/nflx-stock-crash-probability/</guid>
      <description>This is a follow up to my previous post where I explore the probability of a TSLA stock crash, reproducing the results of Timothy Klassen.&#xA;According to the implied cumulative probability density, TSLA has around 15% chance of crashing below $100. Is this really high compared to other stocks? or is it the interpretation of the data erroneous?&#xA;Here I take a look at NFLX (Netflix). Below is the implied volatility according to three different models.</description>
    </item>
    <item>
      <title>On the Probability of a TSLA Stock Crash</title>
      <link>https://chasethedevil.github.io/post/tsla-stock-crash-probability/</link>
      <pubDate>Wed, 11 Jul 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/tsla-stock-crash-probability/</guid>
      <description>Timothy Klassen had an interesting post on linkedin recently, with the title &amp;ldquo;the options market thinks there is a 16% chance that Tesla will not exist in January 2020&amp;rdquo;. As I was also recently looking at the TSLA options, I was a bit intrigued. I looked at the option chain on July 10th, and implied the European volatility from the American option prices. I then fit a few of my favorite models: Andreasen-Huge with Tikhonov regularization, the lognormal mixture, and a polynomial collocation of degree 7.</description>
    </item>
    <item>
      <title>The Fourth Moment of the Normal SABR Model</title>
      <link>https://chasethedevil.github.io/post/normal-sabr-fourth-moment/</link>
      <pubDate>Mon, 11 Jun 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/normal-sabr-fourth-moment/</guid>
      <description>I was wondering if I could use the SABR moments to calibrate a model to SABR parameters directly. It turns out that the SABR moments have relatively simple expressions when \(\beta=0\), that is, for the normal SABR model (with no absorption). This is for the pure SABR stochatic volatility model, not the Hagan approximation. For the Hagan approximation, we would need to use the replication by vanilla options to compute the moments.</description>
    </item>
    <item>
      <title>Implying the Probability Density from Market Option Prices (Part 2)</title>
      <link>https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices-ii/</link>
      <pubDate>Sun, 27 May 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices-ii/</guid>
      <description>This is a follow-up to my posts on the implied risk-neutral density (RND) of the SPW options before and after the big volatility change that happened in early February with two different techniques: a smoothing spline on the implied volatilities and a Gaussian kernel approach.&#xA;The Gaussian kernel (as well as to some extent the smoothing spline) let us believe that there are multiple modes in the distribution (multiple peaks in the density).</description>
    </item>
    <item>
      <title>Implying the Probability Density from Market Option Prices</title>
      <link>https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices/</link>
      <pubDate>Tue, 13 Feb 2018 20:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices/</guid>
      <description>In the previous post, I showed a plot of the probability implied from SPW options before and after the big volatility change of last week. I created it from a least squares spline fit of the market mid implied volatilities (weighted by the inverse of the bid-ask spread). While it looks reasonable, the underlying technique is not very robust. It is particularly sensitive to the number of options strikes used as spline nodes.</description>
    </item>
    <item>
      <title>Where is the S&amp;P 500 going to end?</title>
      <link>https://chasethedevil.github.io/post/spx500_bets_after_rates_hike/</link>
      <pubDate>Tue, 06 Feb 2018 19:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/spx500_bets_after_rates_hike/</guid>
      <description>Yesterday the American stocks went a bit crazy along with the VIX that jumped from 17.50 to 38. It&amp;rsquo;s not exactly clear why, the news mention that the Fed might raise its interest rates, the bonds yield have been recently increasing substantially, and the market self-correcting after stocks grew steadily for months in a low VIX environment.&#xA;I don&amp;rsquo;t exactly follow the SPX/SPW options daily. But I had taken a snapshot two weeks ago when the market was quiet.</description>
    </item>
    <item>
      <title>Discrete Sine Transform via the FFT</title>
      <link>https://chasethedevil.github.io/post/discrete_sine_transform_fft/</link>
      <pubDate>Mon, 05 Feb 2018 13:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/discrete_sine_transform_fft/</guid>
      <description>Several months ago, I had a quick look at a recent paper describing how to use Wavelets to price options under stochastic volatility models with a known characteristic function. The more classic method is to use some numerical quadrature directly on the Fourier integral as described in this paper for example. When I read the paper, I was skeptical about the Wavelet approach, since it looked complicated, and with many additional parameters.</description>
    </item>
    <item>
      <title>Quantitative Finance Books Citing My Papers</title>
      <link>https://chasethedevil.github.io/post/quantitative_finance_books/</link>
      <pubDate>Sat, 09 Dec 2017 13:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/quantitative_finance_books/</guid>
      <description>I would have never really expected that when I started writing papers, but little by little there is a growing list of books citing my papers:&#xA;Applied Quantitative Finance for Equity Derivatives by Jherek Healy: the most recent book on equity derivatives refers to several of my papers. In contrast with many other books, the author goes beyond and provides additional insights on the papers. Interest Rate Derivatives Explained: Volume 2: Term Structure and Volatility Modelling by J√∂rg Kienitz and Peter Casper.</description>
    </item>
    <item>
      <title>Blogs on Quantitative Finance</title>
      <link>https://chasethedevil.github.io/post/quantitative_finance_blogs/</link>
      <pubDate>Wed, 21 Jun 2017 23:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/quantitative_finance_blogs/</guid>
      <description>There are not many blogs on quantitative finance that I read. Blogs are not so popular anymore with the advent of the various social networks (facebook, stackoverflow, google plus, reddit, &amp;hellip;). Here is a small list:&#xA;Clarus FT: often interesting statistics on the swap market, clearing, plus the more technical articles from Gary. Quants R Us: A relatively new blog with a promising starting post analyzing Andreasen-Huge one-step local-volatility algorithm with a Spline Fooling around with Quantlib: the blog from Peter Caspers, also relevant to non-Quantlib professionals has original insights such as Smile dynamics by densities or the Supernatural Libor Coupons.</description>
    </item>
    <item>
      <title>Typo in Hyman non-negative constraint - 28 years later</title>
      <link>https://chasethedevil.github.io/post/typo-in-hyman-non-negative-constraint/</link>
      <pubDate>Tue, 23 May 2017 23:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/typo-in-hyman-non-negative-constraint/</guid>
      <description>In their paper &amp;ldquo;Nonnegativity-, Monotonicity-, or Convexity-Preserving Cubic and Quintic Hermite Interpolation&amp;rdquo;, Dougherty, Edelman and Hyman present a simple filter on the first derivatives to maintain positivity of a cubic spline interpolant.&#xA;Unfortunately, in their main formula for non-negativity, they made a typo: the equation (3.3) is not consistent with the equation (3.1): the \( \Delta x_{i-1/2} \) is interverted with \( \Delta x_{i+1/2} \).&#xA;It was not obvious to find out which equation was wrong since there is no proof in the paper.</description>
    </item>
    <item>
      <title>Implied Volatility from Black-Scholes price</title>
      <link>https://chasethedevil.github.io/post/implied-volatility-from-black-scholes-price/</link>
      <pubDate>Sun, 02 Apr 2017 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/implied-volatility-from-black-scholes-price/</guid>
      <description>Dan Stefanica and Rados Radoicic propose a quite good initial guess in their very recent paper An Explicit Implied Volatility Formula. Their formula is simple, fast to compute and results in an implied volatility guess with a relative error of less than 10%.&#xA;It is more robust than the rational fraction from Minquiang Li: his rational fraction is only valid for a fixed range of strikes and maturities. The new approximation is mathematically proved accurate across all strikes and all maturities.</description>
    </item>
    <item>
      <title>The VIX starts smiling</title>
      <link>https://chasethedevil.github.io/post/vix-starts-smiling/</link>
      <pubDate>Tue, 21 Mar 2017 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/vix-starts-smiling/</guid>
      <description>The VIX implied volatilities used to look like a logarithmic function of the strikes. I don&amp;rsquo;t look at them often, but today, I noticed that the VIX had the start of a smile shape.&#xA;1m VIX implied volatilities on March 21, 2017 with strictly positive volume. Very few strikes trades below the VIX future level (12.9). All of this is likely because the VIX is unusually low: not many people are looking to trade it much lower.</description>
    </item>
    <item>
      <title>When SVI Breaks Down</title>
      <link>https://chasethedevil.github.io/post/when-svi-breaks-down/</link>
      <pubDate>Thu, 16 Mar 2017 07:56:42 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/when-svi-breaks-down/</guid>
      <description>In order to fit the implied volatility smile of equity options, one of the most popular parameterization is Jim Gatheral&amp;rsquo;s SVI, which I have written about before here.&#xA;It turns out that in the current market conditions, SVI does not work well for short maturities. SPX options expiring on March 24, 2017 (one week) offer a good example. I paid attention to include only options with non zero volume, that is options that are actually traded.</description>
    </item>
    <item>
      <title>Brownian Bridge and Discrete Random Variables</title>
      <link>https://chasethedevil.github.io/post/brownian-bridge-and-discrete-sampling/</link>
      <pubDate>Thu, 26 Jan 2017 14:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/brownian-bridge-and-discrete-sampling/</guid>
      <description>The new Heston discretisation scheme I wrote about a few weeks ago makes use a discrete random variable matching the first five moments of the normal distribution instead of the usual normally distributed random variable, computed via the inverse cumulative distribution function. Their discrete random variable is: $$\xi =&#x9;\sqrt{1-\frac{\sqrt{6}}{3}} \quad \text{ if } U_1 &amp;lt; 3,,$$ $$&#x9;\xi =-\sqrt{1-\frac{\sqrt{6}}{3}} \quad \text{ if } U_1 &amp;gt; 4,,$$ $$\xi =&#x9;\sqrt{1+\sqrt{6}} \quad \text{ if } U_1 = 3,,$$ $$\xi =&#x9;-\sqrt{1+\sqrt{6}} \quad \text{ if } U_1 = 4,,$$ with \(U_1 \in \{0,1,&amp;hellip;,7\}\)</description>
    </item>
    <item>
      <title>A new scheme for Heston - Part 2</title>
      <link>https://chasethedevil.github.io/post/a-new-scheme-for-heston_part2/</link>
      <pubDate>Mon, 23 Jan 2017 07:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/a-new-scheme-for-heston_part2/</guid>
      <description>A couple weeks ago, I wrote about a new Heston discretisation scheme which was at least as accurate as Andersen QE scheme and faster, called DVSS2.&#xA;It turns out that it does not behave very well on the following Vanilla forward start option example (which is quite benign). The Heston parameters comes from a calibration to the market and are&#xA;$$v_0= 0.0718, \kappa= 1.542, \theta= 0.0762, \sigma= 0.582, \rho= -0.352$$</description>
    </item>
    <item>
      <title>Equivalence between floating-strike and fixed-strike Asian options</title>
      <link>https://chasethedevil.github.io/post/floating_strike_fixed_strike_asian_equivalence/</link>
      <pubDate>Wed, 18 Jan 2017 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/floating_strike_fixed_strike_asian_equivalence/</guid>
      <description>Many papers present formulae to price Asian options in the Black-Scholes world only for the fixed strike Asian case, that is a contract that pays \( \max(A-K,0)\) at maturity \(T\) where \(A = \sum_{i=0}^{n-1} w_i S(t_i) \) is the Asian average.&#xA;More generally, this can be seen as the payoff of a Basket option where the underlyings are just the same asset but at different times. And any Basket option formula can actually be used to price fixed-strike Asian options by letting the correlation correspond to the correlation between the asset at the averaging times and the variances correspond to the variance at each averaging time.</description>
    </item>
    <item>
      <title>Bachelier Normal Volatility Asymptotics</title>
      <link>https://chasethedevil.github.io/post/normal_volatility_asymptotics/</link>
      <pubDate>Tue, 17 Jan 2017 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/normal_volatility_asymptotics/</guid>
      <description>It is relatively well known that the Black-Scholes volatility can not grow faster than \(\sqrt{\ln(K)}\). The rule is also sometimes simply stated as &amp;ldquo;the implied variance can not grow faster than linear&amp;rdquo; (in log-moneyness). The proof comes from Roger Lee &amp;ldquo;The moment formula for implied volatility at extreme strikes&amp;rdquo; but the rule was suggested earlier, for example in Hodge&amp;rsquo;s paper from 1996 &amp;ldquo;Arbitrage bounds of the implied volatility strike and term structures of European-style options&amp;rdquo;.</description>
    </item>
    <item>
      <title>A new scheme for Heston</title>
      <link>https://chasethedevil.github.io/post/a-new-scheme-for-heston/</link>
      <pubDate>Fri, 06 Jan 2017 07:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/a-new-scheme-for-heston/</guid>
      <description>I stumbled recently upon a new Heston discretisation scheme, in the spirit of Alfonsi, not more complex and more accurate.&#xA;My first attempt at coding the scheme resulted in a miserable failure even though the described algorithm looked not too difficult. I started wondering if the paper, from a little known Lithuanian mathematical journal, was any good. Still, the math in it is very well written, with a great emphasis on the settings for each proposition.</description>
    </item>
    <item>
      <title>Andreasen-Huge interpolation - Don&#39;t stay flat</title>
      <link>https://chasethedevil.github.io/post/dont-stay-flat-with-andreasen-huge-interpolation/</link>
      <pubDate>Tue, 13 Dec 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/dont-stay-flat-with-andreasen-huge-interpolation/</guid>
      <description>Jesper Andreasen and Brian Huge propose an arbitrage-free interpolation method based on a single-step forward Dupire PDE solution in their paper Volatility interpolation. To do so, they consider a piecewise constant representation of the local volatility in maturity time and strike where the number of constants matches the number of market option prices.&#xA;An interesting example that shows some limits to the technique as described in Jesper Andreasen and Brian Huge paper comes from Nabil Kahale paper on an arbitrage-free interpolation of volatilities.</description>
    </item>
    <item>
      <title>Put-Call parity and the log-transformed Black-Scholes PDE</title>
      <link>https://chasethedevil.github.io/post/put_call_parity_with_log_transformed_pde/</link>
      <pubDate>Mon, 05 Dec 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/put_call_parity_with_log_transformed_pde/</guid>
      <description>We will assume zero interest rates and no dividends on the asset \(S\) for clarity. The results can be easily generalized to the case with non-zero interest rates and dividends. Under those assumptions, the Black-Scholes PDE is: $$&#x9;\frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2} = 0.$$&#xA;An implicit Euler discretisation on a uniform grid in \(S\) of width \(h\) with linear boundary conditions (zero Gamma) leads to:</description>
    </item>
    <item>
      <title>Benaim et al. extrapolation does not work on equities</title>
      <link>https://chasethedevil.github.io/post/issues_with_bdk_extrapolation/</link>
      <pubDate>Tue, 04 Oct 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/issues_with_bdk_extrapolation/</guid>
      <description>We have seen earlier that a simple parabola allows to capture the smile of AAPL 1m options surprisingly well. For very high and very low strikes, the parabola does not obey Lee&amp;rsquo;s moments formula (the behavior in the wings needs to be at most linear in variance/log-moneyness).&#xA;Extrapolating the volatility smile in the low or high strikes in a smooth \(C^2\) fashion is however not easy. A surprisingly popular so called &amp;ldquo;arbitrage-free&amp;rdquo; method is the extrapolation of Benaim, Dodgson and Kainth developed to remedy the negative density of SABR in interest rates as well as to give more control over the wings.</description>
    </item>
    <item>
      <title>AES for Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/aes_for_monte_carlo/</link>
      <pubDate>Wed, 17 Aug 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/aes_for_monte_carlo/</guid>
      <description>In finance, and also in science, the Mersenne-Twister is the de-factor pseudo-random number generator (PRNG) for Monte-Carlo simulations. By the way, there is a recent 64-bit maximally equidistributed version called MEMT19937 with 53-bit double precision floating point numbers in mind.&#xA;D.E. Shaw paper Parallel Random Numbers: As easy as 1, 2, 3 makes a bold remark: since specific AES instructions have been available since 2010 in most x86 processors, why not use them?</description>
    </item>
    <item>
      <title>Number of regressors in a BSDE</title>
      <link>https://chasethedevil.github.io/post/number_of_regressors_in_bdse/</link>
      <pubDate>Tue, 26 Jul 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/number_of_regressors_in_bdse/</guid>
      <description>Last year, I was kindly invited at the workshop on Models and Numerics in Financial Mathematics at the Lorentz center. It was surprinsgly interesting on many different levels. Beside the relatively large gap between academia and the industry, which this workshop was trying to address, one thing that struck me is how difficult it was for people of slightly different specialties to communicate.&#xA;It seemed that mathematicians of different countries working on different subjects related to backward stochastic differential equations (BSDEs) would not truly understand each other.</description>
    </item>
    <item>
      <title>Shooting arbitrage - part II</title>
      <link>https://chasethedevil.github.io/post/shooting_arbitrage2/</link>
      <pubDate>Tue, 05 Jul 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/shooting_arbitrage2/</guid>
      <description>In my previous post, I looked at de-arbitraging volatilities of options of a specific maturity with the shooting method. In reality it is not so practical. While the local volatility will be continuous at the given expiry \(T\), it won&amp;rsquo;t be so at the times \( t \lt T \) because of the interpolation or extrapolation in time. If we consider a single market expiry at time \(T\), it is standard practice to extrapolate the implied volatility flatly for \(t \lt T\), that is, \(w(y,t) = v_T(y) t\) where the variance at time \(T\) is defined as \(v_T(y)= \frac{1}{T}w(y,T)\).</description>
    </item>
    <item>
      <title>Shooting arbitrage - part I</title>
      <link>https://chasethedevil.github.io/post/shooting_arbitrage/</link>
      <pubDate>Wed, 22 Jun 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/shooting_arbitrage/</guid>
      <description>In my previous post, I looked at de-arbitraging volatilities of options of a specific maturity with SVI (re-)calibration. The penalty method can be used beyond SVI. For example I interpolate here with a cubic spline on 11 equidistant nodes the original volatility slice that contains arbitrages and then minimize with Levenberg-Marquardt and the negative local variance denominator penalty on 51 equidistant points. This results in a quite small adjustment to the original volatilities:</description>
    </item>
    <item>
      <title>Dearbitraging a weak smile on SVI with Damghani&#39;s method</title>
      <link>https://chasethedevil.github.io/post/damghani_dearbitraging_a_weak_smile_on_svi/</link>
      <pubDate>Wed, 15 Jun 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/damghani_dearbitraging_a_weak_smile_on_svi/</guid>
      <description>Yesterday, I wrote about some calendar spread arbitrages with SVI. Today I am looking at the famous example of butterfly spread arbitrage from Axel Vogt. $$(a, b, m, \rho, \sigma) = (‚àí0.0410, 0.1331, 0.3586, 0.3060, 0.4153)$$ The parameters obey the weak no-arbitrage constraint of Gatheral, and yet produce a negative density, or equivalently, a negative denominator in the local variance Dupire formula. Those parameters are mentioned in Jim Gatheral and Antoine Jacquier paper on arbitrage free SVI volatility surfaces and also in Damghani&amp;rsquo;s paper dearbitraging a weak smile.</description>
    </item>
    <item>
      <title>Arbitrage in Zeliade&#39;s SVI example</title>
      <link>https://chasethedevil.github.io/post/svi_zeliade_arbitrage/</link>
      <pubDate>Tue, 14 Jun 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/svi_zeliade_arbitrage/</guid>
      <description>Zeliade wrote an excellent paper about the calibration of the SVI parameterization for the volatility surface in 2008. I just noticed recently that their example calibration actually contained strong calendar spread arbitrages. This is not too surprising if you look at the parameters, they vary wildly between the first and the second expiry.&#xA;T a b rho m s 0.082 0.027 0.234 0.068 0.100 0.028 0.16 0.030 0.125 -1.0 0.074 0.</description>
    </item>
    <item>
      <title>Dupire Local Volatility with Cash Dividends Part 2</title>
      <link>https://chasethedevil.github.io/post/dupire_cash_dividend_part2/</link>
      <pubDate>Sun, 29 May 2016 17:01:00 +0200</pubDate>
      <guid>https://chasethedevil.github.io/post/dupire_cash_dividend_part2/</guid>
      <description>I had a look at how to price under Local Volatility with Cash dividends in my previous post. I still had a somewhat large error in my FDM price. After too much time, I managed to find the culprit, it was the extrapolation of the prices when applying the jump continuity condition \(V(S,t_\alpha^-) = V(S-\alpha, t_\alpha^+) \) for an asset \(S\) with a cash dividend of amount \(\alpha\) at \( t_\alpha \).</description>
    </item>
    <item>
      <title>Dupire Local Volatility with Cash Dividends</title>
      <link>https://chasethedevil.github.io/post/dupire_cash_dividend/</link>
      <pubDate>Thu, 19 May 2016 17:01:00 +0200</pubDate>
      <guid>https://chasethedevil.github.io/post/dupire_cash_dividend/</guid>
      <description>The Dupire equation for local volatility has been derived under the assumption of Martingality, that means no dividends or interest rates. The extension to continuous dividend yield is described in many papers or books:&#xA;With cash dividends however, the Black-Scholes formula is not valid anymore if we suppose that the asset jumps at the dividend date of the dividend amount. There are various relatively accurate approximations available to price an option supposing a constant (spot) volatility and jumps, for example, this one.</description>
    </item>
    <item>
      <title>SVI, SABR, or parabola on AAPL?</title>
      <link>https://chasethedevil.github.io/post/svi_sabr_or_parabola/</link>
      <pubDate>Thu, 12 May 2016 19:32:42 +0200</pubDate>
      <guid>https://chasethedevil.github.io/post/svi_sabr_or_parabola/</guid>
      <description>In a previous post, I took a look at least squares spline and parabola fits on AAPL 1m options market volatilities. I would have imagined SVI to fit even better since it has 5 parameters, and SABR to do reasonably well.&#xA;It turns out that the simple parabola has the lowest RMSE, and SVI is not really better than SABR on that example.&#xA;SVI, SABR, least squares parabola fitted to AAPL 1m options Note that this is just one single example, unlikely to be representative of anything, but I thought this was interesting that in practice, a simple parabola can compare favorably to more complex models.</description>
    </item>
    <item>
      <title>Adaptive Filon quadrature for stochastic volatility models</title>
      <link>https://chasethedevil.github.io/post/filon_for_heston/</link>
      <pubDate>Thu, 12 May 2016 19:08:18 +0200</pubDate>
      <guid>https://chasethedevil.github.io/post/filon_for_heston/</guid>
      <description>A while ago, I have applied a relatively simple adaptive Filon quadrature to the problem of volatility swap pricing. The Filon quadrature is an old quadrature from 1928 that allows to integrate oscillatory integrand like \(f(x)\cos(k x) \) or \(f(x)\sin(k x) \). It turns out that combined with an adaptive Simpson like method, it has many advantages over more generic adaptive quadrature methods like Gauss-Lobatto, which is often used on similar problems.</description>
    </item>
    <item>
      <title>Least Squares Rational Function</title>
      <link>https://chasethedevil.github.io/post/rational_fit/</link>
      <pubDate>Thu, 21 Apr 2016 16:37:24 +0200</pubDate>
      <guid>https://chasethedevil.github.io/post/rational_fit/</guid>
      <description>In my paper &amp;ldquo;Fast and Accurate Analytic Basis Point Volatility&amp;rdquo;, I use a table of Chebyshev polynomials to provide an accurate representation of some function. This is an idea I first saw in the Faddeeva package to represent the cumulative normal distribution with high accuracy, and high performance. It is also simple to find out the Chebyshev polynomials, and which intervals are the most appropriate for those, which makes this technique quite appealing.</description>
    </item>
    <item>
      <title>Least Squares Spline for Volatility Interpolation</title>
      <link>https://chasethedevil.github.io/post/least_squares_spline/</link>
      <pubDate>Fri, 19 Feb 2016 18:29:33 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/least_squares_spline/</guid>
      <description>I am experimenting a bit with least squares splines. Existing algorithms (for example from the NSWC Fortran library) usually work with B-splines, a relatively simple explanation of how it works is given in this paper (I think this is how De Boor coded it in the NSWC library). Interestingly there is an equivalent formulation in terms of standard cubic splines, although it seems that the pseudo code on that paper has errors.</description>
    </item>
    <item>
      <title>The Mystic Parabola</title>
      <link>https://chasethedevil.github.io/post/mystic_parabola/</link>
      <pubDate>Tue, 16 Feb 2016 22:13:53 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/mystic_parabola/</guid>
      <description>I recently had some fun trying to work directly with the option chain from the Nasdaq website. The data there is quite noisy, but a simple parabola can still give an amazing fit. I will consider the options of maturity two years as illustration. I also relied on a simple implied volatility algorithm that can be summarized in the following steps:&#xA;Compute a rough guess for the forward price by using interest, borrow curves and by extrapolating the dividends.</description>
    </item>
    <item>
      <title>Yahoo Finance Implied Volatility</title>
      <link>https://chasethedevil.github.io/post/yahoo_finance_implied_volatility/</link>
      <pubDate>Wed, 03 Feb 2016 16:45:58 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/yahoo_finance_implied_volatility/</guid>
      <description>The option chain on Yahoo finance shows an implied volatility number for each call or put option in the last column. I was wondering a bit how they computed that number. I did not exactly find out their methodology, especially since we don&amp;rsquo;t even know the daycount convention used, but I did find that it was likely just garbage.&#xA;A red-herring is for example the large discrepancy between put vols and call vols.</description>
    </item>
    <item>
      <title>Linear and Flat forward interpolation with cash dividends</title>
      <link>https://chasethedevil.github.io/post/linear_flat_forward_interpolation/</link>
      <pubDate>Tue, 19 Jan 2016 09:55:32 +0100</pubDate>
      <guid>https://chasethedevil.github.io/post/linear_flat_forward_interpolation/</guid>
      <description>When the dividend curve is built from discrete cash dividends, the dividend yield is discontinuous at the dividend time as the asset price jumps from the dividend amount. This can be particularly problematic for numerical schemes like finite difference methods. In deed, a finite difference grid will make use of the forward yield (eventually adjusted to the discretisation scheme), which explodes then. Typically, if one is not careful about this, then increasing the number of time steps does not increase accuracy anymore, as the spike just becomes bigger on a smaller time interval.</description>
    </item>
    <item>
      <title>Go for Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/go-for-monte-carlo/</link>
      <pubDate>Sat, 22 Aug 2015 16:13:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/go-for-monte-carlo/</guid>
      <description>I have looked a few months ago already at Julia, Dart, Rust and Scala programming languages to see how practical they could be for a simple Monte-Carlo option pricing.&#xA;I forgot the Go language. I had tried it 1 or 2 years ago, and at that time, did not enjoy it too much. Looking at Go 1.5 benchmarks on the computer language shootout, I was surprised that it seemed so close to Java performance now, while having a GC that guarantees pauses of less 10ms and consuming much less memory.</description>
    </item>
    <item>
      <title>Bumping Correlations</title>
      <link>https://chasethedevil.github.io/post/bumping-correlations/</link>
      <pubDate>Sat, 25 Jul 2015 18:36:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/bumping-correlations/</guid>
      <description>In his book &#34;Monte Carlo Methods in Finance&#34;, P. J√§ckel explains a simple way to clean up a correlation matrix. When a given correlation matrix is not positive semi-definite, the idea is to do a singular value decomposition (SVD), replace the negative eigenvalues by 0, and renormalize the corresponding eigenvector accordingly.&#xA;One of the cited applications is &#34;stress testing and scenario analysis for market risk&#34; or &#34;comparative pricing in order to ascertain the extent of correlation exposure for multi-asset derivatives&#34;</description>
    </item>
    <item>
      <title>Andreasen Huge extrapolation</title>
      <link>https://chasethedevil.github.io/post/andreasen-huge-extrapolation/</link>
      <pubDate>Mon, 13 Jul 2015 17:35:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/andreasen-huge-extrapolation/</guid>
      <description>There are not many arbitrage free extrapolation schemes. Benaim et al. extrapolation is one of the few that claims it. However, despite the paper&amp;rsquo;s title, it is not truely arbitrage free. The density might be positive, but the forward is not preserved by the implied density. It can also lead to wings that don&amp;rsquo;t obey Lee&amp;rsquo;s moments condition.&#xA;On a Wilmott forum, P. Caspers proposed the following counter-example based on extrapolating SABR: \( \alpha=15%, \beta=80%, \nu=50%, \rho=-48%, f=3%, T=20.</description>
    </item>
    <item>
      <title>Unintuitive behavior of the Black-Scholes formula - negative volatilities in displaced diffusion extrapolation</title>
      <link>https://chasethedevil.github.io/post/unintuitive-behavior-of-the-black-scholes-formula---negative-volatilities-in-displaced-diffusion-extrapolation/</link>
      <pubDate>Tue, 07 Jul 2015 16:43:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/unintuitive-behavior-of-the-black-scholes-formula---negative-volatilities-in-displaced-diffusion-extrapolation/</guid>
      <description>I am looking at various extrapolation schemes of the implied volatilities. An interesting one I stumbled upon is due to Kahale. Even if his paper is on interpolation, there is actually a small paragraph on using the same kind of function for extrapolation. His idea is to simply lookup the standard deviation \( \Sigma \) and the forward \(f\) corresponding to a given market volatility and slope: $$ c_{f,\Sigma} = f N(d_1) - k N(d_2)$$ with $$ d_1 = \frac{\log(f/k)+\Sigma^2 /2}{\Sigma} $$</description>
    </item>
    <item>
      <title>Square Root Crank-Nicolson</title>
      <link>https://chasethedevil.github.io/post/square-root-crank-nicolson/</link>
      <pubDate>Fri, 19 Jun 2015 16:41:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/square-root-crank-nicolson/</guid>
      <description>C. Reisinger kindly pointed out to me this paper around square root Crank-Nicolson. The idea is to apply a square root of time transformation to the PDE, and discretize the resulting PDE with Crank-Nicolson. Two reasons come to mind to try this: the square root transform will result in small steps initially, where the solution is potentially not so smooth, making Crank-Nicolson behave better.&amp;nbsp;it is the natural time of the Brownian motion.</description>
    </item>
    <item>
      <title>Decoding Hagan&#39;s arbitrage free SABR PDE derivation</title>
      <link>https://chasethedevil.github.io/post/decoding-hagans-arbitrage-free-sabr-pde-derivation/</link>
      <pubDate>Fri, 08 May 2015 16:50:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/decoding-hagans-arbitrage-free-sabr-pde-derivation/</guid>
      <description>Here are the main steps of Hagan derivation. Let&#39;s recall his notation for the SABR model where typically, \\(C(F) = F^\beta\\) First, he defines the moments of stochastic volatility: Then he integrates the Fokker-Planck equation over all A, to obtain On the backward Komolgorov equation, he applies a Lamperti transform like change of variable: And then makes another change of variable so that the PDE has the same initial conditions for all moments: &amp;nbsp;This leads to It turns out that there is a magical symmetry for k=0 and k=2.</description>
    </item>
    <item>
      <title>Matching Hagan PDE SABR with the one-step Andreasen-Huge SABR</title>
      <link>https://chasethedevil.github.io/post/matching-hagan-pde-sabr-with-the-one-step-andreasen-huge-sabr/</link>
      <pubDate>Thu, 30 Apr 2015 17:16:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/matching-hagan-pde-sabr-with-the-one-step-andreasen-huge-sabr/</guid>
      <description>I looked nearly two years ago already at the arbitrage free SABR of Andreasen-Huge in comparison to the arbitrage free PDE of Hagan and showed how close the ideas were: Andreasen-Huge relies on the normal Dupire forward PDE using a slightly simpler local vol (no time dependent exponential term) while Hagan works directly on the Fokker-Planck PDE (you can think of it as the Dupire Forward PDE for the density) and uses an expansion of same order as the original SABR formula (which leads to an additional exponential term in the local volatility).</description>
    </item>
    <item>
      <title>Modern Programming Language for Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/modern-programming-language-for-monte-carlo/</link>
      <pubDate>Sat, 18 Apr 2015 22:58:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/modern-programming-language-for-monte-carlo/</guid>
      <description>A few recent programming languages sparked my interest:&#xA;Julia because of the wide coverage of mathematical functions, and great attention to quality of the implementations. It has also some interesting web interface. Dart: because it&amp;rsquo;s a language focused purely on building apps for the web, and has a supposedly good VM. Rust: it&amp;rsquo;s the latest fad. It has interesting concepts around concurrency and a focus on being low level all the while being simpler than C.</description>
    </item>
    <item>
      <title>Volatility Swap vs Variance Swap Replication - Truncation</title>
      <link>https://chasethedevil.github.io/post/volatility-swap-vs-variance-swap-replication---truncation/</link>
      <pubDate>Mon, 16 Mar 2015 14:39:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/volatility-swap-vs-variance-swap-replication---truncation/</guid>
      <description>I have looked at jump effects on volatility vs. variance swaps. There is a similar behavior on tail events, that is, on truncating the replication. One main problem with discrete replication of variance swaps is the implicit domain truncation, mainly because the variance swap equivalent log payoff is far from being linear in the wings. The equivalent payoff with Carr-Lee for a volatility swap is much more linear in the wings (not so far of a straddle).</description>
    </item>
    <item>
      <title>Arbitrage free SABR with negative rates - alternative to shifted SABR</title>
      <link>https://chasethedevil.github.io/post/arbitrage-free-sabr-with-negative-rates---alternative-to-shifted-sabr/</link>
      <pubDate>Wed, 11 Mar 2015 18:48:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/arbitrage-free-sabr-with-negative-rates---alternative-to-shifted-sabr/</guid>
      <description>Antonov et al. present an interesting view on SABR with negative rates: instead of relying on a shifted SABR to allow negative rates up to a somewhat arbitrary shift, they modify slightly the SABR model to allow negative rates directly: $$ dF_t = |F_t|^\beta v_t dW_F $$ with \\( v\_t \\) being the standard lognormal volatility process of SABR.&#xA;Furthermore they derive a clever semi-analytical approximation for this model, based on low correlation, quite close to the Monte-Carlo prices in their tests.</description>
    </item>
    <item>
      <title>Variance swaps on a foreign asset</title>
      <link>https://chasethedevil.github.io/post/variance-swaps-on-a-foreign-asset/</link>
      <pubDate>Tue, 24 Feb 2015 13:50:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/variance-swaps-on-a-foreign-asset/</guid>
      <description>There is very little information on variance swaps on a foreign asset. There can be two kinds of contracts:&#xA;one that pays the foreign variance in a domestic currency, this is a quanto contract as the exchange rate is implicitly fixed.one that pays the foreign variance, multiplied by the fx rate at maturity. This is a flexo contract, and is just about buying a variance swap from a foreign bank.</description>
    </item>
    <item>
      <title>Jumps impact: Variance swap vs volatility swap</title>
      <link>https://chasethedevil.github.io/post/jumps-impact-variance-swap-vs-volatility-swap/</link>
      <pubDate>Fri, 20 Feb 2015 13:24:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/jumps-impact-variance-swap-vs-volatility-swap/</guid>
      <description>Beside the problem with the discreteness of the replication, variance swaps are sensitive to jumps. This is an often mentioned reason for the collapse of the single name variance swap market in 2008 as jumps are more likely on single name equities.&#xA;Those graphs are the result of Monte-Carlo simulations with various jump sizes using the Bates model, and using Local Volatility implied from the Bates vanilla prices. The local volatility price will be the same price as per static replication for the variance swap, and we can see it they converge when there is no jump.</description>
    </item>
    <item>
      <title>Variance Swap Replication : Discrete or Continuous?</title>
      <link>https://chasethedevil.github.io/post/variance-swap-replication--discrete-or-continuous/</link>
      <pubDate>Thu, 19 Feb 2015 18:45:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/variance-swap-replication--discrete-or-continuous/</guid>
      <description>People regularly believe that Variance swaps need to be priced by discrete replication, because the market trades only a discrete set of options.&#xA;In reality, a discrete replication will misrepresent the tail, and can be quite arbitrary. It looks like the discrete replication as described in Derman Goldman Sachs paper is in everybody&#39;s mind, probably because it&#39;s easy to grasp. Strangely, it looks like most forget the section &#34;Practical problems with replication&#34;</description>
    </item>
    <item>
      <title>Monte Carlo &amp; Inverse Cumulative Normal Distribution</title>
      <link>https://chasethedevil.github.io/post/monte-carlo--inverse-cumulative-normal-distribution/</link>
      <pubDate>Tue, 03 Feb 2015 14:53:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/monte-carlo--inverse-cumulative-normal-distribution/</guid>
      <description>In most financial Monte-Carlo simulations, there is the need of generating normally distributed random numbers. One technique is to use the inverse cumulative normal distribution function on uniform random numbers. There are several different popular numerical implementations:&#xA;Wichura AS241 (1988)Moro &#34;The full Monte&#34; (1995)Acklam (2004)Shaw breakless formula optimized for GPUs (2011) W. Shaw has an excellent overview of the accuracy of the various methods in his paper Refinement of the normal quantile.</description>
    </item>
    <item>
      <title>Local Stochastic Volatility - Particles and Bins</title>
      <link>https://chasethedevil.github.io/post/local-stochastic-volatility---particles-and-bins/</link>
      <pubDate>Fri, 30 Jan 2015 12:03:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/local-stochastic-volatility---particles-and-bins/</guid>
      <description>In an earlier post, I mentioned the similarities between the Guyon-Labordere particle method and the Vanderstoep-Grzelak-Oosterlee &amp;ldquo;bin&amp;rdquo; method to calibrate and price under Local Stochastic volatility. I will be a bit more precise here. The same thing, really&#xA;The particle method can be seen as a generalization of the &amp;ldquo;bin&amp;rdquo; method. In deed, the bin method consists in doing the particle method using a histogram estimation of the conditional variance. The histogram estimation can be more or less seen as a very basic rectangle kernel with the appropriate bandwidth.</description>
    </item>
    <item>
      <title>Flat Volatility Surfaces &amp; Discrete Dividends</title>
      <link>https://chasethedevil.github.io/post/flat-volatility-surfaces--discrete-dividends/</link>
      <pubDate>Tue, 25 Nov 2014 13:58:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/flat-volatility-surfaces--discrete-dividends/</guid>
      <description>In papers around volatility and cash (discrete) dividends, we often encounter the example of the flat volatility surface. For example, the OpenGamma paper presents this graph:&#xA;It shows that if the Black volatility surface is fully flat, there are jumps in the pure volatility surface (corresponding to a process that includes discrete dividends in a consistent manner) at the dividend dates or equivalently if the pure volatility surface is flat, the Black volatility jumps.</description>
    </item>
    <item>
      <title>Machine Learning &amp; Quantitative Finance</title>
      <link>https://chasethedevil.github.io/post/machine-learning--quantitative-finance/</link>
      <pubDate>Tue, 18 Nov 2014 12:34:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/machine-learning--quantitative-finance/</guid>
      <description>There is an interesting course on Machine Learning on Coursera, it does not require much knowledge and yet manages to teach quite a lot.&#xA;I was struck by the fact that most techniques and ideas apply also to problems in quantitative finance.&#xA;Linear regression: used for example in the Longstaff-Schwartz approach to price Bermudan options with Monte-Carlo. Interestingly the teacher insists on feature normalization, something we can forget easily, especially with the polynomial features.</description>
    </item>
    <item>
      <title>Pseudo-Random vs Quasi-Random Numbers</title>
      <link>https://chasethedevil.github.io/post/pseudo-random-vs-quasi-random-numbers/</link>
      <pubDate>Wed, 12 Nov 2014 17:05:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/pseudo-random-vs-quasi-random-numbers/</guid>
      <description>Quasi-Random numbers (like Sobol) are a relatively popular way in finance to improve the Monte-Carlo convergence compared to more classic Pseudo-Random numbers (like Mersenne-Twister). Behind the scenes one has to be a bit more careful about the dimension of the problem as the Quasi-Random numbers depends on the dimension (defined by how many random variables are independent from each other).&#xA;For a long time, Sobol was limited to 40 dimensions using the so called Bratley-Fox direction numbers (his paper actually gives the numbers for 50 dimensions).</description>
    </item>
    <item>
      <title>Integrating an oscillatory function</title>
      <link>https://chasethedevil.github.io/post/integrating-an-oscillatory-function/</link>
      <pubDate>Wed, 05 Nov 2014 16:48:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/integrating-an-oscillatory-function/</guid>
      <description>Recently, some instabilities were noticed in the Carr-Lee seasoned volatility swap price in some situations. The Carr-Lee seasoned volatility swap price involve the computation of a double integral. The inner integral is really the problematic one as the integrand can be highly oscillating.&#xA;I&amp;nbsp; first found a somewhat stable behavior using a specific adaptive Gauss-Lobatto implementation (the one from Espelid) and a change of variable. But it was not very satisfying to see that the outer integral was stable only with another specific adaptive Gauss-Lobatto (the one from Gander &amp;amp; Gauschi, present in Quantlib).</description>
    </item>
    <item>
      <title>The elusive reference: the Lamperti transform</title>
      <link>https://chasethedevil.github.io/post/the-elusive-reference-the-lamperti-transform/</link>
      <pubDate>Mon, 03 Nov 2014 11:23:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-elusive-reference-the-lamperti-transform/</guid>
      <description>Without knowing that it was a well known general concept, I first noticed the use of the Lamperti transform in the Andersen-Piterbarg &amp;ldquo;Interest rate modeling&amp;rdquo; book p.292 &amp;ldquo;finite difference solutions for general phi&amp;rdquo;. Pat Hagan used that transformation for a better discretization of the arbitrage free SABR PDE model.I then started to notice the use of this transformation in many more papers. The first one I saw naming it &amp;ldquo;Lamperti transform&amp;rdquo; was the paper from Ait-Sahalia Maximum likelyhood estimation of discretely sampled diffusions: a closed-form approximation approach.</description>
    </item>
    <item>
      <title>Barrier options under negative rates: complex numbers to the rescue</title>
      <link>https://chasethedevil.github.io/post/barrier-options-under-negative-rates-complex-numbers-to-the-rescue/</link>
      <pubDate>Thu, 02 Oct 2014 11:58:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/barrier-options-under-negative-rates-complex-numbers-to-the-rescue/</guid>
      <description>I stumbled upon an unexpected problem: the one touch barrier formula can break down under negative rates. While negative rates can sound fancy, they are actually quite real on some markets. Combined with relatively low volatilities, this makes the standard Black-Scholes one touch barrier formula blow up because somewhere the square root of a negative number is taken.&#xA;At first, I had the idea to just floor the number to 0.</description>
    </item>
    <item>
      <title>Initial Guesses for SVI - A Summary</title>
      <link>https://chasethedevil.github.io/post/initial-guesses-for-svi---a-summary/</link>
      <pubDate>Fri, 26 Sep 2014 10:46:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/initial-guesses-for-svi---a-summary/</guid>
      <description>I have been looking at various ways of finding initial guesses for SVI calibration (Another SVI Initial Guess, More SVI Initial Guesses, SVI and long maturities issues). I decided to write a paper summarizing this. I find that the process of writing a paper makes me think more carefully about a problem.&#xA;In this case, it turns out that the Vogt initial guess method (guess via asymptotes and minimum variance) is actually very good as long as one has a good way to lookup the asymptotes (the data is not always convex, while SVI is) and as long as rho is not close to -1, that is for long maturity affine like smiles, where SVI is actually more difficult to calibrate properly due to the over-parameterisation in those cases.</description>
    </item>
    <item>
      <title>Asymptotic Behavior of SVI vs SABR</title>
      <link>https://chasethedevil.github.io/post/asymptotic-behavior-of-svi-vs-sabr/</link>
      <pubDate>Tue, 23 Sep 2014 12:06:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/asymptotic-behavior-of-svi-vs-sabr/</guid>
      <description>The variance under SVI becomes linear when the log-moneyness is very large in absolute terms. The lognormal SABR formula with beta=0 or beta=1 has a very different behavior. Of course, the theoretical SABR model has actually a different asymptotic behavior.&#xA;As an illustration, we calibrate SABR (with two different values of beta) and SVI against the same implied volatility slice and look at the wings behavior. While the Lee moments formula implies that the variance should be at most linear, something that the SABR formula does not respect.</description>
    </item>
    <item>
      <title>SVI and long maturities issues</title>
      <link>https://chasethedevil.github.io/post/svi-and-long-maturities-issues/</link>
      <pubDate>Fri, 01 Aug 2014 12:51:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/svi-and-long-maturities-issues/</guid>
      <description>On long maturities equity options, the smile is usually very much like a skew: very little curvature. This usually means that the SVI rho will be very close to -1, in a similar fashion as what can happen for the the correlation parameter of a real stochastic volatility model (Heston, SABR).&#xA;In terms of initial guess, I looked at the more usual use cases and showed that matching a parabola at the minimum variance point often leads to a decent initial guess if one has an ok estimate of the wings.</description>
    </item>
    <item>
      <title>More SVI Initial Guesses</title>
      <link>https://chasethedevil.github.io/post/more-svi-initial-guesses/</link>
      <pubDate>Thu, 31 Jul 2014 14:54:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/more-svi-initial-guesses/</guid>
      <description>In the previous post, I showed one could extract the SVI parameters from a best fit parabola at-the-money. It seemed to work reasonably well, but I found some real market data where it can be much less satisfying.&#xA;Sometimes (actually not so rarely) the ATM slope and curvatures can&#39;t be matched given rho and b found through the asymptotes. As a result if I force to just match the curvature and set m=0 (when the slope can&#39;t be matched), the simple ATM parabolic guess looks shifted.</description>
    </item>
    <item>
      <title>Another SVI Initial Guess</title>
      <link>https://chasethedevil.github.io/post/another-svi-initial-guess/</link>
      <pubDate>Tue, 29 Jul 2014 14:39:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/another-svi-initial-guess/</guid>
      <description>The SVI formula is:&#xA;$$w(k) = a + b ( \rho (k-m) + \sqrt{(k-m)^2+ \sigma^2}$$&#xA;where k is the log-moneyness, w(k) the implied variance at a given moneyness and a,b,rho,m,sigma the 5 SVI parameters.&#xA;A. Vogt described a particularly simple way to find an initial guess to fit SVI to an implied volatility slice a while ago. The idea to compute rho and sigma from the left and right asymptotic slopes.</description>
    </item>
    <item>
      <title>New SABR Formulae</title>
      <link>https://chasethedevil.github.io/post/new-sabr-formulae/</link>
      <pubDate>Wed, 16 Jul 2014 22:35:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/new-sabr-formulae/</guid>
      <description>In a talk at the Global Derivatives conference of Amsterdam (2014), Pat Hagan presented some new SABR formulas, supposedly close to the arbitrage free PDE behavior.&#xA;I tried to code those from the slides, but somehow that did not work out well on his example, I just had something very close to the good old SABR formulas. I am not 100% sure (only 99%) that it is due to a mistake in my code.</description>
    </item>
    <item>
      <title>Heston or Schobel-Zhu issues with short expiries</title>
      <link>https://chasethedevil.github.io/post/heston-or-schobel-zhu-issues-with-short-expiries/</link>
      <pubDate>Thu, 03 Jul 2014 23:28:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/heston-or-schobel-zhu-issues-with-short-expiries/</guid>
      <description>It&#39;s relatively well known that Heston does not fit the market for short expiries. Given that there are just 5 parameters to fit a full surface, it&#39;s almost logical that one part of the surface of it is not going to fit well the market.&#xA;I was more surprised to see how bad Heston or Schobel-Zhu were to fit a single short expiry volatility slice. As an example I looked at SP500 options with 1 week expiry.</description>
    </item>
    <item>
      <title>Moore-Penrose Inverse &amp; Gauss-Newton SABR Minimization</title>
      <link>https://chasethedevil.github.io/post/moore-penrose-inverse--gauss-newton-sabr-minimization/</link>
      <pubDate>Tue, 24 Jun 2014 15:29:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/moore-penrose-inverse--gauss-newton-sabr-minimization/</guid>
      <description>I have found a particularly nice initial guess to calibrate SABR. As it is quite close to the true best fit, it is tempting to use a very simple minimizer to go to the best fit. Levenberg-Marquardt works well on this problem, but can we shave off a few iterations?&#xA;I firstly considered the basic Newton&#39;s method, but for least squares minimization, the Hessian (second derivatives) is needed. It&#39;s possible to obtain it, even analytically with SABR, but it&#39;s quite annoying to derive it and code it without some automatic differentiation tool.</description>
    </item>
    <item>
      <title>On the importance of accuracy for bpvol solvers</title>
      <link>https://chasethedevil.github.io/post/on-the-importance-of-accuracy-for-bpvol-solvers/</link>
      <pubDate>Thu, 12 Jun 2014 17:31:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/on-the-importance-of-accuracy-for-bpvol-solvers/</guid>
      <description>While I was playing around calibrating the arbitrage free SABR model from Hagan (using the PDE on probability density approach), I noticed a misbehavior for some short maturity smiles. I thought it was due to the PDE implementation. Actually some of it was, but the remaining large error was due to the bpvol solver.&#xA;I initially took the same approach as Choi et al. in my solver, that is to work with in-the-money prices (they work with straddles) because it&amp;rsquo;s nice and convenient.</description>
    </item>
    <item>
      <title>Two SABR for the same smile</title>
      <link>https://chasethedevil.github.io/post/two-sabr-for-the-same-smile/</link>
      <pubDate>Tue, 20 May 2014 12:08:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/two-sabr-for-the-same-smile/</guid>
      <description>While playing around with differential evolution to calibrate SABR, I noticed that sometimes, several set of parameters can lead to a very similar smile, usually the good one is for relatively low vol of vol and the bad one is for relatively high vol of vol. I first looked for errors in my implementation, but it&amp;rsquo;s a real phenomenon. I used the normal implied volatility formula with beta=1, then converted it to lognormal (Black) volatility.</description>
    </item>
    <item>
      <title>Heston vs SABR slice by slice fit</title>
      <link>https://chasethedevil.github.io/post/heston-vs-sabr-slice-by-slice-fit/</link>
      <pubDate>Thu, 15 May 2014 22:06:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/heston-vs-sabr-slice-by-slice-fit/</guid>
      <description>Some people use Heston to fit one slice of a volatility surface. In this case, some parameters are clearly redundant. Still, I was wondering how it fared against SABR, which is always used to fit a slice. And what about Schobel-Zhu? Aggregated error in fit per slice on 10 surfaces With Heston, the calibration is actually slightly better with kappa=0, that is, without mean reversion, because the global optimization is easier and the mean reversion is fully redundant.</description>
    </item>
    <item>
      <title>Quadratic Spline with Knots at Mid-Points</title>
      <link>https://chasethedevil.github.io/post/quadratic-spline-with-knots-at-mid-points/</link>
      <pubDate>Wed, 14 May 2014 14:12:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/quadratic-spline-with-knots-at-mid-points/</guid>
      <description>Two months ago, I looked at arbitrage free interpolation using piecewise-constant density. This is equivalent to a piecewise quadratic polynomial in call prices where each piece is centered around each call strike.&#xA;I wondered at the time what a quadratic spline would look like on this problem, as it should be very close in theory, except that we can ensure that it is C1, a condition for a good looking implied volatility.</description>
    </item>
    <item>
      <title>Non-linear Option Pricing</title>
      <link>https://chasethedevil.github.io/post/non-linear-option-pricing/</link>
      <pubDate>Fri, 18 Apr 2014 22:18:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/non-linear-option-pricing/</guid>
      <description>I am currently reading the book &amp;ldquo;Nonlinear Option Pricing&amp;rdquo; by J. Guyon and P. Henry-Labord√®re. It&amp;rsquo;s quite interesting even if the first third is quite theoretical. For example they describe how to solve some not well defined non-linear parabolic PDE by relying on the parabolic envelope. They also explain why most problems lead to parabolic PDEs in finance.&#xA;The rest is a bit more practical. I stumbled upon an good remark regarding Longstaff-Schwartz: the algorithm as Longstaff and Schwarz describe it does not necessary lead to a low-biased estimate as they use future information (the paths they regress on) in the Monte-Carlo estimate.</description>
    </item>
    <item>
      <title>Building a more accurate basis point volatility formula</title>
      <link>https://chasethedevil.github.io/post/building-a-more-accurate-basis-point-volatility-formula/</link>
      <pubDate>Sat, 05 Apr 2014 15:42:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/building-a-more-accurate-basis-point-volatility-formula/</guid>
      <description>P. Jaeckel has defied the limits of accuracy with his latest Black-Scholes volatility solver, managing to also improve performance compared to his earlier solver &#34;By Implication&#34;. Out of a silly exercise, I decided to try my hand for a more accurate Normal (or basis point) volatility solver.&#xA;In reality, the problem is much simpler in the Bachelier/Normal model. A very basic analysis of Bachelier formula shows that the problem can be reduced to a single variable, as Choi et al explain in their paper.</description>
    </item>
    <item>
      <title>Fast and Accurate Implied Volatility Solver</title>
      <link>https://chasethedevil.github.io/post/fast-and-accurate-implied-volatility-solver/</link>
      <pubDate>Wed, 19 Mar 2014 18:10:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/fast-and-accurate-implied-volatility-solver/</guid>
      <description>The calibration of a stochastic volatility model or a volatility surface parameterization (like SVI) involves minimizing the model options volatilities against market options volatilities. Often, the model computes an option price, not an implied volatility. It is therefore useful to have a fast way to invert that option price to get back the implied volatility that corresponds to it. Furthermore during the calibration procedure, the model option price can vary widely: it is convenient to have a robust implied volatility solver.</description>
    </item>
    <item>
      <title>Arbitrage Free Interpolation of Option Prices using Piecewise Constant Density</title>
      <link>https://chasethedevil.github.io/post/arbitrage-free-interpolation-of-option-prices-using-piecewise-constant-density/</link>
      <pubDate>Mon, 17 Mar 2014 15:25:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/arbitrage-free-interpolation-of-option-prices-using-piecewise-constant-density/</guid>
      <description>Tension splines can produce in some cases arbitrage free C2 interpolation of options, but unfortunately this is not guaranteed. It turns out that, on some not so nice looking data, where the discrete probability density is not monotone but only positive, all previously considered interpolation fail (spline in volatility or variance, tension spline in log prices, harmonic spline on prices).K vol¬†put¬†b-slope¬†b-convexity300.0 0.682 0.090 0.00e+00 0.00e+00310.0 0.654 0.136 4.</description>
    </item>
    <item>
      <title>C2 Arbitrage Free Interpolation with Tension Splines</title>
      <link>https://chasethedevil.github.io/post/c2-arbitrage-free-interpolation-with-tension-splines/</link>
      <pubDate>Tue, 11 Mar 2014 17:05:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/c2-arbitrage-free-interpolation-with-tension-splines/</guid>
      <description>In a previous post, I have explored the arbitrage free wiggles in the volatility surface that P. Jaeckel found in his paper. I showed that interpolating in log prices instead of prices was enough to remove the wiggles, but then, it appears that the interpolation is not guaranteed to be arbitrage free, even though it often is. On another example from P. Jaeckel paper, that I reproduced inaccurately but well enough, it is not.</description>
    </item>
    <item>
      <title>Bachelier and Black-Scholes Fits of the Volatility Surface, what about SABR?</title>
      <link>https://chasethedevil.github.io/post/bachelier-and-black-scholes-fits-of-the-volatility-surface-what-about-sabr/</link>
      <pubDate>Fri, 07 Mar 2014 15:31:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/bachelier-and-black-scholes-fits-of-the-volatility-surface-what-about-sabr/</guid>
      <description>I always wondered if Bachelier was really worse than Black-Scholes in practice. As an experiment I fit various implied volatility surfaces with Bachelier and Black-Scholes and look at the average error in implied volatility by slice.&#xA;In theory Bachelier is appealing because slightly simpler: log returns are a bit more challenging to think about than returns. And it also takes indirectly into account the fact that OTM calls are less likely than OTM puts because of default risk, if you assume absorbing probability at strike 0.</description>
    </item>
    <item>
      <title>Arbitrage Free Wiggles</title>
      <link>https://chasethedevil.github.io/post/arbitrage-free-wiggles/</link>
      <pubDate>Mon, 03 Mar 2014 17:13:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/arbitrage-free-wiggles/</guid>
      <description>Peter Jaeckel, in a recent paper (pdf), shows that something that sounds like a reasonable arbitrage free interpolation can produce wiggles in the implied volatility slice.&#xA;The interpolation in question is using some convexity preserving spline on call and put option prices directly and in strike, assuming those input prices are arbitrage free. This is very similar to Kahale interpolation (pdf).&#xA;It seemed too crazy for me so I had to try out his example.</description>
    </item>
    <item>
      <title>Adjoint Delta for Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/adjoint-delta-for-monte-carlo/</link>
      <pubDate>Tue, 25 Feb 2014 18:37:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/adjoint-delta-for-monte-carlo/</guid>
      <description>In an earlier post, I have been quickly exploring adjoint differentiation in the context of analytical Black-Scholes. Today, I tried to mix it in a simple Black-Scholes Monte-Carlo as described in L. Capriotti paper, and measured the performance to compute delta compared to a numerical single sided finite difference delta.I was a bit surprised that even on a single underlying, without any real optimization, adjoint delta was faster by a factor of nearly 40%.</description>
    </item>
    <item>
      <title>SVI on top of SABR</title>
      <link>https://chasethedevil.github.io/post/svi-on-top-of-sabr/</link>
      <pubDate>Thu, 20 Feb 2014 18:36:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/svi-on-top-of-sabr/</guid>
      <description>Several papers show that the limit for large strikes of Heston is SVI.&#xA;Interestingly, I stumbled onto a surface where the Hagan SABR fit was perfect as well as the SVI fit, while the Heston fit was not.&#xA;Originally, I knew that, on this data, the SVI fit was perfect. Until today, I just never tried to fit a lognormal SABR on the same data. I did a small test with random values of the SABR parameters alpha, rho, nu, and found out that in deed, the SVI fit is always perfect on SABR.</description>
    </item>
    <item>
      <title>Smart Initial Guess for Schobel-Zhu</title>
      <link>https://chasethedevil.github.io/post/smart-initial-guess-for-schobel-zhu/</link>
      <pubDate>Wed, 19 Feb 2014 18:57:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/smart-initial-guess-for-schobel-zhu/</guid>
      <description>With a small time expansion, it is easy to derive a reasonable initial guess, without resorting to some global minimizer.&#xA;Like Forde did for Heston, one can find the 5 Schobel-Zhu parameters through 5 points at coordinates (0,0), (x0,t1), (-x0,t1), (x0,t2), (-x0,t2), where x0 is a chosen the log-moneyness, for example, 0.1 and t1, t2 relatively short expiries (for example, 0.1, 0.25).&#xA;We can truncate the small time expansion so that the polynomial in (x,t) is fully captured by those 5 points.</description>
    </item>
    <item>
      <title>A Look at Small Time Expansions for Heston</title>
      <link>https://chasethedevil.github.io/post/a-look-at-small-time-expansions-for-heston/</link>
      <pubDate>Wed, 12 Feb 2014 13:13:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-look-at-small-time-expansions-for-heston/</guid>
      <description>Small time expansions for Heston can be useful during the calibration of the implied volatility surface, in order to find an initial guess for a local minimizer (for example, Levenberg-Marquardt). Even if they are not so accurate, they capture the dynamic of the model parameters, and that is often enough.&#xA;In 2011, Forde et al. proposed a second order small time expansion around the money, which I found to work well for calibration.</description>
    </item>
    <item>
      <title>A Small-Time Schobel-Zhu Expansion</title>
      <link>https://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/</link>
      <pubDate>Mon, 10 Feb 2014 18:30:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/</guid>
      <description>The paper implied vol for any local stochastic vol model from Lorig et al. presents a very generic and simple formula to compute implied volatility expansions up to order-2 (there is actually an order-3 formula available in their Mathematica CDF file).&#xA;I tried it on the Schobel-Zhu stochastic volatility model. This model is an interesting alternative to Heston. I found that, in practice, the implied volatility surface fit was as good, while the simulation under the QE scheme is quite faster (and simpler) than Heston.</description>
    </item>
    <item>
      <title>Brownian Bridge or Not with Heston Quadratic Exponential QMC</title>
      <link>https://chasethedevil.github.io/post/brownian-bridge-or-not-with-heston-quadratic-exponential-qmc/</link>
      <pubDate>Fri, 24 Jan 2014 19:35:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/brownian-bridge-or-not-with-heston-quadratic-exponential-qmc/</guid>
      <description>At first I did not make use of the Brownian Bridge technique in Heston QMC, because the variance process is not simulated like a Brownian Motion under the Quadratic Exponential algorithm from Andersen.&#xA;It is, however, perfectly possible to use the Brownian Bridge on the asset process. Does it make a difference? In my small test, it does not seem to make a difference. An additional question would be, is it better to take first N for the asset and next N for the variance or vice versa or intertwined?</description>
    </item>
    <item>
      <title>Adjoint Algorithmic Differentiation for Black-Scholes</title>
      <link>https://chasethedevil.github.io/post/adjoint-algorithmic-differentiation-for-black-scholes/</link>
      <pubDate>Tue, 21 Jan 2014 13:03:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/adjoint-algorithmic-differentiation-for-black-scholes/</guid>
      <description>Adjoint algorithmic differentiation is particularly interesting in finance as we often encounter the case of a function that takes many input (the market data) and returns one output (the price) and we would like to also compute sensitivities (greeks) to each input.&#xA;As I am just starting around it, to get a better grasp, I first tried to apply the idea to the analytic knock out barrier option formula, by hand, only to find out I was making way too many errors by hand to verify anything.</description>
    </item>
    <item>
      <title>Placing the Strike on the Grid and Payoff Smoothing in Finite Difference Methods for Vanilla Options</title>
      <link>https://chasethedevil.github.io/post/placing-the-strike-on-the-grid-and-payoff-smoothing-in-finite-difference-methods-for-vanilla-options/</link>
      <pubDate>Sun, 12 Jan 2014 16:27:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/placing-the-strike-on-the-grid-and-payoff-smoothing-in-finite-difference-methods-for-vanilla-options/</guid>
      <description>Pooley et al., in Convergence Remedies for non-smooth payoffs in option pricing suggest that placing the strike on the grid for a Vanilla option is good enough:&#xA;At the same time, Tavella and Randall show in their book that numerically, placing the strike in the middle of two nodes leads to a more accurate result. My own numerical experiments confirm Tavella and Randall suggestion.&#xA;In reality, what Pooley et al.</description>
    </item>
    <item>
      <title>Coordinate Transform of the Andreasen Huge SABR PDE &amp; Spline Interpolation</title>
      <link>https://chasethedevil.github.io/post/coordinate-transform-of-the-andreasen-huge-sabr-pde--spline-interpolation/</link>
      <pubDate>Wed, 08 Jan 2014 18:51:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/coordinate-transform-of-the-andreasen-huge-sabr-pde--spline-interpolation/</guid>
      <description>Recently, I noticed how close are the two PDE based approaches from Andreasen-Huge and Hagan for an arbitrage free SABR. Hagan gives a local volatility very close to the one Andreasen-Huge use in the forward PDE in call prices. A multistep Andreasen-Huge (instead of their one step PDE method) gives back prices and densities nearly equal to Hagan density based approach.&#xA;Hagan proposed in some unpublished paper a coordinate transformation for two reasons: the ideal range of strikes for the PDE can be very large, and concentrating the points where it matters should improve stability and accuracy.</description>
    </item>
    <item>
      <title>Levenberg Marquardt &amp; Constraints by Domain Transformation</title>
      <link>https://chasethedevil.github.io/post/levenberg-marquardt--constraints-by-domain-transformation/</link>
      <pubDate>Tue, 17 Dec 2013 15:27:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/levenberg-marquardt--constraints-by-domain-transformation/</guid>
      <description>The Fortran minpack library has a good Levenberg-Marquardt minimizer, so good, that it has been ported to many programming languages. Unfortunately it does not support contraints, even simple bounds.&#xA;One way to achieve this is to transform the domain via a bijective function. For example, \(a+\frac{b-a}{1+e^{-\alpha t}}\) will transform \(]-\infty, +\infty[\) to ]a,b[. Then how should one choose \(\alpha\)?&#xA;A large \(\alpha\) will make tiny changes in \(t\) appear large.</description>
    </item>
    <item>
      <title>Arbitrage Free SABR - Another View on Hagan Approach</title>
      <link>https://chasethedevil.github.io/post/arbitrage-free-sabr---another-view-on-hagan-approach/</link>
      <pubDate>Sat, 14 Dec 2013 00:56:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/arbitrage-free-sabr---another-view-on-hagan-approach/</guid>
      <description>Several months ago, I took a look at two interesting recent ways to price under SABR with no arbitrage:&#xA;One way is due to Andreasen and Huge, where they find an equivalent local volatility expansion, and then use a one-step finite difference technique to price. The other way is due to Hagan himself, where he numerically solves an approximate PDE in the probability density, and then price with options by integrating on this density.</description>
    </item>
    <item>
      <title>American Option on Forward/Futures</title>
      <link>https://chasethedevil.github.io/post/american-option-on-forwardfutures/</link>
      <pubDate>Thu, 21 Nov 2013 11:17:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/american-option-on-forwardfutures/</guid>
      <description>Prices of a Future contract and a Forward contract are the same under the Black-Scholes assumptions (deterministic rates) but the price of options on Futures or options on Forwards might still differ. I did not find this obvious at first.&#xA;For example, when the underlying contract expiration date (Futures, Forward) is different from the option expiration date. For a Future Option, the Black-76 formula can be used, the discounting is done from the option expiry date, because one receives the cash on expiration due to the margin account.</description>
    </item>
    <item>
      <title>Spikes in Heston/Schobel-Zhu Local Volatility</title>
      <link>https://chasethedevil.github.io/post/spikes-in-hestonschobel-zhu-local-volatility/</link>
      <pubDate>Wed, 20 Nov 2013 13:33:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/spikes-in-hestonschobel-zhu-local-volatility/</guid>
      <description>Using precise vanilla option pricing engine for Heston or Schobel-Zhu, like the Cos method with enough points and a large enough truncation can still lead to spikes in the Dupire local volatility (using the variance based formula).&#xA;Local volatility Implied volatility The large spikes in the local volatility 3d surface are due to constant extrapolation, but there are spikes even way before the extrapolation takes place at longer maturities. Even if the Cos method is precise, it seems to be not enough, especially for large strikes so that the second derivative over the strike combined with the first derivative over time can strongly oscillate.</description>
    </item>
    <item>
      <title>Local Stochastic Volatility with Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/local-stochastic-volatility-with-monte-carlo/</link>
      <pubDate>Wed, 16 Oct 2013 16:14:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/local-stochastic-volatility-with-monte-carlo/</guid>
      <description>I always imagined local stochastic volatility to be complicated, and thought it would be very slow to calibrate.&#xA;After reading a bit about it, I noticed that the calibration phase could just consist in calibrating independently a Dupire local volatility model and a stochastic volatility model the usual way.&#xA;One can then choose to compute on the fly the local volatility component (not equal the Dupire one, but including the stochastic adjustment) in the Monte-Carlo simulation to price a product.</description>
    </item>
    <item>
      <title>Heston, Schobel-Zhu, Bates, Double-Heston Fit</title>
      <link>https://chasethedevil.github.io/post/heston-schobel-zhu-bates-double-heston-fit/</link>
      <pubDate>Mon, 07 Oct 2013 19:35:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/heston-schobel-zhu-bates-double-heston-fit/</guid>
      <description>I did some experiments fitting Heston, Schobel-Zhu, Bates and Double-Heston to a real world equity index implied volatility surface. I used a global optimizer (differential evolution).&#xA;To my surprise, the Heston fit is quite good: the implied volatility error is less than 0.42% on average. Schobel-Zhu fit is also good (0.47% RMSE), but a bit worse than Heston. Bates improves quite a bit on Heston although it has 3 more parameters, we can see the fit is better for short maturities (0.</description>
    </item>
    <item>
      <title>Second Cumulant of Heston</title>
      <link>https://chasethedevil.github.io/post/second-cumulant-of-heston/</link>
      <pubDate>Thu, 03 Oct 2013 17:27:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/second-cumulant-of-heston/</guid>
      <description>I recently stumbled upon an error in the various papers related to the Heston Cos method regarding the second cumulant. It is used to define the boundaries of the Cos method. Letting phi be Heston characteristic function, the cumulant generating function is: $$g(u) = \log(\phi(-iu))$$&#xA;And the second cumulant is defined a: $$c_2 = g&amp;rsquo;&amp;rsquo;(0)$$Compared to a numerical implementation, the c_2 from the paper is really off in many use cases.</description>
    </item>
    <item>
      <title>Maxima for Symbolic Calculus</title>
      <link>https://chasethedevil.github.io/post/maxima-for-symbolic-calculus/</link>
      <pubDate>Wed, 02 Oct 2013 15:06:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/maxima-for-symbolic-calculus/</guid>
      <description>A few years ago, I found an interesting open source symbolic calculus software called Xcas. It can however be quickly limited, for example, it does not seem to work well to compute Taylor expansions with several embedded functions. Google pointed me to another popular open source package, Maxima. It looks a bit rudimentary (command like interface), but formulas can actually be very easily exported to latex with the tex command. Here is a simple example:</description>
    </item>
    <item>
      <title>Making Classic Heston Integration Faster than the Cos Method</title>
      <link>https://chasethedevil.github.io/post/making-classic-heston-integration-faster-than-the-cos-method/</link>
      <pubDate>Thu, 05 Sep 2013 17:35:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/making-classic-heston-integration-faster-than-the-cos-method/</guid>
      <description>A coworker pointed to me that Andersen and Piterbarg book &amp;ldquo;Interest Rate Modeling&amp;rdquo; had a chapter on Fourier integration applied to Heston. The authors rely on the Lewis formula to price vanilla call options under Heston. Lewis formula More importantly, they strongly advise the use of a Black-Scholes control variate. I had read about that idea before, and actually tried it in the Cos method, but it did not improve anything for the Cos method.</description>
    </item>
    <item>
      <title>Attari, Lord-Kahl &amp; Cos Methods Comparison on Heston</title>
      <link>https://chasethedevil.github.io/post/attari-lord-kahl--cos-methods-comparison-on-heston/</link>
      <pubDate>Wed, 28 Aug 2013 17:54:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/attari-lord-kahl--cos-methods-comparison-on-heston/</guid>
      <description>I recently wrote about the Cos method. While rereading the various papers on Heston semi-analytical pricing, especially the nice summary by Schmelzle, it struck me how close were the Attari/Bates methods and the Cos method derivations. I then started wondering if Attari was really much worse than the Cos method or not.&#xA;I noticed that Attari method accuracy is directly linked to the underlying Gaussian quadrature method accuracy. I found that the doubly adaptive Newton-Cotes quadrature by Espelid (coteda) was the most accurate/fastest on this problem (compared to Gauss-Laguerre/Legendre/Extrapolated Simpson/Lobatto).</description>
    </item>
    <item>
      <title>Julia and the Cumulative Normal Distribution</title>
      <link>https://chasethedevil.github.io/post/julia-and-the-cumulative-normal-distribution/</link>
      <pubDate>Tue, 13 Aug 2013 15:52:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/julia-and-the-cumulative-normal-distribution/</guid>
      <description>I just stumbled upon Julia, a new programming language aimed at numerical computation. It&amp;rsquo;s quite new but it looks very interesting, with the promise of C like performance (thanks to LLVM compilation) with a much nicer syntax and parallelization features.Out of curiosity, I looked at their cumulative normal distribution implementation. I found that the (complimentary) error function (directly related to the cumulative normal distribution) algorithm relies on an algorithm that can be found in the Faddeeva library.</description>
    </item>
    <item>
      <title>The COS method for Heston</title>
      <link>https://chasethedevil.github.io/post/the-cos-method-for-heston/</link>
      <pubDate>Fri, 02 Aug 2013 14:19:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-cos-method-for-heston/</guid>
      <description>Fang, in her thesis, has the idea of the COS method and applies it to Heston. There are several published papers around it to price options under various models that have a known characteristic function, as well as to price more exotic options like barriers or bermudans.&#xA;The COS method is very close to the more standard Heston quasi analytic formula (use transform of characteristic function for the density and integrates the payoff with the density, exchanging summation), except that the more simple Fourier series are used instead of the standard Fourier transform.</description>
    </item>
    <item>
      <title>Octave vs Scilab for PDEs in Finance</title>
      <link>https://chasethedevil.github.io/post/octave-vs-scilab-for-pdes-in-finance/</link>
      <pubDate>Tue, 30 Jul 2013 12:10:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/octave-vs-scilab-for-pdes-in-finance/</guid>
      <description>I was used to Scilab for small experiments involving linear algebra. I also like some of Scilab choices in algorithms: for example it provides PCHIM monotonic spline algorithm, and uses Cody for the cumulative normal distribution.&#xA;Matlab like software is particularly well suited to express PDE solvers in a relatively concise manner. To illustrate some of my experiments, I started to write a Scilab script for the Arbitrage Free SABR problem.</description>
    </item>
    <item>
      <title>The CUDA Performance Myth II</title>
      <link>https://chasethedevil.github.io/post/the-cuda-performance-myth-ii/</link>
      <pubDate>Fri, 12 Jul 2013 15:23:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-cuda-performance-myth-ii/</guid>
      <description>This is a kind of following to the CUDA performance myth. There is a recent news on the java concurrent mailing list about SplittableRandom class proposed for JDK8. It is a new parallel random number generator a priori usable for Monte-Carlo simulations.&#xA;It seems to rely on some very recent algorithm. There are some a bit older ones: the ancestor, L&amp;rsquo;Ecuyer MRG32k3a that can be parallelized through relatively costless skipTo methods, a Mersenne Twister variant MTGP, and even the less rigourous XorWow popularized by NVidia CUDA.</description>
    </item>
    <item>
      <title>Bessel and Harmonic Kinks in the Forward</title>
      <link>https://chasethedevil.github.io/post/bessel-and-harmonic-kinks-in-the-forward/</link>
      <pubDate>Tue, 02 Jul 2013 15:44:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/bessel-and-harmonic-kinks-in-the-forward/</guid>
      <description>As Bessel (sometimes called Hermite) spline interpolation is only C1, like the Harmonic spline from Fritsch-Butland, the forward presents small kinks compared to a standard cubic spline. Hyman filtering also creates a kink where it fixes the monotonicity. Those are especially visible with a log scale in time. Here is how it looks on the Hagan-West difficult curve.</description>
    </item>
    <item>
      <title>The Finite Difference Theta Scheme Optimal Theta</title>
      <link>https://chasethedevil.github.io/post/the-finite-difference-theta-scheme-optimal-theta/</link>
      <pubDate>Tue, 18 Jun 2013 15:02:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-finite-difference-theta-scheme-optimal-theta/</guid>
      <description>The theta finite difference scheme is a common generalization of Crank-Nicolson. In finance, the book from Wilmott, a paper from A. Sepp, one from Andersen-Ratcliffe present it. Most of the time, it&amp;rsquo;s just a convenient way to handle implicit \(\theta=1\), explicit \(\theta=0\) and Crank-Nicolson \(\theta=0.5\) with the same algorithm.&#xA;Wilmott makes an interesting remark: one can choose a theta that will cancel out higher order terms in the local truncation error and therefore should lead to increased accuracy.</description>
    </item>
    <item>
      <title>Akima for Yield Curve Interpolation ?</title>
      <link>https://chasethedevil.github.io/post/akima-for-yield-curve-interpolation-/</link>
      <pubDate>Mon, 03 Jun 2013 00:07:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/akima-for-yield-curve-interpolation-/</guid>
      <description>On my test of yield curve interpolations, focusing on parallel delta versus sequential delta, Akima is the worst of the lot. I am not sure why this interpolation is still popular when most alternatives seem much better. Hyman presented some of the issues with Akima in his paper in 1983. In the following graph, a higher value is a higher parallel-vs-sequential difference. That plus the Hagan-West example of a tricky curve looks a bit convoluted with it (although it does not have any negative forward).</description>
    </item>
    <item>
      <title>2 Ways for an Accurate Barrier with Finite Difference </title>
      <link>https://chasethedevil.github.io/post/2-ways-for-an-accurate-barrier-with-finite-difference/</link>
      <pubDate>Sun, 02 Jun 2013 00:46:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/2-ways-for-an-accurate-barrier-with-finite-difference/</guid>
      <description>I had explored the issue of pricing a barrier using finite difference discretization of the Black-Scholes PDE a few years ago. Briefly, for explicit schemes, one just need to place the barrier on the grid and not worry about much else, but for implicit schemes, either the barrier should be placed on the grid and the grid&amp;nbsp; truncated at the barrier, or a fictitious point should be introduced to force the correct price at the barrier level (0, typically).</description>
    </item>
    <item>
      <title>SABR with the new Hagan PDE Approach</title>
      <link>https://chasethedevil.github.io/post/sabr-with-the-new-hagan-pde-approach/</link>
      <pubDate>Tue, 28 May 2013 15:56:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/sabr-with-the-new-hagan-pde-approach/</guid>
      <description>At a presentation of the Thalesians, Hagan has presented a new PDE based approach to compute arbitrage free prices under SABR. This is similar in spirit as Andreasen-Huge, but the PDE is directly on the density, not on the prices, and there is no one-step procedure: it&#39;s just like a regular PDE with proper boundary conditions.&#xA;I was wondering how it compared to Andreasen Huge results.&#xA;My first implementation was quite slow.</description>
    </item>
    <item>
      <title>SABR with Andreasen-Huge</title>
      <link>https://chasethedevil.github.io/post/sabr-with-andreasen-huge/</link>
      <pubDate>Fri, 24 May 2013 14:17:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/sabr-with-andreasen-huge/</guid>
      <description>I am on holiday today. Unfortunately I am still thinking about work-related matters, and out of curiosity, wanted to do a little experiment. I know it is not very good to spend free time on work related stuff: there is no reward for it, and there is so much more to life. Hopefully it will be over after this post.&#xA;Around 2 years ago, I saw a presentation from Andreasen and Huge about how they were able to price/calibrate SABR by a one-step finite difference technique.</description>
    </item>
    <item>
      <title>Large Steps in Schobel-Zhu/Heston the Lazy Way</title>
      <link>https://chasethedevil.github.io/post/large-steps-in-schobel-zhuheston-the-lazy-way/</link>
      <pubDate>Fri, 17 May 2013 12:46:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/large-steps-in-schobel-zhuheston-the-lazy-way/</guid>
      <description>Van Haastrecht, Lord and Pelsser present an effective way to price derivatives by Monte-Carlo under the Schobel-Zhu model (as well as under the Schobel-Zhu-Hull-White model). It&#39;s quite similar to Andersen QE scheme for Heston in spirit.&#xA;In their paper they evolve the (log) asset process together with the volatility process, using the same discretization times. A while ago, when looking at&amp;nbsp; Joshi and Chan large steps for Heston, I noticed that, inspired by Broadie-Kaya exact Heston scheme, they present the idea to evolve the variance process using small steps and the asset process using large steps (depending on the payoff) using the integrated variance value computed by small steps.</description>
    </item>
    <item>
      <title>Exact Forward in Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/exact-forward-in-monte-carlo/</link>
      <pubDate>Mon, 13 May 2013 17:58:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/exact-forward-in-monte-carlo/</guid>
      <description>Where I work, there used to be quite a bit of a confusion on which rates one should use as input to a Local Volatility Monte-Carlo simulation.&#xA;In particular there is a paper in the Journal of Computation Finance by Andersen and Ratcliffe &amp;ldquo;The Equity Option Volatility Smile: a Finite Difference Approach&amp;rdquo; which explains one should use specially tailored rates for the finite difference scheme in order to reproduce exact Bond price and exact Forward contract prices</description>
    </item>
    <item>
      <title>Quasi Monte Carlo in Finance</title>
      <link>https://chasethedevil.github.io/post/quasi-monte-carlo-in-finance/</link>
      <pubDate>Mon, 13 May 2013 13:16:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/quasi-monte-carlo-in-finance/</guid>
      <description>I have been wondering if there was any better alternative than the standard Sobol (+ Brownian Bridge) quasi random sequence generator for the Monte Carlo simulations of finance derivatives.&#xA;Here is what I found:&#xA;Scrambled Sobol. The idea is to rerandomize the quasi random numbers slightly. It can provide better uniformity properties and allows for a real estimate of the standard error. There are many ways to do that. The simple Cranley Patterson rotation consisting in adding a pseudo random number modulo 1, Owen scrambling (permutations of the digits) and simplifications of it to achieve a reasonable speed.</description>
    </item>
    <item>
      <title>Upper Bounds in American Monte-Carlo</title>
      <link>https://chasethedevil.github.io/post/upper-bounds-in-american-monte-carlo/</link>
      <pubDate>Tue, 30 Apr 2013 17:05:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/upper-bounds-in-american-monte-carlo/</guid>
      <description>Glasserman and Yu (GY) give a relatively simple algorithm to compute lower and upper bounds of a the price of a Bermudan Option through Monte-Carlo.&#xA;I always thought it was very computer intensive to produce an upper bound, and that the standard Longstaff Schwartz algorithm was quite precise already. GY algorithm is not much slower than the Longstaff-Schwartz algorithm, but what&#39;s a bit tricky is the choice of basis functions: they have to be Martingales.</description>
    </item>
    <item>
      <title>Quasi Monte-Carlo &amp; Longstaff-Schwartz American Option price</title>
      <link>https://chasethedevil.github.io/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/</link>
      <pubDate>Mon, 22 Apr 2013 18:00:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/</guid>
      <description>In the book Monte Carlo Methods in Financial Engineering, Glasserman explains that if one reuses the paths used in the optimization procedure for the parameters of the exercise boundary (in this case the result of the regression in Longstaff-Schwartz method) to compute the Monte-Carlo mean value, we will introduce a bias: the estimate will be biased high because it will include knowledge about future paths.&#xA;However Longstaff and Schwartz seem to just reuse the paths in their paper, and Glasserman himself, when presenting Longstaff-Schwartz method later in the book just use the same paths for the regression and to compute the Monte-Carlo mean value.</description>
    </item>
    <item>
      <title>A Fast Exponential Function in Java</title>
      <link>https://chasethedevil.github.io/post/a-fast-exponential-function-in-java/</link>
      <pubDate>Fri, 19 Apr 2013 16:48:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-fast-exponential-function-in-java/</guid>
      <description>In finance, because one often dicretize the log process instead of the direct process for Monte-Carlo simulation, the Math.exp function can be called a lot (millions of times for a simulation) and can be a bottleneck. I have noticed that the simpler Euler discretization was for local volatility Monte-Carlo around 30% faster, because it avoids the use of Math.exp.&#xA;Can we improve the speed of exp over the JDK one?</description>
    </item>
    <item>
      <title>Root finding in Lord Kahl Method to Compute Heston Call Price (Part III)</title>
      <link>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price-part-iii/</link>
      <pubDate>Fri, 12 Apr 2013 13:41:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price-part-iii/</guid>
      <description>I forgot two important points in my previous post about Lord-Kahl method to compute the Heston call price:&#xA;Scaling: scaling the call price appropriately allows to increase the maximum precision significantly, because the Carr-Madan formula operates on log(Forward) and log(Strike) directly, but not the ratio, and alpha is multiplied by the log(Forward). I simply scale by the spot, the call price is (S_0*max(S/S_0-K/S0)). Here are the results for Lord-Kahl, Kahl-Jaeckel (the more usual way limited to machine epsilon accuracy), Forde-Jacquier-Lee ATM implied volatility without scaling for a maturity of 1 day: Strike Lord-Kahl Kahl-Jaeckel Forde-Jacquier-Lee 62.</description>
    </item>
    <item>
      <title>Root finding in Lord Kahl Method to Compute Heston Call Price (Part II)</title>
      <link>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price-part-ii/</link>
      <pubDate>Thu, 11 Apr 2013 16:29:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price-part-ii/</guid>
      <description>In my previous post, I explored the Lord-Kahl method to compute the call option prices under the Heston model. One of the advantages of this method is to go beyond machine epsilon accuracy and be able to compute very far out of the money prices or very short maturities. The standard methods to compute the Heston price are based on a sum/difference where both sides are far from 0 and will therefore be limited to less than machine epsilon accuracy even if the integration is very precise.</description>
    </item>
    <item>
      <title>Root finding in Lord Kahl Method to Compute Heston Call Price</title>
      <link>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price/</link>
      <pubDate>Tue, 09 Apr 2013 19:49:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price/</guid>
      <description>I just tried to implement Lord Kahl algorithm to compute the Heston call price. The big difficulty of their method is to find the optimal alpha. That&amp;rsquo;s what make it work or break. The tricky part is that the function of alpha we want to minimize has multiple discontinuities (it&amp;rsquo;s periodic in some ways). This is why the authors rely on the computation of an alpha_max: bracketing is very important, otherwise your optimizer will jump the discontinuity without even noticing it, while you really want to stay in the region before the first discontinuity.</description>
    </item>
    <item>
      <title>From Double Precision Normal Density to Double Precision Cumulative Normal Distribution</title>
      <link>https://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</link>
      <pubDate>Tue, 02 Apr 2013 14:24:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/from-double-precision-normal-density-to-double-precision-cumulative-normal-distribution/</guid>
      <description>Marsaglia in his paper on Normal Distribution made the same mistake I initially did while trying to verify the accuracy of the normal density.In his table of values comparing the true value computed by Maple for some values of x to the values computed by Sun or Ooura erfc, he actually does not really use the same input for the comparison. One example is the last number: 16.6. 16.6 does not have an exact representation in double precision, even though it is displayed as 16.</description>
    </item>
    <item>
      <title>Cracking the Double Precision Gaussian Puzzle</title>
      <link>https://chasethedevil.github.io/post/cracking-the-double-precision-gaussian-puzzle/</link>
      <pubDate>Fri, 22 Mar 2013 12:20:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/cracking-the-double-precision-gaussian-puzzle/</guid>
      <description>In my previous post, I stated that some library (SPECFUN by W.D. Cody) computes \(e^{-\frac{x^2}{2}}\) the following way: xsq = fint(x * 1.6) / 1.6; del = (x - xsq) * (x + xsq); result = exp(-xsq * xsq * 0.5) * exp(-del *0.5);&#xA;where fint(z) computes the floor of z.&#xA;Why 1.6? An integer divided by 1.6 will be an exact representation of the corresponding number in double: 1.6 because of 16 (dividing by 1.</description>
    </item>
    <item>
      <title>A Double Precision Puzzle with the Gaussian</title>
      <link>https://chasethedevil.github.io/post/a-double-precision-puzzle-with-the-gaussian/</link>
      <pubDate>Wed, 20 Mar 2013 17:50:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-double-precision-puzzle-with-the-gaussian/</guid>
      <description>Some library computes the Gaussian density function $$e^{-\frac{x^2}{2}}$$ the following way: xsq = fint(x * 1.6) / 1.6; del = (x - xsq) * (x + xsq); result = exp(-xsq * xsq * 0.5) * exp(-del *0.5);&#xA;where fint(z) computes the floor of z.&#xA;Basically, x*x is rewritten as xsq*xsq+del. I have seen that trick once before, but I just can&amp;rsquo;t figure out where and why (except that it is probably related to high accuracy issues).</description>
    </item>
    <item>
      <title>A Seasoned Volatility Swap</title>
      <link>https://chasethedevil.github.io/post/a-seasoned-volatility-swap/</link>
      <pubDate>Thu, 14 Mar 2013 19:55:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-seasoned-volatility-swap/</guid>
      <description>This is very much what&#39;s in the Carr-Lee paper &#34;Robust Replication of Volatility Derivatives&#34;, but it wasn&#39;t so easy to obtain in practice:&#xA;The formulas as written in the paper are not usable as is: they can be simplified (not too difficult, but intimidating at first)The numerical integration is not trivial: a simple Gauss-Laguerre is not precise enough (maybe if I had an implementation with more points), a Gauss-Kronrod is not either (maybe if we split it in different regions).</description>
    </item>
    <item>
      <title>A Volatility Swap and a Straddle</title>
      <link>https://chasethedevil.github.io/post/a-volatility-swap-and-a-straddle/</link>
      <pubDate>Tue, 12 Mar 2013 21:36:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/a-volatility-swap-and-a-straddle/</guid>
      <description>A Volatility swap is a forward contract on future realized volatility. The pricing of such a contract used to be particularly challenging, often either using an unprecise popular expansion in the variance, or a model specific way (like Heston or local volatility with Jumps). Carr and Lee have recently proposed a way to price those contracts in a model independent way in their paper &amp;ldquo;robust replication of volatility derivatives&amp;rdquo;. Here is the difference between the value of a synthetic volatility swap payoff at maturity (a newly issued one, with no accumulated variance) and a straddle.</description>
    </item>
    <item>
      <title>Local Volatility Delta &amp; Dynamic</title>
      <link>https://chasethedevil.github.io/post/local-volatility-delta--dynamic/</link>
      <pubDate>Thu, 29 Nov 2012 12:30:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/local-volatility-delta--dynamic/</guid>
      <description>This will be a very technical post, I am not sure that it will be very understandable by people not familiar with the implied volatility surface.&#xA;Something one notices when computing an option price under local volatility using a PDE solver, is how different is the Delta from the standard Black-Scholes Delta, even though the price will be very close for a Vanilla option. In deed, the Finite difference grid will have a different local volatility at each point and the Delta will take into account a change in local volatility as well.</description>
    </item>
    <item>
      <title>GPU computing in Finance</title>
      <link>https://chasethedevil.github.io/post/gpu-computing-in-finance/</link>
      <pubDate>Mon, 15 Oct 2012 16:14:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/gpu-computing-in-finance/</guid>
      <description>Very interesting presentation from Murex about their GPU computing. Some points were:&#xA;GPU demand for mostly exotics pricing and greeks Local vol main model for EQD exotics. Local vol calibrated via PDE approach. Markov functional model becoming main model for IRD. Use of local regression instead of Longstaff Schwartz (or worse CVA like sim of sim). philox RNG from DE Shaw. But the presenter does not seem to know RNGs very well (recommended Brownian Bridge for Mersenne Twister!</description>
    </item>
    <item>
      <title>Binary Voting</title>
      <link>https://chasethedevil.github.io/post/binary-voting/</link>
      <pubDate>Fri, 07 Sep 2012 17:21:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/binary-voting/</guid>
      <description>How many reports have you had to fill up with a number of stars to choose? How much useless time is spent on figuring the this number just because it is always very ambiguous?&#xA;Some blogger wrote an interesting entry on Why I Hate Five Stars Reviews. Basically he advocates binary voting instead via like/dislike. Maybe a ternary system via like/dislike/don&#39;t care would be ok too.&#xA;One coworker used to advocate the same for a similar reason: people reading those reports only pay attention to the extremes: the 5 stars or the 0 stars.</description>
    </item>
    <item>
      <title>Adaptive Quadrature for Pricing European Option with Heston</title>
      <link>https://chasethedevil.github.io/post/adaptive-quadrature-for-pricing-european-option-with-heston/</link>
      <pubDate>Mon, 25 Jun 2012 12:50:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/adaptive-quadrature-for-pricing-european-option-with-heston/</guid>
      <description>The Quantlib code to evaluate the Heston integral for European options is quite nice. It proposes Kahl &amp;amp; Jaeckel method as well as Gatheral method for the complex logarithm. It also contains expansions where it matters so that the resulting code is very robust. One minor issue is that it does not integrate both parts at the same time, and also does not propose Attari method for the Heston integral that is supposed to be more stable.</description>
    </item>
    <item>
      <title>Gnome Shell more stable than Unity on Ubuntu 12.04</title>
      <link>https://chasethedevil.github.io/post/gnome-shell-more-stable-than-unity-on-ubuntu-12.04/</link>
      <pubDate>Thu, 14 Jun 2012 12:01:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/gnome-shell-more-stable-than-unity-on-ubuntu-12.04/</guid>
      <description>Regularly, the unity dock made some applications inaccessible: clicking on the app icon did not show or start the app anymore, a very annoying bug. This is quite incredible given that this version of Ubuntu is supposed to be long term support. So I decided to give one more chance to Gnome Shell. Installing it on Ubuntu 12.04 is simple with this guide. To my surprise it is very stable so far.</description>
    </item>
    <item>
      <title>Why primitive arrays matter in Java</title>
      <link>https://chasethedevil.github.io/post/why-primitive-arrays-matter-in-java/</link>
      <pubDate>Wed, 29 Feb 2012 10:01:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/why-primitive-arrays-matter-in-java/</guid>
      <description>In the past, I have seen that one could greatly improve performance of some Monte-Carlo simulation by using as much as possible double[][] instead of arrays of objects.&#xA;It was interesting to read this blog post explaining why that happens: it is all about memory access.</description>
    </item>
    <item>
      <title>KDE 4.8 finally has a dock</title>
      <link>https://chasethedevil.github.io/post/kde-4.8-finally-has-a-dock/</link>
      <pubDate>Fri, 27 Jan 2012 13:38:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/kde-4.8-finally-has-a-dock/</guid>
      <description>KDE 4.8 finally has a dock: you just have to add the plasma icon tasks. Also the flexibility around ALT+TAB is welcome. With Krusader as file manager, Thunderbird and Firefox for email and web, it is becoming a real nice desktop, but it took a while since the very bad KDE 4.0 release.&#xA;It is easy to install under ubuntu 11.10 through the backports and seems very stable so far.</description>
    </item>
    <item>
      <title>Generating random numbers following a given discrete probability distribution</title>
      <link>https://chasethedevil.github.io/post/generating-random-numbers-following-a-given-discrete-probability-distribution/</link>
      <pubDate>Mon, 09 Jan 2012 00:14:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/generating-random-numbers-following-a-given-discrete-probability-distribution/</guid>
      <description>I have never really thought very much about generating random numbers according to a precise discrete distribution, for example to simulate an unfair dice.&#xA;In finance, we are generally interested in continuous distributions, where there is typically 2 ways:&#xA;the inverse transform (usually computed in a numerical way), and the acceptance-rejection method, typically the ziggurat. The inverse transform is often preferred, because it&amp;rsquo;s usable method for Quasi Monte-Carlo simulations while the acceptance rejection is not.</description>
    </item>
    <item>
      <title>Quant Interview &amp; Education</title>
      <link>https://chasethedevil.github.io/post/quant-interview--education/</link>
      <pubDate>Wed, 21 Dec 2011 17:37:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/quant-interview--education/</guid>
      <description>Recently, I interviewed someone for a quant position. I was very surprised to find out that someone who did one of the best master in probabilities and finance in France could not solve a very basic probability problem:&#xA;This is accessible to someone with very little knowledge of probabilities When I asked this problem around to co-workers (who have all at least a master in a scientific subject), very few could actually answer it properly.</description>
    </item>
    <item>
      <title>Gnome 3 not so crap after all</title>
      <link>https://chasethedevil.github.io/post/gnome-3-not-so-crap-after-all/</link>
      <pubDate>Wed, 30 Nov 2011 18:11:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/gnome-3-not-so-crap-after-all/</guid>
      <description>In a previous post, I was complaining how bad Gnome 3 was. Since I have installed a real dock: docky, it is now much more usable. I can easily switch / launch applications without an annoying full screen change.&#xA;In addition I found out that it had a good desktop search (tracker). The ALT+F2 also does some sort of completion, too bad it can not use tracker here as well.</description>
    </item>
    <item>
      <title>Good &amp; Popular Algorithms are Simple</title>
      <link>https://chasethedevil.github.io/post/good--popular-algorithms-are-simple/</link>
      <pubDate>Thu, 17 Nov 2011 12:28:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/good--popular-algorithms-are-simple/</guid>
      <description>I recently tried to minimise a function according to some constraints. One popular method to minimise a function in several dimensions is Nelder-Mead Simplex. It is quite simple, so simple that I programmed it in Java in 1h30, including a small design and a test. It helped that the original paper from Nelder-Mead is very clear:&#xA;However the main issue is that it works only for unconstrained problems. Nelder and Mead suggested to add a penalty, but in practice this does not work so well.</description>
    </item>
    <item>
      <title>exp(y*log(x)) Much Faster than Math.pow(x,y)</title>
      <link>https://chasethedevil.github.io/post/expylogx-much-faster-than-math.powxy/</link>
      <pubDate>Fri, 08 Apr 2011 23:03:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/expylogx-much-faster-than-math.powxy/</guid>
      <description>Today I found out that replacing Math.pow(x,y) by Math.exp(yMath.log(x))* made me gain 50% performance in my program. Of course, both x and y are double in my case. I find this quite surprising, I expected better from Math.pow.</description>
    </item>
    <item>
      <title>SIMD and Mersenne-Twister</title>
      <link>https://chasethedevil.github.io/post/simd-and-mersenne-twister/</link>
      <pubDate>Sat, 05 Feb 2011 13:18:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/simd-and-mersenne-twister/</guid>
      <description>Since 2007, there is a new kind of Mersenne-Twister (MT) that exploits SIMD architecture, the SFMT. The Mersenne-Twister has set quite a standard in random number generation for Monte-Carlo simulations, even though it has flaws.&#xA;I was wondering if SFMT improved the performance over MT for a Java implementation. There is actually on the same page a decent Java port of the original algorithm. When I ran it, it ended up slower by more than 20% than the classical Mersenne-Twister (32-bit) on a 64-bit JDK 1.</description>
    </item>
    <item>
      <title>XORWOW L&#39;ecuyer TestU01 Results</title>
      <link>https://chasethedevil.github.io/post/xorwow-lecuyer-testu01-results/</link>
      <pubDate>Wed, 12 Jan 2011 20:26:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/xorwow-lecuyer-testu01-results/</guid>
      <description>Nvidia uses XorWow random number generator in its CURAND library. It is a simple and fast random number generator with a reasonably long period. It can also be parallelized relatively easily. Nvidia suggests it passes L&#39;Ecuyer TestU01, but is not very explicit about it. So I&#39;ve decided to see how it performed on TestU01.&#xA;I found very simple to test a new random number generator on TestU01, the documentation is great and the examples helpful.</description>
    </item>
    <item>
      <title>The CUDA Performance Myth</title>
      <link>https://chasethedevil.github.io/post/the-cuda-performance-myth/</link>
      <pubDate>Mon, 03 Jan 2011 16:07:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-cuda-performance-myth/</guid>
      <description>There is an interesting article on how to generate efficiently the inverse of the normal cumulative distribution on the GPU. This is useful for Monte-Carlo simulations based on normally distributed variables.&#xA;Another result of the paper is a method (breakless algorithm) to compute it apparently faster than the very good Wichura&amp;rsquo;s AS241 algorithm on the CPU as well keeping a similar precision. The key is to avoid branches (if-then) at the cost of not avoiding log() calls.</description>
    </item>
    <item>
      <title>Another Look at Java Matrix Libraries</title>
      <link>https://chasethedevil.github.io/post/another-look-at-java-matrix-libraries/</link>
      <pubDate>Mon, 29 Nov 2010 12:45:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/another-look-at-java-matrix-libraries/</guid>
      <description>A while ago, I was already looking for a good Java Matrix library, complaining that there does not seem any real good one where development is still active: the 2 best ones are in my opinion Jama and Colt.&#xA;Recently I tried to price options via RBF (radial basis functions) based on TR-BDF2 time stepping. This is a problem where one needs to do a few matrix multiplications and inverses (or better, LU solve) in a loop.</description>
    </item>
    <item>
      <title>Street Fighting Mathematics Book</title>
      <link>https://chasethedevil.github.io/post/street-fighting-mathematics-book/</link>
      <pubDate>Wed, 28 Jul 2010 14:25:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/street-fighting-mathematics-book/</guid>
      <description>The MIT has a downloadable book on basic mathematics: Street Fighting Mathematics. I liked the part focused on the geometrical approach. It reminded me of the early greek mathematics.&#xA;Overall it does look like a very American approach to Maths: answering a multiple choices questions test by elimination. But it is still an interesting book.</description>
    </item>
    <item>
      <title>double[][] Is Fine</title>
      <link>https://chasethedevil.github.io/post/double-is-fine/</link>
      <pubDate>Thu, 26 Nov 2009 14:51:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/double-is-fine/</guid>
      <description>In my previous post, I suggest that keeping a double[] performs better than keeping a double[][] if you do matrix multiplications and other operations.&#xA;This is actually not true. I benchmarked 3 libraries, Colt (uses double[]), Apache Commons Math (uses double[][]) and Jama (uses double[][] cleverly). At first it looks like Jama has a similar performance as Colt (they avoid [][] slow access by a clever algorithm). But once hotspot hits, the difference is crazy and Jama becomes the fastest (Far ahead).</description>
    </item>
    <item>
      <title>The Pain of Java Matrix Libraries</title>
      <link>https://chasethedevil.github.io/post/the-pain-of-java-matrix-libraries/</link>
      <pubDate>Thu, 26 Nov 2009 09:17:00 +0000</pubDate>
      <guid>https://chasethedevil.github.io/post/the-pain-of-java-matrix-libraries/</guid>
      <description>Looking for a good Java Matrix (and actually also math) library, I was a bit surprised to find out there does not seem to be any really serious one still maintained.&#xA;Sure, there is Apache Commons Math, but it is still changing a lot, and it is not very performance optimized yet, while it has been active for several years already. There is also Java3D, it does Matrix through GMatrix, but not much linear algebra and if you look at their implementation, it is very basic, not performance oriented.</description>
    </item>
  </channel>
</rss>
