<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.96.0" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Chase the Devil</title>
  <meta name="description" content="A personal, independent, technical blog" />

  
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
<link href="https://fonts.googleapis.com/css2?family=UnifrakturMaguntia&display=swap" rel="stylesheet">
 <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil" />
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://chasethedevil.github.io/"><h1 style="font-family: 'UnifrakturMaguntia', cursive;font-weight: normal;">Chase the Devil</h1></a>
      <p class="lead">
       A personal, independent, technical blog 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://chasethedevil.github.io/">Blog</a> </li>
        <li><a href="/about/"> About </a></li><li><a href="/post/"> Posts </a></li>
      </ul>

        <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>
 </nav>

    <p>&copy; 2022. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="posts">
<article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/modern-programming-language-for-monte-carlo/">Modern Programming Language for Monte-Carlo</a>
  </h1>
  <time datetime="2015-04-18T22:58:00Z" class="post-date">Sat, Apr 18, 2015</time>
   

A few recent programming languages sparked my interest:<br /><ul><li><a href="http://julialang.org/">Julia</a>: because of the wide coverage of mathematical functions, and great attention to quality of the implementations. It has also some interesting web interface.</li><li><a href="https://www.dartlang.org/">Dart</a>: because it's a language focused purely on building apps for the web, and has a supposedly good VM.</li><li><a href="http://www.rust-lang.org/">Rust</a>: it's the latest fad. It has interesting concepts around concurrency and a focus on being low level all the while being simpler than C.</li></ul>I decided to see how well suited they would be on a simple Monte-Carlo simulation of a forward start option under the Black model. I am no expert at all in any of the languages, so this is a beginner's test. I compared the runtime for executing 16K simulations times a multiplier.<br /><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">Multipl. Scala&nbsp; Julia&nbsp; JuliaA&nbsp; Dart&nbsp; Python&nbsp; Rust<br />1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.03&nbsp;&nbsp; 0.08&nbsp;&nbsp;&nbsp; 0.09&nbsp;&nbsp; 0.03&nbsp;&nbsp;&nbsp;&nbsp; 0.4&nbsp; 0.004 <br />10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.07&nbsp;&nbsp; 0.02 &nbsp;&nbsp; 0.06&nbsp;&nbsp; 0.11&nbsp;&nbsp;&nbsp;&nbsp; 3.9&nbsp; 0.04<br />100&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.51&nbsp;&nbsp; 0.21 &nbsp;&nbsp; 0.40&nbsp;&nbsp; 0.88&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.23<br />1000&nbsp;&nbsp;&nbsp;&nbsp; 4.11&nbsp;&nbsp; 2.07 &nbsp;&nbsp; 4.17&nbsp;&nbsp; 8.04&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.01</span><br /><br /><b>About performance</b><br /><br />I am quite impressed at Dart performance versus Scala (or vs. Java, as it has the same performance as Scala) given that it is much less strict about types and its focus is not at all on this kind of stuff.<br /><br />Julia performance is great, that is if one is careful about types. Julia is very <a href="http://julia.readthedocs.org/en/latest/manual/performance-tips/#man-performance-tips">finicky about casting and optimizations</a>, fortunately @time helps spotting the issues (often an inefficient cast will lead to copy and thus high allocation). JuliaA is my first attempt, with an implicit badly performing conversion of MersenneTwister to AbstractRNG. It is slower first, as the JIT costs is reflected on the first run, very much like in Java (although it appears to be even worse).<br /><br />Rust is the most impressive. I had to add the --release flag to the cargo build tool to produce a properly optimized binary, otherwise the performance is up to 7x worse.<br /><br /><b>About the languages</b><br /><br />My Python code is not vectorized, just like any of the other implementations. While the code looks relatively clean, I made the most errors compared to Julia or Scala. Python numpy isn't always great: norm.ppf is very slow, slower than my hand coded python implementation of AS241.<br /><br />Dart does not have fixed arrays: everything is a list. It also does not have strict 64 bit int: they can be arbitrarily large. The dev environment is ok but not great. <br /><br />Julia is a bit funny, not very OO (no object method) but more functional, although many OO concepts are there (type inheritence, type constructors). It was relatively straightforward, although I do not find intuitive the type conversion issues (eventual copy on conversion).<br /><br />Rust took me the most time to write, as it has quite new concepts around mutable variables, and "pointers" scope. I relied on an existing MersenneTwister64 that worked with latest Rust. It was a bit disappointing to see that some dSFMT git project did not compile with the latest Rust, likely because Rust is still a bit too young. This does not sound so positive, but I found it to be the language the most interesting to learn.<br /><br />I was familiar with Scala before this exercise. I used a non functional approach, with while loops in order to make sure I had maximum performance. This is something I find a bit annoying in Scala, I always wonder if for performance I need to do a while instead of a for, when the classic for makes much more sense (that and the fact that the classic for leads to some annoying delegation in runtime errors/on debug).<br /><br />I relied on the default RNG for Dart but MersenneTwister for Scala, Julia, Python, Rust. All implementations use a hand coded AS241 for the inverse cumulative normal.<br /><br /><b>Update&nbsp;</b><br /><br />Using FastMath.exp instead of Math.exp leads a slightly better performance for Scala:<br /><br />1 0.06<br />10 0.05<br />100 0.39<br />1000 2.66<br /><br />I did not expect that this would still be true in 2015 with Java 8 Oracle JVM.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/volatility-swap-vs-variance-swap-replication---truncation/">Volatility Swap vs Variance Swap Replication - Truncation</a>
  </h1>
  <time datetime="2015-03-16T14:39:00Z" class="post-date">Mon, Mar 16, 2015</time>
  <p>I have looked at <!-- raw HTML omitted -->jump effects on volatility vs. variance swaps<!-- raw HTML omitted -->. There is a similar behavior on tail events, that is, on truncating the replication.<!-- raw HTML omitted --><!-- raw HTML omitted -->One main <!-- raw HTML omitted -->problem with discrete replication of variance swaps<!-- raw HTML omitted --> is the implicit domain truncation, mainly because the variance swap equivalent log payoff is far from being linear in the wings.<!-- raw HTML omitted --><!-- raw HTML omitted -->The equivalent payoff with Carr-Lee for a volatility swap is much more linear in the wings (<!-- raw HTML omitted -->not so far of a straddle<!-- raw HTML omitted -->). So we could expect the replication to be less sensitive to the wings truncation.<!-- raw HTML omitted --><!-- raw HTML omitted -->I have done a simple test on flat 40% volatility:<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->As expected, the vol swap is much less sensitive, and interestingly, very much like for the jumps, it moves in the opposite direction: the truncated price is higher than the non truncated price.<!-- raw HTML omitted --><!-- raw HTML omitted --></p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/arbitrage-free-sabr-with-negative-rates---alternative-to-shifted-sabr/">Arbitrage free SABR with negative rates - alternative to shifted SABR</a>
  </h1>
  <time datetime="2015-03-11T18:48:00Z" class="post-date">Wed, Mar 11, 2015</time>
   

<a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2557046">Antonov et al.</a> present an interesting view on SABR with negative rates: instead of relying on a shifted SABR to allow negative rates up to a somewhat arbitrary shift, they modify slightly the SABR model to allow negative rates directly:
$$ dF_t = |F_t|^\beta v_t dW_F $$
with \\( v\_t \\) being the standard lognormal volatility process of SABR.<br /><br />Furthermore they derive a clever semi-analytical approximation for this model, based on low correlation, quite close to the Monte-Carlo prices in their tests. It's however not clear if it is arbitrage-free.<br /><br />It turns out that it is easy to tweak Hagan SABR PDE approach to this "absolute SABR" model: one just needs to push the boundary \\(F\_{min}\\) far away, and to use the absolute value in C(F).<br /><br />It then reproduces the same behavior as in Antonov et al. paper:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-kKiSIo-QgAg/VQBp3sRtYFI/AAAAAAAAH34/_A9DKmA_n-E/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A13%3A45%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-kKiSIo-QgAg/VQBp3sRtYFI/AAAAAAAAH34/_A9DKmA_n-E/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A13%3A45%2BPM.png" height="191" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">"Absolute SABR" arbitrage free PDE</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-cRLZged_Ees/VQBp7sKKTrI/AAAAAAAAH4A/PIZbUBBHP1I/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A14%3A02%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-cRLZged_Ees/VQBp7sKKTrI/AAAAAAAAH4A/PIZbUBBHP1I/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A14%3A02%2BPM.png" height="250" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Antonov et al. graph</td></tr></tbody></table>&nbsp;I obtain a higher spike, it would look much more like Antonov graph had I used a lower resolution to compute the density: the spike would be smoothed out.<br /><br />Interestingly, the arbitrage free PDE will also work for high beta (larger than 0.5):<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-YngRqD1ilNw/VQBroKrwKWI/AAAAAAAAH4M/3h9N7zHVjx0/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A21%3A13%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://3.bp.blogspot.com/-YngRqD1ilNw/VQBroKrwKWI/AAAAAAAAH4M/3h9N7zHVjx0/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A21%3A13%2BPM.png" height="190" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">beta = 0.75</td></tr></tbody></table>It turns out to be then nearly the same as the absorbing SABR, even if prices can cross a little the 0. This is how the bpvols look like with beta = 0.75:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-J_cdl8wwUms/VQBsOst-xYI/AAAAAAAAH4U/xWRMyUpOwxA/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A24%3A18%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-J_cdl8wwUms/VQBsOst-xYI/AAAAAAAAH4U/xWRMyUpOwxA/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A24%3A18%2BPM.png" height="191" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">red = absolute SABR, blue = absorbing SABR with beta=0.75</td></tr></tbody></table>They overlap when the strike is positive.<br /><br />If we go back to Antonov et al. first example, the bpvols look a bit funny (very symmetric) with beta=0.1:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-DrQY0znkznc/VQBsxqF8GAI/AAAAAAAAH4g/MGMwg4sS2Zw/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A26%3A30%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-DrQY0znkznc/VQBsxqF8GAI/AAAAAAAAH4g/MGMwg4sS2Zw/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A26%3A30%2BPM.png" height="191" width="320" /></a></div><br />For beta=0.25 we also reproduce Antonov bpvol graph, but with a lower slope for the left wing:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-QtPOjLCr4ts/VQBtT6hqvmI/AAAAAAAAH4o/jHLn9yC6Frk/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A28%3A55%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-QtPOjLCr4ts/VQBtT6hqvmI/AAAAAAAAH4o/jHLn9yC6Frk/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A28%3A55%2BPM.png" height="191" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">bpvols with beta = 0.25</td></tr></tbody></table>It's interesting to see that in this case, the positive strikes bp vols are closer to the normal Hagan analytic approximation (which is not arbitrage free) than to the absorbing PDE solution.<br /><br />For longer maturities, the results start to be a bit different from Antonov, as Hagan PDE relies on a order 2 approximation only:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-kPhdB8qyCKI/VQBuC3w2G4I/AAAAAAAAH40/lIIp0-zSokU/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A31%3A59%2BPM.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-kPhdB8qyCKI/VQBuC3w2G4I/AAAAAAAAH40/lIIp0-zSokU/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A31%3A59%2BPM.png" height="191" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">absolute SABR PDE with 10y maturity</td></tr></tbody></table><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-h2QCjhFGF14/VQBuTcUmlOI/AAAAAAAAH48/TarV9Gu24M0/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A33%3A08%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-h2QCjhFGF14/VQBuTcUmlOI/AAAAAAAAH48/TarV9Gu24M0/s1600/Screenshot%2B-%2B03112015%2B-%2B05%3A33%3A08%2BPM.png" height="153" width="320" /></a></div>The right wing is quite similar, except when it goes towards 0, it's not as flat, the left wing is much lower.<br /><br />Another important aspect is to reproduce Hagan's knee, the atm vols should produce a knee like curve, as different studies show (see for example <a href="http://www-2.rotman.utoronto.ca/~hull/downloadablepublications/TreeBuilding.pdf">this recent Hull &amp; White study</a> or this <a href="http://www.tandfonline.com/doi/abs/10.1080/14697688.2012.740569">other recent analysis by DeGuillaume</a>). Using the same parameters as Hagan (beta=0, rho=0) leads to a nearly flat bpvol: no knee for the absolute SABR, curiously there is a bump at zero, possibly due to numerical difficulty with the spike in the density:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-H7PhpMWdy6U/VQB_m9TNZ0I/AAAAAAAAH5M/4yp7RMOwmo4/s1600/Screenshot%2B-%2B03112015%2B-%2B06%3A46%3A44%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-H7PhpMWdy6U/VQB_m9TNZ0I/AAAAAAAAH5M/4yp7RMOwmo4/s1600/Screenshot%2B-%2B03112015%2B-%2B06%3A46%3A44%2BPM.png" height="191" width="320" /></a></div>The problem is still there with beta = 0.1:<br /><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-ljZ11v0FIqw/VQB_m_hao1I/AAAAAAAAH5Q/Jpn7wgZ2Dwg/s1600/Screenshot%2B-%2B03112015%2B-%2B06%3A46%3A55%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-ljZ11v0FIqw/VQB_m_hao1I/AAAAAAAAH5Q/Jpn7wgZ2Dwg/s1600/Screenshot%2B-%2B03112015%2B-%2B06%3A46%3A55%2BPM.png" height="191" width="320" /></a></div><br />Overall, the idea of extending SABR to the full real line with the absolute value looks particularly simple, but it's not clear that it makes real financial sense.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/variance-swaps-on-a-foreign-asset/">Variance swaps on a foreign asset</a>
  </h1>
  <time datetime="2015-02-24T13:50:00Z" class="post-date">Tue, Feb 24, 2015</time>
   

There is very little information on variance swaps on a foreign asset. There can be two kinds of contracts:<br /><ul><li>one that pays the foreign variance in a domestic currency, this is a quanto contract as the exchange rate is implicitly fixed.</li><li>one that pays the foreign variance, multiplied by the fx rate at maturity. This is a flexo contract, and is just about buying a variance swap from a foreign bank. The price of such a contract today is very simple, just the standard variance swap price multiplied by the fx rate today (change of measure).</li></ul>For quanto contracts, it's not so obvious a priori. If we consider a stochastic volatility model for the asset, the replication formula will not be applicable directly as the stochastic volatility will appear in the quanto drift correction. Furthermore, vanilla quanto option prices can not be computed simply as under Black-Scholes, a knowledge of the underlying model is necessary.<br /><br />Interestingly, under the Schobel-Zhu model, it is simple to fit an analytic formula for the quanto variance swap. The standard variance swap price is:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-gfq9trxBHhg/VOxxHi0khTI/AAAAAAAAH00/xD8NbXUSJls/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A33%3A17.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-gfq9trxBHhg/VOxxHi0khTI/AAAAAAAAH00/xD8NbXUSJls/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A33%3A17.png" height="50" width="400" /></a></div>The quanto variance swap can be priced with the same formula using a slightly different theta:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-OwYg8Hs9qRw/VOxxMe-iifI/AAAAAAAAH08/xBeV56UEGV8/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A34%3A06.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-OwYg8Hs9qRw/VOxxMe-iifI/AAAAAAAAH08/xBeV56UEGV8/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A34%3A06.png" /></a></div><br />We can use it to assess the accuracy of a naive quanto option replication where we use the ATM quanto forward instead of the forward in the variance swap replication formula.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-ate0oZ41eoY/VOxxhwqGI_I/AAAAAAAAH1E/6LRgNiAHCJg/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A34%3A52.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-ate0oZ41eoY/VOxxhwqGI_I/AAAAAAAAH1E/6LRgNiAHCJg/s1600/Screenshot%2B-%2B230215%2B-%2B19%3A34%3A52.png" height="289" width="640" /></a></div><br />Interestingly, the&nbsp; quanto forward approximation turns out to be very accurate and the correction is important. The price without correction is the price with zero correlation, and we see it can be +/-5% off in this case.<br /><br />The local vol price seems a bit off, I am not sure exactly why. It could be due the discretization, the theoretical variance should be divided by (N-1) but here we divide by N where N is the number of observations. That would still lead to a skewed price but better centered around correlation 0.<br /><br />It's also a bit surprising that local vol is worse than the simpler ATM quanto forward approximation: it seems that it's extracting the wrong information to do a more precise quanto correction, likely related to the shift of stochastic volatility under the domestic measure.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/jumps-impact-variance-swap-vs-volatility-swap/">Jumps impact: Variance swap vs volatility swap</a>
  </h1>
  <time datetime="2015-02-20T13:24:00Z" class="post-date">Fri, Feb 20, 2015</time>
  <!-- raw HTML omitted -->

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/variance-swap-replication--discrete-or-continuous/">Variance Swap Replication : Discrete or Continuous?</a>
  </h1>
  <time datetime="2015-02-19T18:45:00Z" class="post-date">Thu, Feb 19, 2015</time>
   

People regularly believe that Variance swaps need to be priced by discrete replication, because the market trades only a discrete set of options.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-9dEW7QRFa7k/VOYguM8BHOI/AAAAAAAAH0Q/RPFxCeyq6nU/s1600/Screenshot%2B-%2B190215%2B-%2B18%3A36%3A26.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-9dEW7QRFa7k/VOYguM8BHOI/AAAAAAAAH0Q/RPFxCeyq6nU/s1600/Screenshot%2B-%2B190215%2B-%2B18%3A36%3A26.png" height="340" width="640" /></a></div><br />In reality, a discrete replication will misrepresent the tail, and can be quite arbitrary. It looks like the discrete replication as described in <a href="http://bfi.cl/papers/Derman%201999%20-%20More%20about%20Variance%20Swaps.pdf">Derman Goldman Sachs paper</a> is in everybody's mind, probably because it's easy to grasp. Strangely, it looks like most forget the section "Practical problems with replication" on p27 of his paper, where you can understand that discrete replication is not all that practical.<br /><br />Reflecting on all of this, I noticed it was possible to create more accurate discrete replications easily, and that those can have vastly different hedging weights. It is a much better idea to just replicate the log payoff continuously with a decent model for interpolation and extrapolation and imply the hedge from the greeks.<br /><br />I wrote <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2567398">a small paper around this here</a>.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/gtk-3.0--gnome-3.0-annoyance/">GTK 3.0 / Gnome 3.0 annoyance</a>
  </h1>
  <time datetime="2015-02-08T22:30:00Z" class="post-date">Sun, Feb 8, 2015</time>
  <p>It&rsquo;s quite incredible that Gnome 3.0 was almost an identical mess as KDE 4.0 had been a year or two earlier. Both are much better now, more stable, but both also still have their issues, and don&rsquo;t feel like a real improvement over Gnome 2.0 or KDE 3.5.</p>
<p>Now the main file manager for Gnome 3.0, Nautilus has buttons with nearly identical icons that mean vastly different things, one is a menu, the other is a list view. Also it does not integrate with other desktops well from a look and feel perpective, here is a screenshot under XFCE (KDE would not look better).The push for window buttons inside the toolbar makes for a funny looking window. In Gnome Shell, it&rsquo;s not much better, plus there are some windows with a dark theme and some with a standard theme all mixed together.</p>
<p>On the left is Caja: an updated GTK 2.0 version of Nautilus. I find it more functional, I don&rsquo;t really understand the push to remove most options from the screen in Gnome 3.0. The only positive thing I can see on for the new Nautilus, is the grey color for the left side, which looks more readable and polished.</p>
<p>Interestingly, Nautilus within Ubuntu Unity feels better, it has a real menu and standard looking window. I suppose they customized it quite a bit.
 

<div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-edQQUDP-LOo/VNfTxeA9YyI/AAAAAAAAHz4/ezOAmMYoiS0/s1600/Screenshot%2B-%2B02082015%2B-%2B10%3A12%3A25%2BPM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-edQQUDP-LOo/VNfTxeA9YyI/AAAAAAAAHz4/ezOAmMYoiS0/s1600/Screenshot%2B-%2B02082015%2B-%2B10%3A12%3A25%2BPM.png" height="254" width="640" /></a></div>


When it comes to HiDPI support, Gnome shell is often touted has having one of the best. Well maybe for laptop screens, but certainly not for larger screens, where it just double everything and everything just looks too big. XFCE is actually decent on HiDPI screens.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/monte-carlo--inverse-cumulative-normal-distribution/">Monte Carlo &amp; Inverse Cumulative Normal Distribution</a>
  </h1>
  <time datetime="2015-02-03T14:53:00Z" class="post-date">Tue, Feb 3, 2015</time>
   

In most financial Monte-Carlo simulations, there is the need of generating normally distributed random numbers. One technique is to use the inverse cumulative normal distribution function on uniform random numbers. There are several different popular numerical implementations:<br /><ul><li>Wichura AS241 (1988)</li><li>Moro "The full Monte" (1995)</li><li><a href="http://home.online.no/~pjacklam/notes/invnorm/">Acklam</a> (2004)</li><li><a href="http://arxiv.org/abs/0901.0638">Shaw breakless formula</a> optimized for GPUs (2011) </li></ul>W. Shaw has an excellent overview of the accuracy of the various methods in his paper <i><a href="http://www.mth.kcl.ac.uk/~shaww/web_page/papers/NormalQuantile1.pdf">Refinement of the normal quantile</a></i>.<br /><br />But what about performance? In Monte-Carlo, we could accept a slighly lower accuracy for an increase in performance.<br /><br />I tested the various methods on the Euler full truncation scheme for Heston using a small timestep (0.01). Here are the results with Sobol quasi-rng:<br /><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">AS241&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.9186256922511046 0.42s<br />MORO &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.9186256922459066 0.38s</span></span><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">ACKLAM &nbsp; &nbsp; &nbsp; &nbsp; 0.9186256922549364 0.40s</span></span><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">ACKLAM REFINED 0.9186256922511045 2.57s<br />SHAW-HYBRID &nbsp;&nbsp; 0.9186256922511048 0.68s</span></span><br /><br />In practice, the most accurate algorithm, AS241, is of comparable speed as the newer but less accurate algorithms of MORO and ACKLAM. Acklam refinement to go to double precision (which AS241 is) kills its performance.<br /><br />What about the Ziggurat on pseudo rng only? Here are the results with Mersenne-Twister-64, and using the Doornik implementation of the Ziggurat algorithm:<br /><br /><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">AS241&nbsp; 0.9231388565879476&nbsp; 0.49s<br />ZIGNOR 0.9321405648313437&nbsp; 0.44s</span></span><br /><br />There is a more optimized algorithm, VIZIGNOR, also from Doornik which should be a bit faster. As expected, the accuracy is quite lower than with Sobol, and the Ziggurat looks worse. This is easily visible if one plots the implied volatilities as a function of the spot for AS241 and for ZIGNOR.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-lITlDFhF-cE/VNDQfqtNbTI/AAAAAAAAHzU/zki5VJADyv4/s1600/Screenshot%2Bfrom%2B2015-02-03%2B14%3A43%3A10.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-lITlDFhF-cE/VNDQfqtNbTI/AAAAAAAAHzU/zki5VJADyv4/s1600/Screenshot%2Bfrom%2B2015-02-03%2B14%3A43%3A10.png" height="321" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">AS241 implied volatility on Mersenne-Twister</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-QxKOGzNMSXE/VNDQp7dL0EI/AAAAAAAAHzc/wm1c-ymLYww/s1600/Screenshot%2Bfrom%2B2015-02-03%2B14%3A18%3A51.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-QxKOGzNMSXE/VNDQp7dL0EI/AAAAAAAAHzc/wm1c-ymLYww/s1600/Screenshot%2Bfrom%2B2015-02-03%2B14%3A18%3A51.png" height="321" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">ZIGNOR implied volatility on Mersenne-Twister</td></tr></tbody></table><br />Zignor is much noisier.<br /><br />Note the slight bump in the scheme EULER-FT-BK that appears because the scheme, that approximates the Broadie-Kaya integrals with a trapeze (as in Andersen QE paper), does not respect martingality that well compared to the standard full truncated Euler scheme EULER-FT, and the slightly improved EULER-FT-MID where the variance integrals are approximated by a trapeze as in Van Haastrecht paper on Schobel-Zhu:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-pIO5C8vN1Es/VNDSPriO-OI/AAAAAAAAHzo/d0DUYBjiG8Q/s1600/Screenshot%2B-%2B030215%2B-%2B14%3A49%3A29.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-pIO5C8vN1Es/VNDSPriO-OI/AAAAAAAAHzo/d0DUYBjiG8Q/s1600/Screenshot%2B-%2B030215%2B-%2B14%3A49%3A29.png" height="76" width="640" /></a></div>This allows to leak less correlation than the standard full truncated Euler.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/local-stochastic-volatility---particles-and-bins/">Local Stochastic Volatility - Particles and Bins</a>
  </h1>
  <time datetime="2015-01-30T12:03:00Z" class="post-date">Fri, Jan 30, 2015</time>
  <p>In an <!-- raw HTML omitted -->earlier post<!-- raw HTML omitted -->, I mentioned the similarities between the Guyon-Labordere <!-- raw HTML omitted -->particle method<!-- raw HTML omitted --> and the Vanderstoep-Grzelak-Oosterlee <!-- raw HTML omitted -->&ldquo;bin&rdquo; method<!-- raw HTML omitted --> to calibrate and price under Local Stochastic volatility. I will be a bit more precise here.<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->The same thing, really<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->The particle method can be seen as a generalization of the &ldquo;bin&rdquo; method. In deed, the bin method consists in doing the particle method using a histogram estimation of the conditional variance. The histogram estimation can be more or less seen as a very basic rectangle kernel with the appropriate bandwidth. The &ldquo;bin&rdquo; method is then just the particle method with another kernel (wiki link) (in the particle method, the kernel is a quartic with bandwidth defined by some slightly elaborate formula). A very good paper on this is Silverman <!-- raw HTML omitted --><!-- raw HTML omitted -->Density estimation for statistics and data analysis<!-- raw HTML omitted --><!-- raw HTML omitted -->, referenced by Guyon-Labordere.<!-- raw HTML omitted --><!-- raw HTML omitted -->In theory, the original particle method has the advantage of using a narrower bandwidth, resulting in a theoretical increase in performance as one does not have to sum over all particles, while providing a more local therefore precise estimate. In practice, the performance advantage is not so clear on my non optimized code.<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->Two-pass<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->There is an additional twist in the particle method: one can compute the expectation and the payoff evaluation in the same Monte-Carlo simulation, or in two sequential Monte-Carlo simulations.<!-- raw HTML omitted --><!-- raw HTML omitted -->Why would we do two? Mainly because the expectation is computed across all paths, at each time step, while, usually, payoff evaluation requires a full path as it will need to store some state at each observation time for path-dependent payoffs.<!-- raw HTML omitted --><!-- raw HTML omitted -->We can avoid recomputing the paths by just caching them at each observation time. The problem is that the size of this cache can quickly become extremely large and blow up the memory. For example a 10y daily knock-out will require 10 * 252 * 8 * 2 * MB = 40 GB for 1 million paths.<!-- raw HTML omitted --><!-- raw HTML omitted -->A side effect of the second simulation is that one can use a Quasi-Random number generator there, while for the first simulation, this is not easy as we compute all paths, dimension by dimension.<!-- raw HTML omitted --><!-- raw HTML omitted -->In practice, both methods work well, particle or bins, single-pass or two-pass. Here is a graph of the error in volatility, SV is a not so well calibrated Heston to market data. LVSV are the local stochastic volatility simulations, using as Vanderstoep 100 steps per year and 500K simulations with 30 bins.<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->The advantages of the particle do not show up in terms of accuracy on this example.<!-- raw HTML omitted -->I have also noticed that short expiries seem trickier, the error being larger. This might just be due to the time-step size, but interestingly the papers only show graphs of medium (min=6m) to large expiries.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/flat-volatility-surfaces--discrete-dividends/">Flat Volatility Surfaces &amp; Discrete Dividends</a>
  </h1>
  <time datetime="2014-11-25T13:58:00Z" class="post-date">Tue, Nov 25, 2014</time>
   

In papers around volatility and cash (discrete) dividends, we often encounter the example of the flat volatility surface. For example, the <a href="http://www.opengamma.com/sites/default/files/equity-variance-swaps-dividends-opengamma.pdf">OpenGamma paper</a> presents this graph:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-AuaTFyvjgVA/VHRxUid4HzI/AAAAAAAAHjs/T4PAQTnUBN8/s1600/Screenshot%2Bfrom%2B2014-11-25%2B12%3A59%3A09.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-AuaTFyvjgVA/VHRxUid4HzI/AAAAAAAAHjs/T4PAQTnUBN8/s1600/Screenshot%2Bfrom%2B2014-11-25%2B12%3A59%3A09.png" height="167" width="400" /></a></div><br />It shows that if the Black volatility surface is fully flat, there are jumps in the pure volatility surface (corresponding to a process that includes discrete dividends in a consistent manner) at the dividend dates or equivalently if the pure volatility surface is flat, the Black volatility jumps.<br /><br />This can be traced to the fact that the Black formula does not respect C(S,K,Td-) = C(S,K-d,Td) as the forward drops from F(Td-) to F(Td-)-d where d is dividend amount at td, the dividend ex date.<br /><br />Unfortunately, those examples are not very helpful. In practice, the market observables are just Black volatility points, which can be interpolated to volatility slices for each expiry without regards to dividends, not a full volatility surface. Discrete dividends will mostly happen between two slices: the Black volatility jump will happen on some time-interpolated data.<br /><br />While the jump size is known (it must obey to the call price continuity), the question of how one should interpolate that data until the jump is far from trivial even using two flat Black volatility slices.<br /><br />The most logical is to consider a model that includes discrete dividends consistently. For example, one can fully lookup the Black volatility corresponding the price of an option assuming a piecewise lognormal process with jumps at the dividend dates. It can be priced by applying a finite difference method on the PDE. Alternatively, <a href="http://www.risk.net/risk-magazine/technical-paper/1530307/finessing-fixed-dividends">Bos &amp; Vandermark</a> propose a simple spot and strike adjusted Black formula that obey the continuity requirement (the Lehman model), which, in practice, stays quite close to the piecewise lognormal model price. Another possibility is to rely on a forward modelling of the dividends, as in <a href="http://www.quantitative-research.de/dl/Dividends_And_Volatility.pdf">Buehler</a> (if one is comfortable with the idea that the option price will then depend ultimately on dividends past the option expiry).<br /><br />Recently, a <a href="http://onlinelibrary.wiley.com/doi/10.1002/wilm.10112/abstract">Wilmott article</a> suggested to only rely on the jump adjustment, but did not really mention how to find the volatility just before or just after the dividend. Here is an illustration of how those assumptions can change the volatility in between slices using two dividends at T=0.9 and T=1.1.<br /><br />In the first graph, we just interpolate linearly in forward moneyness the pure vol from the Bos &amp; Vandermark formula, as it should be continuous with the forward (the PDE would give nearly the same result) and compute the equivalent Black volatility (and thus the jump at the dividend dates).<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-Pye5KeoR16M/VHR1WACQD3I/AAAAAAAAHj4/h65Vpj4mMjI/s1600/bos_2_div_flat.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-Pye5KeoR16M/VHR1WACQD3I/AAAAAAAAHj4/h65Vpj4mMjI/s1600/bos_2_div_flat.png" height="300" width="400" /></a></div><br />In the second graph, we interpolate linearly the two Black slices, until we find a dividend, at which point we impose the jump condition and repeat the process until the next slice. We process forward (while the Wilmott article processes backward) as it seemed a bit more natural to make the interpolation not depend on future dividends. Processing backward would just make the last part flat and first part down-slopping. On this example backward would be closer to the Bos Black volatility, but when the dividends are near the first slice, the opposite becomes true.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-ScSlBHCBoWc/VHR1eOigrXI/AAAAAAAAHkA/3HJ9zRQvguA/s1600/blackjump_2_div_flat.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-ScSlBHCBoWc/VHR1eOigrXI/AAAAAAAAHkA/3HJ9zRQvguA/s1600/blackjump_2_div_flat.png" height="300" width="400" /></a></div>While the scale of those changes is not that large on the example considered, the choice can make quite a difference in the price of structures that depend on the volatility in between slices. A recent example I encountered is the variance swap when one includes adjustment for discrete dividends (then the prices just after the dividend date are used).<br /><br />To conclude, if one wants to use the classic Black formula everywhere, the volatility must jump at the dividend dates. Interpolation in time is then not straightforward and one will need to rely on a consistent model to interpolate. It is not exactly clear then why would anyone stay with the Black formula except familiarity.



  
</article>
</div>
<p style="text-align:left; width:49%; display: inline-block;"><a href="/page/8/">Previous</a></p>
<p style="text-align:right; width:50%;  display: inline-block;"><a href="/page/10/">Next</a></p>
    </main>

    
      
    
  </body>
</html>
