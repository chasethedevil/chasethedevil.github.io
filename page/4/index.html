<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.91.2" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Chase the Devil</title>
  <meta name="description" content="A personal, independent, technical blog" />

  
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
<link href="https://fonts.googleapis.com/css2?family=UnifrakturMaguntia&display=swap" rel="stylesheet">
 <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil" />
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://chasethedevil.github.io/"><h1 style="font-family: 'UnifrakturMaguntia', cursive;font-weight: normal;">Chase the Devil</h1></a>
      <p class="lead">
       A personal, independent, technical blog 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://chasethedevil.github.io/">Blog</a> </li>
        <li><a href="/about/"> About </a></li><li><a href="/post/"> Posts </a></li>
      </ul>

        <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>
 </nav>

    <p>&copy; 2022. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="posts">
<article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/svn_is_dead/">SVN is dead</a>
  </h1>
  <time datetime="2017-09-26T23:56:42&#43;0100" class="post-date">Tue, Sep 26, 2017</time>
  <p>A few years ago, when <a href="https://git-scm.com/">Git</a> was rising fast and <a href="https://subversion.apache.org/">SVN</a> was already not hype anymore, a friend thought that SVN was for many organizations better suited than Git, with the following classical arguments, which were sound at the time:</p>
<ol>
<li>Who needs decentralization for a small team or a small company working together?</li>
<li>‎SVN is proven, works well and is simple to use and put in place.</li>
</ol>
<p>Each argument is in reality not so strong. It becomes clear now that Git is much more established.</p>
<p>Regarding the first argument, a long time ago some people had trouble with CVS as it introduced the idea of merging instead of locking files. Git represents a similar paradigm shift between the centralized and the decentralized. It can scare people in not so rational ways. You could lock files with CVS as you did with visual sourcesafe or any other crappy old source control system. It&rsquo;s just that people favored merges as it was effectively more convenient and more productive. You can also use Git with a centralized workflow. Another more scary paradigm shift with Git is to move away from the idea that branches are separate folders. With Git you just switch branches as it is instantaneous even though, again, you could use it in the old fashioned SVN way.</p>
<p>Now onto the second argument, SVN is proven to work well. But so is Cobol. Today it should be clear that SVN is essentially dead. Most big projects move or have moved to git. Tools work better with Git, even <a href="https://www.eclipse.org/">Eclipse</a> works natively with Git but requires buggy plugins for SVN. New developers don&rsquo;t know SVN.</p>
<p>I heard other much worse arguments against Git since. For example, some people believed that, with Git, they could lose some of their code changes. This was partially due to sensational news article such as the <a href="https://www.theregister.co.uk/2017/02/01/gitlab_data_loss/">Gitlab.com data loss</a>, where in reality some administrator deleted some directory and had non-working backups. As a result, some Git repositories were deleted, but in reality it&rsquo;s a common data loss situation, unrelated to the use of Git as version control system. This Stackoverflow question gives a nice overview of <a href="https://stackoverflow.com/questions/21048765/what-can-cause-data-loss-in-git">data loss risks with Git</a>.</p>
<p>What I feel is true however is that Git is more complex than SVN, because it is more powerful and more flexible. But if you adopt a simple workflow, it&rsquo;s not necessarily more complicated.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/the_neural_network_in_your_cpu/">The Neural Network in Your CPU</a>
  </h1>
  <time datetime="2017-08-06T23:56:42&#43;0100" class="post-date">Sun, Aug 6, 2017</time>
  <p>Machine learning and artificial intelligence are the current hype (again). In their new Ryzen processors, <a href="http://www.anandtech.com/Gallery/Album/5197#18">AMD advertises the Neural Net Prediction</a>. It turns out this is was already used in their older (2012) Piledriver architecture used for example in the <a href="http://www.anandtech.com/show/5831/amd-trinity-review-a10-4600m-a-new-hope">AMD A10-4600M</a>. It is also present in recent Samsung processors such as <a href="https://www.theregister.co.uk/2016/08/22/samsung_m1_core/">the one powering the Galaxy S7</a>. What is it really?</p>
<p>The basic idea can be traced to a paper from Daniel Jimenez and Calvin Lin <a href="https://www.cs.utexas.edu/~lin/papers/hpca01.pdf">&ldquo;Dynamic Branch Prediction with Perceptrons&rdquo;</a>, more precisely described in the subsequent paper <a href="http://taco.cse.tamu.edu/pdfs/tocs02.pdf">&ldquo;Neural methods for dynamic branch prediction&rdquo;</a>. Branches typically occur  in <code>if-then-else</code> statements. <a href="https://en.wikipedia.org/wiki/Branch_predictor">Branch prediction</a> consists in guessing which code branch, the <code>then</code> or the <code>else</code>, the code will execute, thus allowing to precompute the branch in parallel for faster evaluation.</p>
<p>Jimenez and Lin rely on a simple single-layer perceptron neural network whose input are the branch outcome (global or hybrid local and global) histories and the output predicts which branch will be taken. In reality, because there is a single layer, the output y is simply a weighted average of the input (x, and the constant 1):</p>
<p>$$ y = w_0 + \sum_{i=1}^n x_i w_i $$</p>
<p>\( x_i = \pm 1 \) for a taken or not taken. \( y &gt; 0 \) predicts to take the branch.</p>
<p>Ideally, each static branch is allocated its own perceptron. In practice, a hash of the branch address is used.</p>
<p>The training consists in updating each weight according to the actual branch outcome t : \( w_i = w_i + 1 \) if \( x_i = t \) otherwise \( w_i = w_i - 1 \). But this is done only if the predicted outcome is lower than the training (stopping) threshold or if the branch was mispredicted. The threshold keeps from overtraining and allow to adapt quickly to changing behavior.</p>
<p>The perceptron is one of those algorithms created by a psychologist. In this case, the culprit is Frank Rosenblatt. Another more recent algorithm created by a psychologist is the <a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization">particle swarm optimization</a> from James Kennedy. As <a href="https://quantsrus.github.io/post/particle_swarm_optimization/">in the case of</a> particle swarm optimization, there is not a single well defined perceptron, but many variations around some key principles. A reference seems to be the perceptron from H.D. Block, probably because he describes the perceptron in terms closer to code, while Rosenblatt was really describing a perceptron machine.</p>
<p>The perceptron from H.D. Block is slightly more general than the perceptron used for branch prediction:</p>
<ul>
<li>the output can be -1, 0 or 1. The output is zero if the weighted average is below a threshold (a different constant from the training threshold of the branch prediction perceptron).</li>
<li>reinforcement is not done on inactive connections, that is for \( x_i = 0 \).</li>
<li>a learning rate \( \alpha \) is used to update the weight: \( w_i += \alpha t x_i \)</li>
</ul>
<p>The perceptron used for branch prediction is quite different from the deep learning neural networks fad, which have many more layers, with some feedback loop. The challenge of those is the training: when many layers are added to the perceptron, the gradients of each layer activation function multiply in the backpropagation algorithm. This makes the &ldquo;effective&rdquo; gradient at the first layers to be very small, which translates to tiny changes in the weights, making training not only very slow but also likely stuck in a sub-optimal local minimum. Beside the <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">vanishing gradient</a> problem, there is also the <a href="https://en.wikipedia.org/wiki/Catastrophic_interference">catastrophic interference</a> problem to pay attention to. Those issues are today dealt with the use of <a href="http://neuralnetworksanddeeplearning.com/chap6.html">specific strategies to train / structure the network</a> combined with raw computational power that was unavailable in the 90s.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/benham_disc_in_web_canvas/">Benham disc in web canvas</a>
  </h1>
  <time datetime="2017-07-10T23:56:42&#43;0100" class="post-date">Mon, Jul 10, 2017</time>
  <p>Around 15 years ago, I wrote a small Java applet to try and show the <a href="https://en.wikipedia.org/wiki/Benham%27s_top">Benham disk</a> effect. Even back then applets were already passé and Flash would have been more appropriate. These days, no browser support Java applets anymore, and very few web users have Java installed. Flash also mostly disappeared. The <a href="https://www.w3schools.com/html/html5_canvas.asp">web canvas</a> is today&rsquo;s standard allowing to embbed animations in a web page.
 

This effect shows color perception from a succession of black and white pictures. It is a computer reproduction from the Benham disc with ideas borrowed from "Pour La Science Avril/Juin 2003".
Using a delay between 40 and 60ms, the inner circle should appear <font color="#770000">red</font>, the one in the middle 
<font color="#000077">blue</font> and the outer one <font color="#007700">green</font>. When you reverse the rotation direction,
blue and red circles should be inverted.

<form>
  Delay: <input type="number" name="delay" value="60" id="delayInput"> Reverse <input type="checkbox" value="false" id="reverseInput" onclick="javascript:reverse()"> <input type="button" value="Start" onclick="javascript:startStop()" id="startButton">
</form>

<canvas id="myCanvas" width="480" height="480" style="border:1px solid #000000;">
</canvas> 

<script type="text/javascript">
var c = document.getElementById("myCanvas");
  c.style.width ='100%';
  c.style.height='100%';
  // ...then set the internal size to match
  c.width  = c.offsetWidth;
  c.height = c.offsetWidth;
var x=c.width/2;
var y=x;
linewidth = c.width / 100;
var g = c.getContext("2d");

function paintImage(g, x,y,startArcAngle) {
var radius = 0.9;
var r = radius*x; endAngle = 2*Math.PI/3+startArcAngle;
g.beginPath();
g.arc(x, y, r, Math.PI/3+startArcAngle, endAngle, false);
g.lineWidth = linewidth;
g.strokeStyle = "black";
g.stroke();

radius = 0.8; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, Math.PI/3+startArcAngle, endAngle, false);
g.stroke();

radius = 0.7; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, Math.PI/3+startArcAngle, endAngle, false);
g.stroke();

radius = 0.6; r = radius*x; endAngle = Math.PI/3+startArcAngle;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.5; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.4; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false);
g.stroke();

//  paintImage(g, startArcAngle, 60, 0.3); //red -180 to -60
radius = 0.3; r = radius*x; endAngle = Math.PI+startArcAngle;// if (endAngle > Math.PI*2) endAngle = endAngle - 2*Math.PI 
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();
        
radius = 0.2; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.1; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();

g.beginPath();
g.arc(x, y, x,  Math.PI+startArcAngle, Math.PI*2+startArcAngle, false); 
g.fill();
}

var delay = 40;
var currentAnimate = 0;
var animationStartTime = window.performance.now();
var currentIndex = 3;
var angles = [0.0, 2*Math.PI/3, 4*Math.PI/3];

var offscreenCanvas = [document.createElement('canvas'),document.createElement('canvas'),document.createElement('canvas')];
for (var i in offscreenCanvas) {
  offscreenCanvas[i].width = c.offsetWidth;
  offscreenCanvas[i].height = c.offsetWidth;
  g = offscreenCanvas[i].getContext("2d");
  paintImage(g, x, y, angles[i]);
}
g = c.getContext("2d");

//function animate0() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y,  0.0);
//  currentAnimate = setTimeout(animate1, delay);
//}
//function animate1() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y,  2*Math.PI/3);
//  currentAnimate = setTimeout(animate2, delay);
//}
//function animate2() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y, 4*Math.PI/3);
//  currentAnimate= setTimeout(animate0, delay);
//}

window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame ||
                              window.webkitRequestAnimationFrame || window.msRequestAnimationFrame;


function animateContinuous(time) {
  var index = Math.floor(((time - animationStartTime) % (3*delay))/delay);
  if (index < 0) index = 0
  if (index != currentIndex) {
    //g.clearRect(0,0,c.width, c.height);
    //paintImage(g, x, y, angles[index]);
    var offscreenContext = offscreenCanvas[index].getContext('2d');
    var image = offscreenContext.getImageData(0,0,c.width,c.height); 
    g.putImageData(image, 0, 0);       
    currentIndex = index;
  }
  currentAnimate = requestAnimationFrame(animateContinuous);
}

function reverse() {
  //tmp = angles[2]; angles[2] = angles[0]; angles[0] = tmp;
  tmp = offscreenCanvas[2]; offscreenCanvas[2] = offscreenCanvas[0]; offscreenCanvas[0] = tmp;
}

function startStop() {
  var elem = document.getElementById("startButton");
  var delayElem = document.getElementById("delayInput");
 if (elem.value=="Stop") {
    elem.value = "Start";
    //clearTimeout(currentAnimate);
    window.cancelAnimationFrame(currentAnimate);
    currentAnimate = 0;
  } else {
    elem.value = "Stop";
    delay = delayElem.value;
    animationStartTime = window.performance.now();
    //animate0();
    currentAnimate = requestAnimationFrame(animateContinuous);
  }
}
</script>

</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/quantitative_finance_blogs/">Blogs on Quantitative Finance</a>
  </h1>
  <time datetime="2017-06-21T23:56:42&#43;0100" class="post-date">Wed, Jun 21, 2017</time>
  <p>There are not many blogs on quantitative finance that I read. Blogs are not so popular anymore with the advent of the various social networks (facebook, stackoverflow, google plus, reddit, &hellip;). Here is a small list:</p>
<ul>
<li><a href="https://www.clarusft.com/blog/">Clarus FT</a>: often interesting statistics on the swap market, clearing, plus the <a href="https://www.clarusft.com/author/gary/">more technical articles from Gary</a>.</li>
<li><a href="https://quantsrus.github.io/">Quants R Us</a>: A relatively new blog with a promising starting post analyzing <a href="https://quantsrus.github.io/post/andreasen_huge_spline/">Andreasen-Huge one-step local-volatility algorithm with a Spline</a></li>
<li><a href="https://quantlib.wordpress.com/author/petercaspers/">Fooling around with Quantlib</a>: the blog from Peter Caspers, also relevant  to non-Quantlib professionals has original insights such as <a href="https://quantlib.wordpress.com/2015/09/19/smile-dynamics-by-densities/">Smile dynamics by densities</a> or the <a href="https://quantlib.wordpress.com/2015/08/23/supernatural-libor-coupons/">Supernatural Libor Coupons</a>. Unfortunately it is not so active anymore.</li>
<li><a href="http://www.implementingquantlib.com">Implementing Quantlib</a>: the blog from Luigi Ballabio, which explains many of the design decisions in Quantlib. Very interesting for developer of financial libraries, see for example <a href="http://www.implementingquantlib.com/2017/04/fd-solvers.html">the fd solvers</a>.</li>
<li><a href="https://hpcquantlib.wordpress.com/">HPC Quantlib</a> from Klaus Spanderen. Yes lots of quantlib blogs, but this one is actually not much focused on quantlib. It goes into great details about some numerical techniques, see for example the <a href="https://hpcquantlib.wordpress.com/2017/05/07/newer-semi-analytic-heston-pricing-algorithms/">analysis of Heston pricing algorithm</a></li>
<li><a href="http://oxfordstrat.com/rd-blog/">Oxford Strat</a>. It is a different kind of subject: too many trading strategies but some interesting data, for example <a href="http://oxfordstrat.com/data/global-market-correlations/">global market correlations</a> and <a href="http://oxfordstrat.com/ideas/sharpe-ratio/">ideas</a>.</li>
<li><a href="https://forum.wilmott.com/">Wilmott forums</a> not a blog, but it sometimes (not often) has interesting discussions and can be a good way to connect.</li>
</ul>
<p>Another way to find out what&rsquo;s going on in the quantitative finance world is to scan regularly recent papers on <a href="https://arxiv.org/list/q-fin/recent">arxiv</a>, <a href="http://www.ssrn.com">SSRN</a> or the suggestions of <a href="http://scholar.google.com">Google scholar</a>.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/typo-in-hyman-non-negative-constraint/">Typo in Hyman non-negative constraint - 28 years later</a>
  </h1>
  <time datetime="2017-05-23T23:56:42&#43;0100" class="post-date">Tue, May 23, 2017</time>
  <p>In their paper <a href="http://www.ams.org/journals/mcom/1989-52-186/S0025-5718-1989-0962209-1/S0025-5718-1989-0962209-1.pdf">&ldquo;Nonnegativity-, Monotonicity-, or Convexity-Preserving Cubic and Quintic Hermite Interpolation&rdquo;</a>, Dougherty, Edelman and Hyman present a simple filter on the first derivatives to maintain positivity of a cubic spline interpolant.</p>
<p>Unfortunately, in their main formula for non-negativity, they made a typo: the equation (3.3) is not consistent with the equation (3.1): the  \( \Delta x_{i-1/2} \)  is interverted with  \( \Delta x_{i+1/2} \).</p>
<p>It was not obvious to find out which equation was wrong since there is no proof in the paper. Fortunately, the proof is in the reference paper <a href="http://epubs.siam.org/doi/abs/10.1137/0722023">&ldquo;Monotone piecewise bicubic interpolation&rdquo;</a> from Carlson and Fritsch and it is clear then that equation (3.1) is the correct one.</p>
<p>Here is a counter example for equation (3.3) for a Hermite cubic spline with natural boundary conditions</p>
<!-- raw HTML omitted -->
<p>In the above example, even though the step size \Delta x is constant, the error is visible at the last node since then only one inequation apply, and it will be different with the typo.</p>
<p>It is quite annoying to stumble upon such typos, especially when the equations stem from a derived correct paper. We wonder then where are the other typos in the paper and our trust in the equations is greatly weakened. Unfortunately, such mistakes happen to everybody, including myself, and they are rarely caught by reviewers.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/implied-volatility-from-black-scholes-price/">Implied Volatility from Black-Scholes price</a>
  </h1>
  <time datetime="2017-04-02T07:56:42&#43;0100" class="post-date">Sun, Apr 2, 2017</time>
  <p>Dan Stefanica and Rados Radoicic propose a quite good initial guess in their very recent paper <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2908494">An Explicit Implied Volatility Formula</a>. Their formula is simple, fast to compute and results in an implied volatility guess with a relative error of less than 10%.</p>
<p>It is more robust than the rational fraction from <a href="https://mpra.ub.uni-muenchen.de/6867/1/MPRA_paper_6867.pdf">Minquiang Li</a>: his rational fraction is only valid for a fixed range of strikes and maturities. The new approximation is mathematically proved accurate across all strikes and all maturities. There is only the need to be careful in the numerical implementation with the case where the price is very small (a Taylor expansion of the variable C will be useful in this case).</p>
<p>As mentioned in an <a href="/post/fast-and-accurate-implied-volatility-solver/">earlier post</a>, Peter Jäckel solved the real problem by providing the code for a fast, very accurate and robust solver along with his paper <a href="http://jaeckel.16mb.com/LetsBeRational.pdf">Let&rsquo;s be rational</a>. This new formula used as initial guess to Minquiang Li SOR-TS solver provides an interesting alternative: the resulting code is very simple and efficient. The accuracy, relative or absolute can be set to eventually speedup the calculation.</p>
<p>Below is an example of the performance on a few different cases for strike 150, forward 100, time to maturity 1.0 year and a relative tolerance of 1E-8 using <a href="https://golang.org/">Go 1.8</a>.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Original volatility</th>
<th style="text-align:center">Method</th>
<th style="text-align:left">Implied Volatility</th>
<th style="text-align:right">Time</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">64%</td>
<td style="text-align:center">Jäckel</td>
<td style="text-align:left">0.6400000000000002</td>
<td style="text-align:right">1005 ns</td>
</tr>
<tr>
<td style="text-align:center">64%</td>
<td style="text-align:center">Rational</td>
<td style="text-align:left">0.6495154924570236</td>
<td style="text-align:right">72 ns</td>
</tr>
<tr>
<td style="text-align:center">64%</td>
<td style="text-align:center">SR</td>
<td style="text-align:left">0.6338265040549524</td>
<td style="text-align:right">200 ns</td>
</tr>
<tr>
<td style="text-align:center">64%</td>
<td style="text-align:center">Rational-Li</td>
<td style="text-align:left">0.6400000010047917</td>
<td style="text-align:right">436 ns</td>
</tr>
<tr>
<td style="text-align:center">64%</td>
<td style="text-align:center">SR-Li</td>
<td style="text-align:left">0.6400000001905617</td>
<td style="text-align:right">568 ns</td>
</tr>
<tr>
<td style="text-align:center">16%</td>
<td style="text-align:center">Rational</td>
<td style="text-align:left">0.1575005551326285</td>
<td style="text-align:right">72 ns</td>
</tr>
<tr>
<td style="text-align:center">16%</td>
<td style="text-align:center">SR</td>
<td style="text-align:left">0.15117970813645165</td>
<td style="text-align:right">200 ns</td>
</tr>
<tr>
<td style="text-align:center">16%</td>
<td style="text-align:center">Jäckel</td>
<td style="text-align:left">0.16000000000000025</td>
<td style="text-align:right">1323 ns</td>
</tr>
<tr>
<td style="text-align:center">16%</td>
<td style="text-align:center">Rational-Li</td>
<td style="text-align:left">0.16000000000219483</td>
<td style="text-align:right">714 ns</td>
</tr>
<tr>
<td style="text-align:center">16%</td>
<td style="text-align:center">SR-Li</td>
<td style="text-align:left">0.16000000000018844</td>
<td style="text-align:right">1030 ns</td>
</tr>
<tr>
<td style="text-align:center">4%</td>
<td style="text-align:center">Rational</td>
<td style="text-align:left">0.1528010258201771</td>
<td style="text-align:right">72 ns</td>
</tr>
<tr>
<td style="text-align:center">4%</td>
<td style="text-align:center">SR</td>
<td style="text-align:left">0.043006234681405076</td>
<td style="text-align:right">190 ns</td>
</tr>
<tr>
<td style="text-align:center">4%</td>
<td style="text-align:center">Jäckel</td>
<td style="text-align:left">0.03999999999999886</td>
<td style="text-align:right">1519 ns</td>
</tr>
<tr>
<td style="text-align:center">4%</td>
<td style="text-align:center">Rational-Li</td>
<td style="text-align:left">0.040000000056277685</td>
<td style="text-align:right">10235 ns</td>
</tr>
<tr>
<td style="text-align:center">4%</td>
<td style="text-align:center">SR-Li</td>
<td style="text-align:left">0.040000000000453895</td>
<td style="text-align:right">2405 ns</td>
</tr>
</tbody>
</table>
<p>The case 4% was an example of a particularly challenging setting in a <a href="https://forum.wilmott.com/viewtopic.php?f=34&amp;t=97812&amp;start=75">Wilmott forum</a>. It results in a very small call option price (9E-25).</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/vix-starts-smiling/">The VIX starts smiling</a>
  </h1>
  <time datetime="2017-03-21T07:56:42&#43;0100" class="post-date">Tue, Mar 21, 2017</time>
  <p>The VIX implied volatilities used to look like a logarithmic function of the strikes. I don&rsquo;t look at them often, but today, I noticed that the VIX had the start of a smile shape.</p>
<figure><img src="/post/vix_smile.png"/><figcaption>
            <h4>1m VIX implied volatilities on March 21, 2017 with strictly positive volume.</h4>
        </figcaption>
</figure>

<p>Very few strikes trades below the VIX future level (12.9). All of this is likely because the VIX is unusually low: not many people are looking to trade it much lower.</p>
<p><strong>Update March 22:</strong> Actually the smile in VIX is not particularly new, it is visible in Jim Gatheral 2013 presentation <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiF2LP9turSAhUJVBQKHUVFCIoQFggoMAA&amp;url=http%3A%2F%2Fmfe.baruch.cuny.edu%2Fwp-content%2Fuploads%2F2012%2F09%2FBeijingSPXVIX2013.pdf&amp;usg=AFQjCNHCx2b2AXNXPHixUAYQC2nWH9ULHQ">Joint modeling of SPX and VIX</a> for the short maturities. Interestingly, <a href="/post/when-svi-breaks-down/">the issue with SVI</a> is also visible in those slides in the shortest maturity.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/when-svi-breaks-down/">When SVI Breaks Down</a>
  </h1>
  <time datetime="2017-03-16T07:56:42&#43;0100" class="post-date">Thu, Mar 16, 2017</time>
  <p>In order to fit the implied volatility smile of equity options, one of the most popular parameterization is Jim Gatheral&rsquo;s SVI, which I have written about before <a href="/post/another-svi-initial-guess/">here</a>.</p>
<p>It turns out that in the current market conditions, SVI does not work well for short maturities. <a href="http://www.optionistics.com/quotes/stock-option-chains/SPX">SPX options</a> expiring on March 24, 2017 (one week) offer a good example. I paid attention to include only options with non zero volume, that is options that are actually traded.</p>
<figure><img src="/post/spxw_03242017.png"/><figcaption>
            <h4>SPXW implied volatilities on March 16, 2017 with strictly positive volume.</h4>
        </figcaption>
</figure>

<p>SVI does not fit well near the money (the SPX index is at 2385) and has an obviously wrong right wing. This is not due to the choice of weights used for the calibration (I used the volume as weight; equal weights would be even worse). Interestingly, SABR (with beta=1) does much better, even though it has two less parameters than SVI. Also a simple least squares parabola here does not work at all as it ends up fitting only the left wing.</p>
<p>If we include all options with non zero open interest and use ask/(bid-ask) weights, SVI is even worse:
<figure><img src="/post/spxw_03242017f.png"/><figcaption>
            <h4>SPXW implied volatilities on March 16, 2017 with strictly positive open interest.</h4>
        </figcaption>
</figure>
</p>
<p>We can do a bit better with SVI by squaring the weights and it shows the problem of SVI more clearly:
<figure><img src="/post/spxw_03242017f2.png"/><figcaption>
            <h4>SPXW implied volatilities on March 16, 2017 with strictly positive open interest and SVI weights squared.</h4>
        </figcaption>
</figure>
</p>
<p>These days, the VIX index is particularly low. Today, it is at 11.32. Usually, a low VIX translates to growing stocks as investors are confident in a low volatility environment. The catch with those extremely low ATM vols, is that the curvature is more pronounced, and so people are not so confident after all.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/brownian-bridge-and-discrete-sampling/">Brownian Bridge and Discrete Random Variables</a>
  </h1>
  <time datetime="2017-01-26T14:55:32&#43;0100" class="post-date">Thu, Jan 26, 2017</time>
  <p>The <a href="/post/a-new-scheme-for-heston">new Heston discretisation scheme</a> I wrote about a few weeks ago makes use
a discrete random variable matching the first five moments of the normal distribution instead of the usual
normally distributed random variable, computed via the inverse cumulative distribution function. Their discrete random
variable is:
$$\xi =	\sqrt{1-\frac{\sqrt{6}}{3}} \quad \text{ if } U_1 &lt; 3,,$$
$$	\xi =-\sqrt{1-\frac{\sqrt{6}}{3}} \quad \text{ if } U_1 &gt; 4,,$$
$$\xi =	\sqrt{1+\sqrt{6}} \quad \text{ if } U_1 = 3,,$$
$$\xi =	-\sqrt{1+\sqrt{6}} \quad \text{ if } U_1 = 4,,$$
with \(U_1 \in \{0,1,&hellip;,7\}\)</p>
<p>The advantage of the discrete variable is that it is much faster to generate. But there are some interesting
side-effects. The first clue I found is a loss of accuracy on forward-start vanilla options.</p>
<p>By accident, I found a much more interesting side-effect: you can not use the Brownian-Bridge variance reduction
on the discrete random variable. This is very well illustrated by the case
of a digital option in the Black model, for example with volatility 10% and a 3 months maturity, zero interest rate and dividends. For the following graph,
I use 16000 Sobol paths composed of 100 time-steps.</p>
<figure><img src="/post/black_discrete_sampling.png"/><figcaption>
            <h4>Digital Call price with different random variables.</h4>
        </figcaption>
</figure>

<p>The &ldquo;-BB&rdquo; suffix stands for the Brownian-Bridge path construction, &ldquo;Five&rdquo; for five moments discrete variable
and &ldquo;AS241&rdquo; for the inverse cumulative distribution function (continuous approach). As you can see,
the price is discrete, and follows directly from the discrete distribution.
The use of any random number generator with a large enough number of paths would lead to the same conclusion.</p>
<p>This is because with the Brownian-Bridge technique, the last point in the path, corresponding to the maturity,
is sampled first, and the other path points are then completed inside from the first and last points.
But the digital option depends only on the value of the path at maturity, that is, on this last point.
As this point corresponds follows our discrete distribution, the price of the digital option is a step function.</p>
<p>In contrast, for the incremental path construction, each point is computed from the previous point.
The last point will thus include the variation of all points in the path, which will be very close to normal, even with a discrete distribution per point.</p>
<p>The take-out to price more exotic derivatives (including forward-start options) with discrete random variables
and the incremental path construction, is that several intermediate time-steps (between payoff observations)
are a must-have with discrete random variables, however small is the original time-step size.</p>
<p>Furthermore, one can notice the discrete staircase even with a relavely small time-step for example of 1/32 (meaning 8 intermediate time-steps in
our digital option example). I suppose this is a direct consequence of the digital payoff discontinuity. In Talay
<a href="http://link.springer.com/chapter/10.1007/BFb0006577">&ldquo;Efficient numerical schemes for the approximation of expectations of functionals of the solution of a SDE, and applications&rdquo;</a> (which you can
read by adding .sci-hub.cc to the URL host name), second order convergence
is proven only if the payoff function and its derivatives up to order 6 are continuous. There is something natural
that a discrete random variable imposes continuity conditions on the payoff, not necessary with a continuous,
smooth random variable: either the payoff or the distribution needs to be smooth.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/samsung_wireless_printer_fedora25/">Samsung Wireless Printer under Fedora 25</a>
  </h1>
  <time datetime="2017-01-26T09:55:32&#43;0100" class="post-date">Thu, Jan 26, 2017</time>
  <p>This is a note for those who want to setup a Samsung wireless printer under Linux. It is quite simple,
<a href="https://ubuntuforums.org/showthread.php?t=2263245">this forum post</a> helped me, the actual useful steps on Fedora 25 are:</p>
<ul>
<li>download tar.gz linux driver from <a href="http://www.samsungsetup.com/">Samsung website</a>. As root, unpack &amp; install:</li>
</ul>
<pre tabindex="0"><code>tar xvzf SamsungPrinterInstaller.tar.gz 
cd uld
./install.sh
</code></pre><ul>
<li>in the printer menu, lookup for the wireless key (8 digits),</li>
<li>connect to the printer Wifi network with a computer using the wireless key,</li>
<li>enter the network gateway IP, this is typically <a href="http://192.168.3.1">http://192.168.3.1</a>,</li>
<li>click on Login with user &ldquo;admin&rdquo; and password &ldquo;sec00000&rdquo;,</li>
<li>open the network wifi settings and select &ldquo;Easy Wi-Fi Settings&rdquo;,</li>
<li>connect back to your wireless network,</li>
<li>add the network printer via the printer settings wizard, or alternatively through CUPS interface <a href="http://localhost:631">http://localhost:631</a>.</li>
</ul>
<p>That&rsquo;s it. Printer and scanner will then work on your local Wi-Fi network.</p>

  
</article>
</div>
<p style="text-align:left; width:49%; display: inline-block;"><a href="/page/3/">Previous</a></p>
<p style="text-align:right; width:50%;  display: inline-block;"><a href="/page/5/">Next</a></p>
    </main>

    
      
    
  </body>
</html>
