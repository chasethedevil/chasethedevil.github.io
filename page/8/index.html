<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.23" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Chase the Devil &middot; </title>

  
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/poole.css">
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/hyde-x.css">
  <link rel="stylesheet" href="http://chasethedevil.github.io/css/highlight/sunburst.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=UnifrakturMaguntia:400,700">
    <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://chasethedevil.github.io/touch-icon-144-precomposed.png">
  <link href="http://chasethedevil.github.io/favicon.png" rel="icon">

  
  
  
  <link href="http://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil &middot; " />

  <meta name="description" content="">
  <meta name="keywords" content="">
  
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-365717-1', 'auto');
    ga('send', 'pageview');
  </script>
  
<script type="text/javascript"
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<link href=' http://fonts.googleapis.com/css?family=UnifrakturMaguntia' rel='stylesheet' type='text/css'>
</head>
<body class="theme-base-00">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1>Chase the Devil</h1>
      <p class="lead">Technical blog for Fabien.</p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="http://chasethedevil.github.io/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="http://chasethedevil.github.io/about/">About</a></li>
      
      <li class="sidebar-nav-item"><a href="http://chasethedevil.github.io/post/">Posts</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>  
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="http://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

    
  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/on-the-importance-of-accuracy-for-bpvol-solvers/">On the importance of accuracy for bpvol solvers</a>
      </h1>
      <span class="post-date">Jun 12, 2014 &middot; 2 minute read &middot; <a href="http://chasethedevil.github.io/post/on-the-importance-of-accuracy-for-bpvol-solvers/#disqus_thread">Comments</a>
      </span>
      
      <p>While I was playing around calibrating the arbitrage free SABR model from Hagan (using the PDE on probability density approach), I noticed a misbehavior for some short maturity smiles. I thought it was due to the PDE implementation. Actually some of it was, but the remaining large error was due to the bpvol solver.<br /><br />I initially took the same approach as Choi et al. in <a href="http://chasethedevil.github.io/post/building-a-more-accurate-basis-point-volatility-formula/" target="_blank">my solver</a>, that is to work with in-the-money prices (they work with straddles) because it&rsquo;s nice and convenient. I thought it was no big deal if prices lower than 1E-16 were not solved. It turns out I was wrong. Choi et al. solver has the same issue.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-OhKc0_EA0oI/U5nGPTB2ybI/AAAAAAAAHUM/DrRvgORONZo/s1600/Screenshot+-+06122014+-+05:24:27+PM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-OhKc0_EA0oI/U5nGPTB2ybI/AAAAAAAAHUM/DrRvgORONZo/s1600/Screenshot+-+06122014+-+05:24:27+PM.png" height="302" width="400" /></a></div>In the above figure, CKK denotes the Choi et al algorithm (similar with my old algorithm) and Chebyshev is my updated algorithm that is accurate with far out-of-the-money option. What happens is that even though the market price at the lowest strike is not very low, the price at the lowest strike stemming from the best fit smile is extremely low, and when we want to invert it, CKK produces a large error due to lack of representation of numbers near 1.0 as it uses indirectly the in-the-money price. That&rsquo;s where it introduces a particularly big error in this case.<br /><br /><br />I have updated my solver since, to work with out-of-the-money option prices as well, and have near machine accuracy on the whole range. I also reduced the number of Chebyshev polynomials used in the process. All the details are in my updated paper at <a href="http://papers.ssrn.com/abstract=2420757">http://papers.ssrn.com/abstract=2420757</a><br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-VpIX_Pxw3k8/U5nHvLaORvI/AAAAAAAAHUY/hqzbAvsPO9w/s1600/Screenshot+-+06122014+-+05:24:13+PM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-VpIX_Pxw3k8/U5nHvLaORvI/AAAAAAAAHUY/hqzbAvsPO9w/s1600/Screenshot+-+06122014+-+05:24:13+PM.png" height="356" width="400" /></a></div><br /><br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/throws-exception/">throws Exception</a>
      </h1>
      <span class="post-date">May 27, 2014 &middot; 2 minute read &middot; <a href="http://chasethedevil.github.io/post/throws-exception/#disqus_thread">Comments</a>
      </span>
      
      <p>There was a big debate at work around Exception declaration in a Java API. I was quite surprised that such an apparently simple subject could end up being so controversial. The controversy was around the choice of declaring in the interfaces:<br /><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">void myMethod() throws Exception</span></span><br /><br />instead of<br /><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;"><span style="font-size: x-small;">void myMethod() throws MyAPIException</span></span><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;"><span style="font-size: x-small;">void myMethod() throws MyAPIRuntimeException</span></span><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;"><span style="font-size: x-small;">void myMethod() </span></span><br /><br />where MyAPI represents either a generic API related exception or a specific exception related to the method in question.<br /><br />The choice of &ldquo;throws Exception&rdquo; did not even occur to me as a possibility, but after some digging, I found that some relatively famous libraries actually followed that principle at one point, for example Apache Struts 1.x or Spring MVC. <br /><br />More modern libraries, like Google Guava, commons-math 3.x, Struts 2.x generally favor MyAPIRuntimeException where MyAPI is actually context-specific. Some old popular libraries declare a checked Exception, for example the HibernateException in Hibernate.<br /><br />This seems to be a recurring subject on Stackoverflow:<br /><a href="http://stackoverflow.com/questions/20530221/java-interface-throws-exception-best-practice" target="_blank">Stackoverflow - Java interface throws Exception best practice</a><br /><a href="http://stackoverflow.com/questions/4283634/what-to-put-in-the-throws-clause-of-an-interface-method" target="_blank">Stackoverflow - What to put in the throws clause of an interface method</a><br /><br />But those are quite poor in terms of explanations. The best comments on this subjects are from:<br /><a href="http://www.artima.com/intv/handcuffs.html"><span class="ts">Anders         Hejlsberg (C#, Delphi, Turbo Pascal creator) - The Trouble with         Checked Exceptions</span></a><br />    <a href="http://www.artima.com/intv/solid2.html"><span class="ts">James         Gosling (Java creator) - Failure and Exceptions</span></a><br /><br />    <br />This comment from Anders is particularly acute:<br />    &ldquo;<b>To work around this requirement, people do ridiculous things.       For example, they decorate every method with, &ldquo;</b><b><code>throws         Exception</code></b><b>.&rdquo; That just completely defeats the       feature, and you just made the programmer write more gobbledy       gunk. That doesn&rsquo;t help anybody.</b>    &ldquo;<br />    <br /><br />         <br />Today I believe the API in question declares &ldquo;throws Exception&rdquo;&hellip; <br />         <br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/kde-xfce-gnome-shell-in-2014/">KDE, XFCE, Gnome-Shell in 2014</a>
      </h1>
      <span class="post-date">May 25, 2014 &middot; 4 minute read &middot; <a href="http://chasethedevil.github.io/post/kde-xfce-gnome-shell-in-2014/#disqus_thread">Comments</a>
      </span>
      
      <p>Many people (and notoriously, Linus Torvald) complained about Gnome-shell, especially the early iterations. Similarly KDE 4 was a nightmare of instability and inflexibility when it came out. And XFCE has always sounded a bit too basic. the moves of Gnome and KDE were particularly shocking as the earlier iteration: Gnome 2 and KDE 3 were well appreciated, productive environments.<br /><br /><span style="font-size: large;">Gnome Shell 3.10</span><br /><br />It took me a bit of time to get used to it, and in the early stages I went to KDE 4 for a while, only to come back to it later.<br /><br /><ul><li><i>Positive aspects:</i> lots of space on the desktop, things don&rsquo;t get in the way, looks good,very good desktop overview (fast and well presented), a dock by default, great external monitor support (plug and play, remembers settings automatically), best OSD (volume) of all.</li><li><i>Negative aspects:</i> the notifications bar looks awkward and badly integrated (better with an extension), still unstable and big memory leaks (on Fedora 20, where the integration should be the best, it regularly crashes, starts with 300Mb and goes up to 1Gb in a couple of days), fallback-session completely useless as one can not customize it at all. But the killer for my work was&nbsp; inability to share the desktop with Webex, while XFCE could.</li></ul><br /><span style="font-size: large;">KDE</span> <br /><br />I gave it a long try especially in 2012, it has not changed much in 2014. My opinion of it fell when I tried it a very short time after months of Gnome Shell, and even more so after seeing the trouble my parents had with it, compared to Gnome 2.<br /><br /><ul><li><i>Positive aspects:</i> desktop search (needs to be configured in order to scan only the relevant folders, used to be slow and resource intensive, not so much in 2014)<i>&nbsp;</i></li><li><i>Negative aspects:</i> resource hog, awful start menu, too many shiny effects by default that only distract the user from his task, silly concepts like activities, every aspect of the desktop seems to require tweaking in non obvious ways for it to be more usable, looks ok but not great.</li></ul><br /><span style="font-size: large;">XFCE</span><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-nw0i5RiPfz0/U4RIv9aY2pI/AAAAAAAAHTQ/xF9ZwyRtXZk/s1600/Screenshot+-+05272014+-+10:06:57+AM.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-nw0i5RiPfz0/U4RIv9aY2pI/AAAAAAAAHTQ/xF9ZwyRtXZk/s1600/Screenshot+-+05272014+-+10:06:57+AM.png" height="223" width="400" /></a></div><br />On Fedora, the default XFCE is very very basic, so much that I could hardly see a difference with one from 10 years ago. On Xubuntu, it&rsquo;s much much better. When I came to it from Gnome-Shell, I was surprised at how good was the &ldquo;old&rdquo; desktop paradigm for productivity. I also surprisingly found multiple desktops more natural to use than on Gnome Shell/KDE.<br />On Fedora the way to make it like Xubuntu is to install elementary icons, the whisker menu and choose the greybird/bluebird themes.<br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;"><br /></span></span><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">yum groups install &ldquo;Xfce Desktop&rdquo;<br />yum install xfce4-mixer.x86_64 xfce4-whiskermenu-plugin.x86_64 xfce4-cpugraph-plugin.x86_64 xfce4-mount-plugin.x86_64 xfce4-icon-theme.noarch google-droid* elementary-xfce-icon-theme.noarch xfce4-volumed.x86_64 pavucontrol.x86_64</span></span><br /><br /><ul><li><i>Positive aspects:</i> fast and lean, great start menu. </li><li><i>Negative aspects:</i> external monitor support could be more automatic like Gnome-Shell, no nice overview of all windows, default installation can be a bit too bare, sometimes not sexy (volume applet is ugly, xubuntu provides the unity indicators in xfce as a remedy), primitive OSD.</li></ul><span style="font-size: large;"><br /></span><span style="font-size: large;">Cinnamon, Unity, Conclusion</span><br /><br />I gave a short try to cinnamon as well, in hopes that it was more stable than gnome shell. In short, it was not. It&rsquo;s certainly less of a memory hog, but I had some strange behavior with an additional phantom panel sometimes appearing at the bottom at the screen. And overall it looks a lot less polished.<br /><br />Unity is more interesting, but it&rsquo;s too Ubuntu centric, I don&rsquo;t like the start button equivalent (slow, badly presented, don&rsquo;t care about HUD), the windows overview is not as useful as Gnome shell, the dock, something I usually like, is strangely annoying.<br /><br />This is a very subjective review, my feeling is that in 2014, people should not waste their time with KDE or Cinnamon. Gnome shell could be worth a try if you don&rsquo;t care so much about memory leaks and slight instability but value a distraction free desktop. Otherwise go for XFCE or Unity on (X)ubuntu.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/two-sabr-for-the-same-smile/">Two SABR for the same smile</a>
      </h1>
      <span class="post-date">May 20, 2014 &middot; 2 minute read &middot; <a href="http://chasethedevil.github.io/post/two-sabr-for-the-same-smile/#disqus_thread">Comments</a>
      </span>
      
      <p>While playing around with <a href="http://chasethedevil.github.io/post/good--popular-algorithms-are-simple/" target="_blank">differential evolution</a> &amp; SABR calibration, I noticed that sometimes, several set of parameters can lead to a very similar smile, usually the good one is for relatively low vol of vol and the bad one is for relatively high vol of vol. I first looked for errors in my implementation, but it&rsquo;s a real phenomenon.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-W8y6ZCg2RC8/U3snVBI5I8I/AAAAAAAAHNI/JTCgBE4ZR3I/s1600/Screenshot+from+2014-05-19+17:55:50.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-W8y6ZCg2RC8/U3snVBI5I8I/AAAAAAAAHNI/JTCgBE4ZR3I/s1600/Screenshot+from+2014-05-19+17:55:50.png" height="332" width="400" /></a></div><br />I used the normal implied volatility formula with beta=1, then converted it to lognormal (Black) volatility. While it might not be a great idea to rely on the normal formula with beta=1, I noticed the same phenomenon with the <a href="http://chasethedevil.blogspot.fr/2013/05/sabr-with-new-hagan-pde-approach.html" target="_blank">arbitrage free PDE density approach</a>, especially for long maturities. Interestingly, I did not notice such behavior before with other stochastic volatility models like Heston or Schobel-Zhu: I suspect it has to do with the approximations rather than with the true behavior of SABR.<br /><br />Differential evolution is surprisingly good at finding the global minimum without much initial knowledge, however when there are close fits like this it can be more problematic, usually this requires pushing the population size up. I find that differential evolution is a neat way to test the robustness (as well as performance) of different SABR algorithms as it will try many crazy sets.<br /><br />In practice, for real world calibration, there is not much use of differential evolution to calibrate SABR as it is relatively simple to find a good initial guess.<br /><br /><br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/heston-vs-sabr-slice-by-slice-fit/">Heston vs SABR slice by slice fit</a>
      </h1>
      <span class="post-date">May 15, 2014 &middot; 3 minute read &middot; <a href="http://chasethedevil.github.io/post/heston-vs-sabr-slice-by-slice-fit/#disqus_thread">Comments</a>
      </span>
      
      <p>Some people use <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCoQFjAA&amp;url=http%3A%2F%2Fpapers.ssrn.com%2Fsol3%2Fpapers.cfm%3Fabstract_id%3D1496982&amp;ei=nx11U6QOoozQBcrfgIAK&amp;usg=AFQjCNHi149E0_JiOzZRT9kgDWWYvHWlFQ&amp;sig2=ZnhySOuJd8V-jBcWo4Ky2w&amp;bvm=bv.66699033,d.d2k" target="_blank">Heston to fit one slice </a>of a volatility surface. In this case, some parameters are clearly redundant. Still, I was wondering how it fared against SABR, which is always used to fit a slice. And what about Schobel-Zhu?<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-sy-AiaNcXMs/U3UUPfJdrOI/AAAAAAAAHMI/N_WsmNiYEqA/s1600/Screenshot+from+2014-05-15+21:20:28.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-sy-AiaNcXMs/U3UUPfJdrOI/AAAAAAAAHMI/N_WsmNiYEqA/s1600/Screenshot+from+2014-05-15+21:20:28.png" height="317" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Aggregated error in fit per slice on 10 surfaces</td></tr></tbody></table>With Heston, the calibration is actually slightly better with kappa=0, that is, without mean reversion, because the global optimization is easier and the mean reversion is fully redundant. It&rsquo;s still quite remarkable that 3 parameters result in a fit as good as 5 parameters.<br />This is however not the case for Schobel-Zhu, where each &ldquo;redundant parameter&rdquo; seem to make a slight difference in the quality of calibration. kappa = 0 deteriorate a little bit the fit (the mean error is clearly higher), and theta near 0 (so calibrating 4 parameters) is also a little worse (although better than kappa = 0). Also interestingly, the five parameters Schobel-Zhu fit is slightly better than Heston, but not so when one reduce the number of free parameters.<br /><br />So what about Heston vs SABR. It is interesting to consider the case of general Beta and Beta=1: it turns out that as confirmed for equities, beta=1 is actually a better choice.<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-F8dl70uVMdY/U3UXMSvx3lI/AAAAAAAAHMQ/IvKzxaEo6NI/s1600/Screenshot+from+2014-05-15+21:34:49.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-F8dl70uVMdY/U3UXMSvx3lI/AAAAAAAAHMQ/IvKzxaEo6NI/s1600/Screenshot+from+2014-05-15+21:34:49.png" height="507" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Aggregated error in fit per slice on 10 surfaces</td></tr></tbody></table><br />Overall on my 10 surfaces composed each of around 10 slices, an admittedly small sample, Heston (without mean-reversion) fit is a little bit better than SABR. Also the <a href="http://chasethedevil.github.io/post/svi-on-top-of-sabr/" target="_blank">SVI-SABR</a> idea from Gatheral is not great: the fit is clearly worse than SABR with Beta=1 and even worse than a simple quadratic.<br />Of course the best overall fit is achieved with the classic SVI, because it has 6 parameters while the others have only 3.<br /><br />All the calibrations so far were done slice by slice independently, using levenberg marquardt on an initial guess found by differential evolution. Some people advocate for speed or stability of parameters reasons the idea of calibrating each slice using the previous slice as initial guess with a local optimizer like levenberg marquardt, in a bootstrapping fashion.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-9d15Ef2O-eo/U3UaxZ_lsOI/AAAAAAAAHMc/JmE5Feup4f0/s1600/Screenshot+from+2014-05-15+21:51:18.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-9d15Ef2O-eo/U3UaxZ_lsOI/AAAAAAAAHMc/JmE5Feup4f0/s1600/Screenshot+from+2014-05-15+21:51:18.png" height="317" width="400" /></a></div>The results can be quite different, especially for SVI, which then becomes the worst, even worse than SVI-SABR, which is actually a subset of SVI with fewer parameters. How can this be? <br /><br />This is because as the number of parameters increases, the first slices optimizations have a disproportionate influence, and finding the real minimum is much more difficult, even with differential evolution for the first slice. It&rsquo;s easy to picture that you&rsquo;ll have much more chances to get stuck in some local minimum.<br />It&rsquo;s interesting to note that the real stochastic volatility models are actually better behaved in this regard, but I am not so sure that this kind of calibration is such a great idea in general.<br /><br />In practice, the SVI parameters fitted independently evolve in a given surface on each slice in a smooth manner, mostly monotonically. It&rsquo;s just that to go from one set on one slice to the other on the next slice, you might have to do something more than a local optimization.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/quadratic-spline-with-knots-at-mid-points/">Quadratic Spline with Knots at Mid-Points</a>
      </h1>
      <span class="post-date">May 14, 2014 &middot; 2 minute read &middot; <a href="http://chasethedevil.github.io/post/quadratic-spline-with-knots-at-mid-points/#disqus_thread">Comments</a>
      </span>
      
      <p>Two months ago, I looked at <a href="http://chasethedevil.github.io/post/arbitrage-free-interpolation-of-option-prices-using-piecewise-constant-density/" target="_blank">arbitrage free interpolation using piecewise-constant density</a>. This is equivalent to a piecewise quadratic polynomial in call prices where each piece is centered around each call strike.<br /><br />I wondered at the time what a quadratic spline would look like on this problem, as it should be very close in theory, except that we can ensure that it is C1, a condition for a good looking implied volatility.<br /><br />For a while, I did not find any references around splines where knots are in between two interpolation points and derived my own formula. And then I lost the paper, but out of curiosity, I looked at the excellent De Boor book &ldquo;<a href="http://www.amazon.com/Practical-Splines-Applied-Mathematical-Sciences/dp/0387953663" target="_blank">A Practical Guide to Splines</a>&rdquo; and found that there was actually a chapter around this: quadratic splines with knots at mid-points. Interestingly, it turns out that a quadratic spline on standard knots is not always well defined, which is why, if one does quadratic splines, the knots need to be moved.<br /><br />The papers from this era are quite rudimentary in their presentation (the book is much better). I found the paper from Demko 1977 &ldquo;<a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCoQFjAA&amp;url=http%3A%2F%2Fwww.sciencedirect.com%2Fscience%2Farticle%2Fpii%2F0021904578900904&amp;ei=oldzU8i0EsTY0QX3xIH4Bg&amp;usg=AFQjCNH8gbNKzPTyFH3xI-FDPJZIAFJAbg&amp;sig2=5fGbnp0Kaf3fx-KZDf5AiA&amp;bvm=bv.66699033,d.d2k" target="_blank">Interpolation by Quadratic Splines</a>&rdquo; quite usable for coding. I adjusted the boundaries to make the first and last quadratic fit the first two/last two strikes (adding a first strike at 0 and a large last strike if necessary) and spend countless time worrying about indices. The result on a simple classic example is interesting.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://2.bp.blogspot.com/-gFaieqqfxOY/U3NZabgplZI/AAAAAAAAHLc/Ilu6Of0U18k/s1600/Screenshot+from+2014-05-14+13:52:54.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://2.bp.blogspot.com/-gFaieqqfxOY/U3NZabgplZI/AAAAAAAAHLc/Ilu6Of0U18k/s1600/Screenshot+from+2014-05-14+13:52:54.png" height="332" width="400" /></a></div>On the non monotonic discrete density data of my earlier blog entry, this gives:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-5vz9Gfle_4s/U3Na_BXCrsI/AAAAAAAAHLo/-5nrMhsLwKY/s1600/Screenshot+from+2014-05-14+14:00:08.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-5vz9Gfle_4s/U3Na_BXCrsI/AAAAAAAAHLo/-5nrMhsLwKY/s1600/Screenshot+from+2014-05-14+14:00:08.png" height="332" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">QSpline is the quadratic spline</td></tr></tbody></table>Unfortunately, interpolating small prices with such a spline results in a highly oscillating interpolation: this is the <a href="http://www.sciencedirect.com/science/article/pii/0021904591900348" target="_blank">Gibbs phenomenon for splines</a>. We need to loose strict C1 continuity for practical applications, and use a first derivative approximation instead, very much like the Harmonic cubic spline.<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://1.bp.blogspot.com/-vREiCCtH0Ko/U3Nb3ofEfLI/AAAAAAAAHLw/Im482o1J5QY/s1600/Screenshot+from+2014-05-14+14:04:33.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://1.bp.blogspot.com/-vREiCCtH0Ko/U3Nb3ofEfLI/AAAAAAAAHLw/Im482o1J5QY/s1600/Screenshot+from+2014-05-14+14:04:33.png" height="332" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">On Jaeckel data, the quadratic spline on prices is highly oscillating</td></tr></tbody></table><br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/on-interviewing-candidates-for-a-job/">On Interviewing Candidates for a Job</a>
      </h1>
      <span class="post-date">Apr 23, 2014 &middot; 3 minute read &middot; <a href="http://chasethedevil.github.io/post/on-interviewing-candidates-for-a-job/#disqus_thread">Comments</a>
      </span>
      
      <p>I am going to write a little about my experience and conclusions so far around interviewing a candidate for a software developer position or for a quant position, but it should be quite general.<br /><br />At first, I used to ask interview questions I liked when I was myself a candidate. On the technical side, it would stuff like:<br /><ul><li>which design patterns do you know?</li><li>what&rsquo;s your opinion on design patterns?</li><li>what&rsquo;s a virtual method?</li><li>any interesting algorithm you like?</li><li>which libraries did you use?</li></ul>For a quant type I&rsquo;d ask more specific questions<br /><ul><li>what&rsquo;s a Brownian motion?</li><li>what&rsquo;s the Stratanovitch integral?</li><li>why do we use the Ito integral in finance?</li><li>questions on numerical methods: Monte-Carlo and finite differences.</li><li>questions on financial details.&nbsp;</li></ul>I found the approach mostly frustrating: very few people would give interesting (or even good) answers, because most people are not that well prepared for the interview. The exception goes to the academic kind of guy, who usually gives excellent answers, sometimes so good that you feel dumb asking those questions.<br /><br />People who don&rsquo;t give good answers could actually be good coworkers. When I was junior, I was particularly bad at job interviews. I did not necessarily know object orienting concepts that well, even if I started programming at an early age. After a few years, I did not know database theory well either because I had experience only with simple queries, having mostly worked on other stuff. A failed interview made me look more closely at the subject, and it turns out that you can sound like an expert after reading only 1 relatively short book (and the theory is actually quite interesting). I went later to the extreme of complex queries, and then realized <a href="http://chasethedevil.github.io/post/use-orm-for-better-performance/" target="_blank">why ORMs are truely important</a>. Similarly when I first interviewed for the &ldquo;finance&rdquo; industry, I sounded very dumb, barely knowing what options were. It&rsquo;s natural to make mistakes, and to not know much. I learnt all that through various mentor coworkers who indirectly encouraged me with their enthusiasm to read the right stuff. What&rsquo;s valuable is the ability to learn, and maybe, when you are very experienced, your past experiences (which might not match at all the interviewer knowledge).<br /><br />Similarly, I sometimes appeared extremely good to interviewers, because it turned out I had practiced similar tests as their own out of curiosity not much time before the interview. <br /><br />There is also a nasty aspect on asking precise pre-formatted technical questions, you will tend to think that everybody is dumb because they can&rsquo;t answer those basic questions you know so well, turning you into an arrogant asshole.<br /><br />I also tried asking probability puzzles (requiring only basic maths knowledge). This gave even less clues towards the candidates in general, except for the exceptional one, where, again you feel a bit dumb for asking those.<br /><br />In the end, I noticed that the most interesting part of the interview was to discuss a subject the candidate knew well, with the idea of trying to extract knowledge from the candidate, to learn something from him.<br /><br />I believe this is might be what the interview should only be about. Furthermore, you don&rsquo;t feel like you are losing your time with such an approach. <br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/non-linear-option-pricing/">Non-linear Option Pricing</a>
      </h1>
      <span class="post-date">Apr 18, 2014 &middot; 2 minute read &middot; <a href="http://chasethedevil.github.io/post/non-linear-option-pricing/#disqus_thread">Comments</a>
      </span>
      
      <p>I am currently reading the book &ldquo;<a href="http://www.amazon.co.uk/Nonlinear-Pricing-Chapman-Financial-Mathematics/dp/1466570334/ref=sr_1_1?ie=UTF8&amp;qid=1397852099&amp;sr=8-1&amp;keywords=nonlinear+option+pricing" target="_blank">Nonlinear Option Pricing</a>&rdquo; by J. Guyon and P. Henry-Labordère. It&rsquo;s quite interesting even if the first third is quite theoretical. For example they describe how to solve some not well defined non-linear parabolic PDE by relying on the parabolic envelope. They also explain why most problems lead to parabolic PDEs in finance. <br /><br />The rest is a bit more practical. I stumbled upon an good remark regarding Longstaff-Schwartz: the algorithm as Longstaff and Schwarz describe it does not necessary lead to a low-biased estimate as they use future information (the paths they regress on) in the Monte-Carlo estimate. It was actually <a href="http://chasethedevil.github.io/post/quasi-monte-carlo--longstaff-schwartz-american-option-price/" target="_blank">a subject of discussion</a> with colleagues, and I analyzed the numerical impact in a simple use case in <a href="http://papers.ssrn.com/abstract=2262259">http://papers.ssrn.com/abstract=2262259</a> In short: it&rsquo;s actually more precise to include the path, even if the estimate is not purely low biased anymore, but the bias is really small in practice. <br /><br />On the same subject I was a bit surprised that <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CCgQFjAA&amp;url=http%3A%2F%2Farxiv.org%2Fabs%2F1404.1180&amp;ei=LYhRU_iZGqWO7Qb9x4HYDQ&amp;usg=AFQjCNGfwQQ-TumcT5nv8gk1BiUCoRn8Qw&amp;sig2=uqPbG7aLjmZ1crAxUYP_FA&amp;bvm=bv.65058239,d.ZGU" target="_blank">a recent paper</a> on American Monte-Carlo regressed systematically on all paths instead of just a subset. One interesting part of the paper is a way to do successive regressions on different blocks of paths.<br /><br />Those details are rarely discussed in papers and books. It was comforting to see that I am not alone to wonder about all this.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/5-minutes-of-xtend/">5 Minutes of Xtend</a>
      </h1>
      <span class="post-date">Apr 8, 2014 &middot; 1 minute read &middot; <a href="http://chasethedevil.github.io/post/5-minutes-of-xtend/#disqus_thread">Comments</a>
      </span>
      
      <p>There is a relatively new JVM based language, <a href="https://www.eclipse.org/xtend" target="_blank">Xtend</a>. Their homepage says &ldquo;<b>JAVA 10, TODAY!</b>&rdquo;, so I thought I would give it a try, I was especially interested in operator overloading support, and the fact that it compiles to Java code, not Java byte code.<br /><br />Unfortunately, after 5 minutes with it, and pasting some non Java code in an xtend file, Eclipse hangs forever, even on restart. After creating another workspace, just to trash the new workspace a similar way. This is quite incredible for a nearly 2 years old project, on eclipse.org.<br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="http://chasethedevil.github.io/post/building-a-more-accurate-basis-point-volatility-formula/">Building a more accurate basis point volatility formula</a>
      </h1>
      <span class="post-date">Apr 5, 2014 &middot; 3 minute read &middot; <a href="http://chasethedevil.github.io/post/building-a-more-accurate-basis-point-volatility-formula/#disqus_thread">Comments</a>
      </span>
      
      <p>P. Jaeckel has defied the limits of accuracy with his<a href="http://www.pjaeckel.webspace.virginmedia.com/LetsBeRational.7z" target="_blank"> latest Black-Scholes volatility solver</a>, managing to also improve performance compared to his earlier solver &ldquo;<a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0CC8QFjAA&amp;url=http%3A%2F%2Fwww.pjaeckel.webspace.virginmedia.com%2FByImplication.pdf&amp;ei=dwNAU5zkO4aI7AaFy4H4BQ&amp;usg=AFQjCNF1RnfynBrckd79E9RVbhVhuXQrQg&amp;sig2=kOxFO9jmD3wL1E94GjYhRQ&amp;bvm=bv.64125504,d.ZGU" target="_blank">By Implication</a>&rdquo;. Out of a silly exercise, I decided to try my hand for a more accurate <a href="http://www.clarusft.com/analytic-implied-basis-point-volatility/" target="_blank">Normal (or basis point) volatility solver</a>.<br /><br />In reality, the problem is much simpler in the Bachelier/Normal model. A very basic analysis of Bachelier formula shows that the problem can be reduced to a single variable, as Choi et al explain in <a href="http://www.tandfonline.com/doi/abs/10.1080/13504860802583436" target="_blank">their paper</a>. So the problem is not really one of solving, but one of approximating (the inverse of) a function.<br /><br />The first step to build that function is to actually have a highly accurate slow solver as reference. This is quite easy, I just started with Choi formula and used <a href="http://en.wikipedia.org/wiki/Halley%27s_method" target="_blank">Halley&rsquo;s method</a> to refine. In reality, <a href="http://en.wikipedia.org/wiki/Halley%27s_method" target="_blank">Halley&rsquo;s method</a> is already a bit overkill on this problem: it works impressively well, 1 iteration is enough to have an insane level of accuracy, only noticeable when one works in high precision arithmetic (for example 50 digits). For double precision, <a href="http://en.wikipedia.org/wiki/Newton%27s_method" target="_blank">Newton&rsquo;s method</a> would actually be enough - I initially thought that my Halley&rsquo;s implementation did not work as it produced the exact same output as Newton in double precision. <a href="http://www.tandfonline.com/doi/abs/10.1080/14697680902849361" target="_blank">Li proposes</a> the use of the SOR method, which for this exercise, behaves very much like Newton&rsquo;s method.<br /><br />I then followed the logic from Choi et al, but working directly with in-the-money call options instead of <a href="http://en.wikipedia.org/wiki/Straddle" target="_blank">straddles</a>. Straddles sound neat at first (hides that we work in-the-money), but it&rsquo;s actually useless for the algorithm. Choi et al. ignore half of the straddle range when they use their eta transform in the paper. One other change is the mapping itself, I found a better mapping for the call options (but not that far of Choi initial idea). Finally, because I am lazy, I did not go to the pain of finding a good rational fraction approximation along with the square root problem they describe, I just tried a Chebyshev polynomial.<br /><br />Unfortunately, a single Chebyshev polynomial does not work well: even with a very large (1000) degree it&rsquo;s not very precise, so much that I thought that my transform was garbage. I had noticed by mistake, that on another part (negative) of the interval, the Chebyshev polynomial worked actually very well to approximate something related to the volatility of another option. Suddendly came to me the idea of, like Johnson does in <a href="http://ab-initio.mit.edu/wiki/index.php/Faddeeva_Package" target="_blank">his Faddeeva package</a>, using N Chebyshev polynomials on N small intervals. This is like the big heavy hammer for which everything looks like nails, but it&rsquo;s actually very fast to evaluate as the degree of each polynomial can then be low (7), plus a table lookup (could be coded as switch statements if one really cares about such details). The slowest part is actually the call to the log function.<br /><br />The final bit is the use of a Taylor approximation for my -u/log(1-u) transform as it is not all that accurate in double precision when u is near 0. And that produces the following graph<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-r3FCXrjN13k/U0AHWIg7MRI/AAAAAAAAHGU/yDE6BEPtmIs/s1600/Screenshot+from+2014-04-05+15%253A37%253A03.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-r3FCXrjN13k/U0AHWIg7MRI/AAAAAAAAHGU/yDE6BEPtmIs/s1600/Screenshot+from+2014-04-05+15%253A37%253A03.png" height="342" width="400" /></a></div><br />It is interesting to note that &ldquo;solving&rdquo; the b.p. vol is <b>10x faster</b> than solving the Black vol.<br /><br />I wrote <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2420757" target="_blank">a small paper around all this</a> where you&rsquo;ll find the details as well as Matlab code.</p>

      
    </div>
    
    

<ul class="pagination">
    
    <li>
        <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li
    >
    <a href="/page/7/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/">1</a></li>
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/page/2/">2</a></li>
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="disabled"><span aria-hidden="true">&hellip;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/page/7/">7</a></li>
    
    
    
    
    
     
        
        
    
    
    <li
    class="active"><a href="/page/8/">8</a></li>
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/page/9/">9</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="disabled"><span aria-hidden="true">&hellip;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
     
        
        
    
    
    <li
    ><a href="/page/37/">37</a></li>
    
    
    <li
    >
    <a href="/page/9/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li>
        <a href="/page/37/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "chasethedevil";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<div class="content container" style="padding-top: 0rem;"-->
 <a href="https://twitter.com/share" class="twitter-share-button"{count} data-hashtags="chasethedevil" data-size="large">Tweet</a>
 <a style="font-size:75%;" href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent(window.location); return false"><i class="fa fa-reddit fa-2x" aria-hidden="true"></i>Submit to reddit</a> 
<table style="border-collapse: collapse;">
     <tr style="padding: 0px; margin: 0px; border: none;">
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">&copy; 2006-16 <a href="http://chasethedevil.github.io/about/">Fabien</a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 0px;"><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding: 0px; margin: 0px; border: none;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</td></tr></table>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</div>
<script src="http://chasethedevil.github.io/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>

<script>
  var _gaq=[['_setAccount','UA-365717-1'],['_trackPageview']];
  (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
  g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
  s.parentNode.insertBefore(g,s)}(document,'script'));
</script>

</body>
</html>

