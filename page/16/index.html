<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.111.3">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Chase the Devil</title>
  <meta name="description" content="A personal, independent, technical blog" />

  
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
<link href="https://fonts.googleapis.com/css2?family=UnifrakturMaguntia&display=swap" rel="stylesheet">
 <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil" />
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://chasethedevil.github.io/"><h1 style="font-family: 'UnifrakturMaguntia', cursive;font-weight: normal;">Chase the Devil</h1></a>
      <p class="lead">
       A personal, independent, technical blog 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://chasethedevil.github.io/">Blog</a> </li>
        <li><a href="/about/"> About </a></li><li><a href="/post/"> Posts </a></li><li><a href="/tags/"> Tags </a></li>
      </ul>

        <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>
 </nav>

    <p>&copy; 2024. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="posts">
<article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/heston-schobel-zhu-bates-double-heston-fit/">Heston, Schobel-Zhu, Bates, Double-Heston Fit</a>
  </h1>
  <time datetime="2013-10-07T19:35:00Z" class="post-date">Mon, Oct 7, 2013</time>
   

I did some experiments fitting Heston, Schobel-Zhu, Bates and Double-Heston to a real world equity index implied volatility surface. I used a global optimizer (differential evolution).<br /><br />To my surprise, the Heston fit is quite good: the implied volatility error is less than 0.42% on average. Schobel-Zhu fit is also good (0.47% RMSE), but a bit worse than Heston. Bates improves quite a bit on Heston although it has 3 more parameters, we can see the fit is better for short maturities (0.33% RMSE). Double-Heston has the best fit overall but it is not that much better than simple Heston while it has twice the number of parameters, that is 10 (0.24 RMSE). Going beyond, for example Triple-Heston, does not improve anything, and the optimization becomes very challenging. With Double-Heston, I already noticed that kappa is very low (and theta high) for one of the processes, and kappa is very high (and theta low) for the other process: so much that I had to add a penalty to enforce constraints in my local optimizer. The best fit is at the boundary for kappa and theta. So double Heston already feels over-parameterized.<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-C_IidKxPcx4/UlKmCDJFLmI/AAAAAAAAG0o/PxOjIyGqdQQ/s1600/heston_cos3d.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="http://3.bp.blogspot.com/-C_IidKxPcx4/UlKmCDJFLmI/AAAAAAAAG0o/PxOjIyGqdQQ/s640/heston_cos3d.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Heston volatility error</td></tr></tbody></table><div class="separator" style="clear: both; text-align: center;"></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-rvjEFAbCS_o/UlKmXZc--7I/AAAAAAAAG0s/yomyHTMJU18/s1600/schobelzhu_cos3d.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="http://3.bp.blogspot.com/-rvjEFAbCS_o/UlKmXZc--7I/AAAAAAAAG0s/yomyHTMJU18/s640/schobelzhu_cos3d.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Schobel-Zhu  volatility error</td></tr></tbody></table><br /><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><br /><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-_628A9dt_nU/UlKmf4oWujI/AAAAAAAAG00/b8fU_hw_oOY/s1600/bates_cos3d.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="http://4.bp.blogspot.com/-_628A9dt_nU/UlKmf4oWujI/AAAAAAAAG00/b8fU_hw_oOY/s640/bates_cos3d.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Bates  volatility error</td></tr></tbody></table><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-ioz8CuCWNmU/UlKmonoZozI/AAAAAAAAG08/eOTk8KiqxD0/s1600/double_heston_cos3d.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" height="480" src="http://4.bp.blogspot.com/-ioz8CuCWNmU/UlKmonoZozI/AAAAAAAAG08/eOTk8KiqxD0/s640/double_heston_cos3d.png" width="640" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Double Heston  volatility error</td></tr></tbody></table><br /><br />Another advantage of Heston is that one can find tricks to find a good initial guess for a local optimizer.<br /><br /><b>Update October 7: </b>My initial fit relied only on differential evolution and was not the most stable as a result. Adding Levenberg-Marquardt at the end stabilizes the fit, and improves the fit a lot, especially for Bates and Double Heston. I updated the graphs and conclusions accordingly. Bates fit is not so bad at all.



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/second-cumulant-of-heston/">Second Cumulant of Heston</a>
  </h1>
  <time datetime="2013-10-03T17:27:00Z" class="post-date">Thu, Oct 3, 2013</time>
  <p>I recently stumbled upon an error in the various papers related to the Heston <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;ved=0CEEQFjAC&amp;url=http%3A%2F%2Fta.twi.tudelft.nl%2Fmf%2Fusers%2Foosterle%2Foosterlee%2FCOS.pdf&amp;ei=qYxNUqryFqXJ0QW5u4HYDA&amp;usg=AFQjCNGaMK8Lotud1DP5qReeLWgpoCA0aA&amp;sig2=fljLmTq0WhG8SCgzaOxXxA&amp;bvm=bv.53537100,d.d2k">Cos method</a> regarding the second cumulant. It is used to define the boundaries of the Cos method. Letting phi be Heston characteristic function, the cumulant generating function is:
$$g(u) = \log(\phi(-iu))$$</p>
<p>And the second cumulant is defined a: <!-- raw HTML omitted -->$$c_2 = g&rsquo;&rsquo;(0)$$<!-- raw HTML omitted --><!-- raw HTML omitted -->Compared to a numerical implementation, the c_2 from the paper is really off in many use cases.</p>
<p>This is where <a href="/post/maxima-for-symbolic-calculus">Maxima</a> comes useful, even if I had to simplify the results by hand. It leads to the following analytical formula:
$$c_2 = \frac{v_0}{4\kappa^3}{ 4 \kappa^2 \left(1+(\rho\sigma t -1)e^{-\kappa t}\right) + \kappa \left(4\rho\sigma(e^{-\kappa t}-1)-2\sigma^2 t e^{-\kappa t}\right)+\sigma^2(1-e^{-2\kappa t}) }\\+ \frac{\theta}{8\kappa^3} { 8 \kappa^3 t - 8 \kappa^2 \left(1+ \rho\sigma t + (\rho\sigma t-1)e^{-\kappa t}\right) + 2\kappa \left( (1+2e^{-\kappa t})\sigma^2 t+8(1-e^{-\kappa t})\rho\sigma \right) \\+ \sigma^2(e^{-2\kappa t} + 4e^{-\kappa t}-5) }$$</p>
<p>In contrast, the paper formula was:
<figure><img src="/post/Screenshot%20from%202013-10-03%2017%2023%2028.png"/>
</figure>
</p>
<p>I saw this while trying to calibrate Heston on a bumped surface: the results were very different with the Cos method than with the other methods. The short maturities were mispriced, except if one pushed the truncation level L to 24 (instead of the usual 12), and as a result one would also need to significantly raise the number of points used in the Cos method. With the corrected formula, it works well with L=12.</p>
<p>Here is an example of failure on a call option of strike, spot 1.0 and maturity 1.0 and not-so-realistic Heston parameters $$\kappa=0.1, \theta=1.12, \sigma=1.0, v_0=0.2, \rho=-0377836$$ using 200 points:</p>
<table>
<thead>
<tr>
<th>Formula</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>New</td>
<td>0.1640581405</td>
</tr>
<tr>
<td>Paper</td>
<td>0.1743425406</td>
</tr>
<tr>
<td>N=30 with 10000 points</td>
<td>0.1640581423</td>
</tr>
</tbody>
</table>
<p><strong>Update March 2014</strong> - this is now described in my paper <a href="http://ssrn.com/abstract=2362968">Fourier Integration and Stochastic Volatility Calibration</a>.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/maxima-for-symbolic-calculus/">Maxima for Symbolic Calculus</a>
  </h1>
  <time datetime="2013-10-02T15:06:00Z" class="post-date">Wed, Oct 2, 2013</time>
  <p>A few years ago, I found an interesting open source symbolic calculus software called <a href="http://www-fourier.ujf-grenoble.fr/~parisse/giac.html%E2%80%8E">Xcas</a>. It can however be quickly limited, for example, it does not seem to work well to compute Taylor expansions with several embedded functions. Google pointed me to another popular open source package, <a href="http://maxima.sourceforge.net/">Maxima</a>. It looks a bit rudimentary (command like interface), but formulas can actually be very easily exported to latex with the tex command. Here is a simple example:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>(%i14) D(x):=sqrt((lambda-rho*eta*x)^2+(-x^2+x)*eta^2);
</span></span><span style="display:flex;"><span>(%i15) G(x) := (lambda - rho*eta*x - D(x))/(lambda - rho*eta*x +D(x));
</span></span><span style="display:flex;"><span>(%i16) tex(taylor((1-exp(-t*D(x)))/(1-G(x)*exp(-t*D(x)))*(lambda - rho*eta*x - D(x)),x,0,3));</span></span></code></pre></div>
<p>$$-{{\left(e^{t,\lambda}-1\right),\eta^2,x}\over{2,e^{t,\lambda},\lambda}}+{{\left(\left(4,e^{t,\lambda},t,\eta^3,\rho+\left(4,\left(e^{t,\lambda}\right)^2-4,e^{t,\lambda}\right),\eta^2\right),\lambda^2+\left(\left(-4,\left(e^{t,\lambda}\right)^2+4,e^{t,\lambda}\right),\eta^3,\rho-2,e^{t,\lambda},t,\eta^4\right),\lambda+\left(\left(e^{t,\lambda}\right)^2-1\right),\eta^4\right),x^2}\over{8,\left(e^{t,\lambda}\right)^2,\lambda^3}}+{{\left(\left(8,\left(e^{t,\lambda}\right)^2,t^2,\eta^4,\rho^2-16,\left(e^{t,\lambda}\right)^2,t,\eta^3,\rho\right),\lambda^4+\left(16,\left(e^{t,\lambda}\right)^2,t,\eta^4,\rho^2+\left(-8,\left(e^{t,\lambda}\right)^2,t^2,\eta^5+\left(16,\left(e^{t,\lambda}\right)^3-16,\left(e^{t,\lambda}\right)^2\right),\eta^3\right),\rho+16,\left(e^{t,\lambda}\right)^2,t,\eta^4\right),\lambda^3+\left(\left(-16,\left(e^{t,\lambda}\right)^3+16,\left(e^{t,\lambda}\right)^2\right),\eta^4,\rho^2+\left(-16,\left(e^{t,\lambda}\right)^2-8,e^{t,\lambda}\right),t,\eta^5,\rho+2,\left(e^{t,\lambda}\right)^2,t^2,\eta^6+\left(-8,\left(e^{t,\lambda}\right)^3+8,e^{t,\lambda}\right),\eta^4\right),\lambda^2+\left(\left(12,\left(e^{t,\lambda}\right)^3-12,e^{t,\lambda}\right),\eta^5,\rho+\left(2,\left(e^{t,\lambda}\right)^2+4,e^{t,\lambda}\right),t,\eta^6\right),\lambda+\left(-2,\left(e^{t,\lambda}\right)^3-\left(e^{t,\lambda}\right)^2+2,e^{t,\lambda}+1\right),\eta^6\right),x^3}\over{32,\left(e^{t,\lambda}\right)^3,\lambda^5}}+\cdots $$
Regarding Taylor expansion, there seems to be quite a few options possible, but I found that the default expansion was already relatively easy to read. XCas produced less readable expansions, or just failed.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/martin-odersky-teaches-scala-to-the-masses/">Martin Odersky teaches Scala to the Masses</a>
  </h1>
  <time datetime="2013-09-17T20:11:00Z" class="post-date">Tue, Sep 17, 2013</time>
  <p>I tried today the <a href="https://www.coursera.org/course/progfun">Scala courses on coursera</a> by the Scala creator, Martin Odersky. I was quite impressed by the quality: I somehow believed Scala to be only a better Java, now I think otherwise. Throughout the course, even though it all sounds very basic, you understand the key concepts of Scala and why functional programming + OO concepts are a natural idea. What&rsquo;s nice about Scala is that it avoids the functional vs OO or even the functional vs procedural debate by allowing both, because both can be important, at different scales. Small details can be (and probably should be) procedural for efficiency, because a processor is a processor, but higher level should probably be more functional (immutable) to be clearer, easier to evolve and more easily parallelized.</p>
<p>I recently saw a very good example at work recently of how mutability could be very problematic, with no gain in this case because it was high level (and likely just the result of being too used to OO concepts).</p>
<p>I believe it will make my code more functional programming oriented in the future, especially at the high level.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/setting-values-in-java-enum---a-bad-idea/">Setting Values in Java Enum - A Bad Idea</a>
  </h1>
  <time datetime="2013-09-12T10:06:00Z" class="post-date">Thu, Sep 12, 2013</time>
   

My Scala habits have made me create a stupid bug related to Java enums. In Scala, the concept of <a href="http://www.scala-lang.org/old/node/107">case classes</a> is very neat and recently, I just confused enum in Java with what I sometimes do in Scala case classes.<br /><br />I wrote an enum with a setter like:<br /><br />&nbsp;<span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&nbsp;&nbsp; public static enum BlackVariateType {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V0,<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ZERO_DERIVATIVE;<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; private double volSquare;<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; public double getBlackVolatilitySquare() {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return volSquare;<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<br /><br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; public void setBlackVolatilitySquare(double volSquare) {<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; this.volSquare = volSquare;<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</span></span><br /><span style="font-size: x-small;"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">&nbsp;&nbsp; }</span></span><br /><br />Here, calling setBlackVolatilitySquare will override any previous value, and thus, if several parts are calling it with different values, it will be a mess as there is only a single instance.<br /><br />I am not sure if there is actually one good use case to have a setter on an enum. This sounds like a very dangerous practice in general. Member variables allowed should be only final. <br /><br />



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/making-classic-heston-integration-faster-than-the-cos-method/">Making Classic Heston Integration Faster than the Cos Method</a>
  </h1>
  <time datetime="2013-09-05T17:35:00Z" class="post-date">Thu, Sep 5, 2013</time>
  <p>A coworker pointed to me that Andersen and Piterbarg book &ldquo;Interest Rate Modeling&rdquo; had a chapter on Fourier integration applied to Heston. The authors rely on the Lewis formula to price vanilla call options under Heston.
<figure><img src="/post/lewis_formula.png"/><figcaption>
            <h4>Lewis formula</h4>
        </figcaption>
</figure>
</p>
<p>More importantly, they strongly advise the use of a Black-Scholes control variate. I had read about that idea before, and actually tried it in the Cos method, but it did not improve anything for the Cos method. So I was a bit sceptical. I decided to add the control variate to <a href="/post/attari-lord-kahl--cos-methods-comparison-on-heston/">my Attari code</a>. The results were very encouraging. So I pursued on implementing the Lewis formula and their basic integration scheme (no change of variable).
<figure><img src="/post/attari_formula.png"/><figcaption>
            <h4>Attari formula</h4>
        </figcaption>
</figure>

<figure><img src="/post/carrmadan_formula.png"/><figcaption>
            <h4>Carr-Madan formula (used by Lord-Kahl)</h4>
        </figcaption>
</figure>

<figure><img src="/post/heston_formula.png"/><figcaption>
            <h4>Heston formula</h4>
        </figcaption>
</figure>

<figure><img src="/post/cos_formula.png"/><figcaption>
            <h4>Cos formula</h4>
        </figcaption>
</figure>
</p>
<p>My impression is that the Lewis formula is not so different from the Attari formula in practice: both have a quadratic denominator, and are of similar complexity. The Lewis formula makes the Black-Scholes control variate real (the imaginary part of the characteristic function is null). The Cos formula looks quite different, but it actually is not that much different as the Vk are quadratic in the denominator as well. I still have this idea of showing how close it is to Attari in spirit.</p>
<p>My initial implementation of Attari relied on the log transform described by Kahl-Jaeckel to move from an infinite integration domain to a finite domain. As a result adaptive quadratures (for example based on Simpson) provide better performance/accuracy ratio than a very basic trapezoidal rule as used by Andersen and Piterbarg. If I remove the log transform and truncate the integration according by Andersen and Piterbarg criteria, pricing is faster by a factor of x2 to x3.</p>
<p>This is one of the slightly surprising aspect of Andersen-Piterbarg method: using a very basic integration like the Trapezoidal rule is enough. A more sophisticated integration, be it a Simpson 3/8 rule or some fancy adaptive Newton-Cotes rule does not lead to any better accuracy. The Simpson 3/8 rule won&rsquo;t increase accuracy at all (although it does not cost more to compute) while the adaptive quadratures will often lead to a higher number of function evaluations or a lower overall accuracy.</p>
<p>Here is the accuracy on put options with a maturity of 2 years:
<figure><img src="/post/cos_a_p_2y.png"/>
</figure>
</p>
<p>I had to push to 512 points for the Cos method and L=24 (truncation) in order to have a similar accuracy as Attari and Andersen-Piterbarg with 200 points and a control variate. For 1000 options here are the computation times (the difference is smaller for 10 options, around 30%):</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>Attari</td>
<td>0.023s</td>
</tr>
<tr>
<td>Andersen-Piterbarg</td>
<td>0.024s</td>
</tr>
<tr>
<td>Cos</td>
<td>0.05s</td>
</tr>
</tbody>
</table>
<p>Here is the accuracy on put options with a maturity of 2 days:
<figure><img src="/post/cos_a_p_2d.png"/>
</figure>
</p>
<p>All methods used 200 points. The error is nearly the same for all. And the Cos method takes now only 0.02s. The results are similar with a maturity of 2 weeks.</p>
<p><strong>Conclusion</strong></p>
<p>The Cos method performs less well on longer maturities. Attari or Lewis formula with control variate and caching of the characteristic function are particularly attractive, especially with the simple Andersen-Piterbarg integration.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/better-fonts-in-fedora-than-in-ubuntu/">Better Fonts in Fedora than in Ubuntu</a>
  </h1>
  <time datetime="2013-08-31T13:36:00Z" class="post-date">Sat, Aug 31, 2013</time>
   

<div style="text-align: justify;"><div class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif; font-size: small;">By default, text in Fedora 19 looks ok but not great. There are good tips to improve fonts on http://fedorasolved.org/Members/khaytsus/improve-fonts</span></div><div class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif; font-size: small;"> </span></div><div class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif; font-size: small;">As <u>root</u> user here is what need to be done:</span></div></div><pre class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;">&nbsp;</span></pre><pre class="TerminalCommand"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">cd /etc/fonts/conf.d</span></pre><pre class="TerminalCommand"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">ln -s /usr/share/fontconfig/conf.avail/10-autohint.conf</span></pre><pre class="TerminalCommand"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">ln -s /usr/share/fontconfig/conf.avail/11-lcdfilter-default.conf</span></pre><pre class="TerminalCommand"><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">yum install freetype-freeworl<span class="highlightedSearchTerm">d</span></span></pre><div style="text-align: justify;"><pre class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;">&nbsp;</span></pre><div class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;">Reboot, then, in gnome-tweak-tool choose hinting = slight, and antialiasing = rgba. I also choose the liberation sans and liberation mono fonts.</span></div><div class="TerminalCommand"><br /></div><div class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;">I am not sure which one did the trick, but it looks much better (even better than my laptop under Ubuntu, not sure why).</span></div><pre class="TerminalCommand"><span style="font-family: &quot;Helvetica Neue&quot;,Arial,Helvetica,sans-serif;">&nbsp;<div class="separator" style="clear: both; text-align: center;"><br /><a href="http://1.bp.blogspot.com/-cDwcj_QVjsQ/UiHVKJn7-fI/AAAAAAAAGuo/7seakYSZp7Q/s1600/Screenshot+from+2013-08-31+13:35:40.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-cDwcj_QVjsQ/UiHVKJn7-fI/AAAAAAAAGuo/7seakYSZp7Q/s1600/Screenshot+from+2013-08-31+13:35:40.png" /></a></div><br /></span></pre></div>



  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/attari-lord-kahl--cos-methods-comparison-on-heston/">Attari, Lord-Kahl &amp; Cos Methods Comparison on Heston</a>
  </h1>
  <time datetime="2013-08-28T17:54:00Z" class="post-date">Wed, Aug 28, 2013</time>
  <p>I recently wrote about the <a href="/post/the-cos-method-for-heston/">Cos method</a>. While rereading the various papers on Heston semi-analytical pricing, especially the <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CDAQFjAA&amp;url=http%3A%2F%2Fpfadintegral.com%2Fdocs%2FSchmelzle2010%2520Fourier%2520Pricing.pdf&amp;ei=qREeUpO9HuPE0QXfn4DADw&amp;usg=AFQjCNHANjSlqO6-o5ZfWR8xLpoVT7d5XA&amp;sig2=xeon4_iLfpw8HpKz-0PQQA&amp;bvm=bv.51156542,d.d2k">nice summary by Schmelzle</a>, it struck me how close were the Attari/Bates methods and the Cos method derivations. I then started wondering if Attari was really much worse than the Cos method or not.</p>
<p>I noticed that Attari method accuracy is directly linked to the underlying Gaussian quadrature method accuracy. I found that the doubly adaptive Newton-Cotes quadrature by Espelid (coteda) was the most accurate/fastest on this problem (compared to Gauss-Laguerre/Legendre/Extrapolated Simpson/Lobatto). If the accuracy of the integration is 1e-6, Attari maximum accuracy will also be 1E-6, this means that very out of the money options will be completely mispriced (might even be negative). In a sense it is similar to what I observed on the Cos method.</p>
<p>&ldquo;Lord-Kahl&rdquo; uses 1e-4 integration accuracy, &ldquo;Attari&rdquo; uses 1E-6, and &ldquo;Cos&rdquo; uses 128 points. The reference is computed using <a href="/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price-part-ii">Lord-Kahl</a> with Newton-Cotes and 1E-10 integration accuracy.
Well here are the results in terms of accuracy:
<figure><img src="/post/Screenshot%20from%202013-08-28%2017%2020%2029.png"/>
</figure>
</p>
<p>As expected, Lord-Kahl absolute accuracy is only 1E-5 (a bit better than 1E-4 integration accuracy), while Attari is a bit better than 1E-6, and Cos is nearly 1E-7 (higher inaccuracy in the high strikes, probably because of the truncation inherent in the Cos method).
<figure><img src="/post/Screenshot%20from%202013-08-28%2017%2021%2022.png"/>
</figure>
</p>
<p>The relative error tells a different story, Lord-Kahl is 1E-4 accurate here, over the full range of strikes. It is the only method to be accurate for very out of the money options: the <a href="/post/root-finding-in-lord-kahl-method-to-compute-heston-call-price">optimal alpha</a> allows to go beyond machine epsilon without problems. The Cos method can only go to absolute accuracy of around 5E-10 and will oscillate around, while the reference prices can be as low as 1E-25. Similarly Attari method will oscillate around 5E-8.</p>
<p>What&rsquo;s interesting is how much time it takes to price 1000 options of various strikes and same maturity. In Attari, the charateristic function is cached.</p>
<table>
<thead>
<tr>
<th>Method</th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cos</td>
<td>0.012s</td>
</tr>
<tr>
<td>Lord-Kahl</td>
<td>0.099s</td>
</tr>
<tr>
<td>Attari</td>
<td>0.086s</td>
</tr>
<tr>
<td>Reference</td>
<td>0.682s</td>
</tr>
</tbody>
</table>
<p>The Cos method is around 7x faster than Attari, for a higher accuracy. Lord-Kahl is almost 8x slower than Cos, which is still quite impressive given that here, the characteristic function is not cached, plus it can price very OTM options while following a more useful relative accuracy measure. When pricing 10 options only, Lord-Kahl becomes faster than Attari, but Cos is still faster by a factor of 3 to 5.</p>
<p>It&rsquo;s also quite impressive that on my small laptop I can price nearly 100K options per second with Heston.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/giving-fedora-another-chance/">Giving Fedora Another Chance</a>
  </h1>
  <time datetime="2013-08-14T22:15:00Z" class="post-date">Wed, Aug 14, 2013</time>
  <p>I have had some stability issues with the Ubuntu 13.04 on my home computer, not on my laptop. It might be related to hard disk encryption (out of curiosity I encrypted my main hard drive in the installer option, resulting in a usable but quite slow system - it&rsquo;s incredible how much the hard drive is still important for performance). I did not have any particular issue on my work laptop with it.</p>
<p>Anyway I gave Fedora 19 a try, with Gnome Shell, even if I am no particular fan of it. So far so good, it seems more stable than my previous Fedora 17 trial, and I get used to Gnome Shell. It&rsquo;s quite different, so it takes a while to get used to, but it is as productive as any other env (maybe more so even).</p>
<p>It made me notice that Ubuntu One cloud storage is much less open that it seems: it&rsquo;s extremely difficult to make it work under Fedora. Some people manage this, I did not. I moved to owncloud, which fits my needs.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/julia-and-the-cumulative-normal-distribution/">Julia and the Cumulative Normal Distribution</a>
  </h1>
  <time datetime="2013-08-13T15:52:00Z" class="post-date">Tue, Aug 13, 2013</time>
  <p>I just stumbled upon <!-- raw HTML omitted -->Julia<!-- raw HTML omitted -->, a new programming language aimed at numerical computation. It&rsquo;s quite new but it looks very interesting, with the promise of C like performance (thanks to LLVM compilation) with a much nicer syntax and parallelization features.<!-- raw HTML omitted --><!-- raw HTML omitted -->Out of curiosity, I looked at their cumulative normal distribution implementation. I found that the (complimentary) error function (directly related to the cumulative normal distribution) algorithm relies on an algorithm that can be found in the Faddeeva library. I had not heard of this algorithm or this library before, but the author, <!-- raw HTML omitted -->Steven G. Johnson<!-- raw HTML omitted -->, claims it is faster and as precise as Cody &amp; SLATEC implementations. As <!-- raw HTML omitted -->I previously had a look at those algorithms<!-- raw HTML omitted --> and was quite impressed by Cody&rsquo;s implementation.<!-- raw HTML omitted --><!-- raw HTML omitted -->The <!-- raw HTML omitted -->source of Faddeeva<!-- raw HTML omitted --> shows a big list (100) of Chebychev expansions for various ranges of a normalized error function. I slightly modified the Faddeva code to compute directly the cumulative normal distribution, avoiding some exp(-x<em>x)<em>exp(x</em>x) calls on the way.<!-- raw HTML omitted --><!-- raw HTML omitted -->Is it as accurate? I compared against a high precision implementation as in my previous test of cumulative normal distribution algorithms. And after replacing the exp(-x</em>x) with <!-- raw HTML omitted -->Cody&rsquo;s trick<!-- raw HTML omitted --> to compute it with higher accuracy, here is how it looks (referenced as &ldquo;Johnson&rdquo;).<!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted --><!-- raw HTML omitted -->I also measured performance on various ranges, and found out that this Johnson algorithm is around 2x faster than Cody (in Scala) and 30% faster than my optimization of Cody (using a table of exponentials for Cody&rsquo;s trick).<!-- raw HTML omitted --><!-- raw HTML omitted --></p>

  
</article>
</div>
<p style="text-align:left; width:49%; display: inline-block;"><a href="/page/15/">Previous</a></p>
<p style="text-align:right; width:50%;  display: inline-block;"><a href="/page/17/">Next</a></p>
    </main>

    
      
    
  </body>
</html>
