<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.40.1" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Chase the Devil &middot; Chase the Devil</title>

  
  <link href="https://fonts.googleapis.com/css?family=UnifrakturMaguntia" rel="stylesheet">  
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde-x.css">
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://chasethedevil.github.io/touch-icon-144-precomposed.png">
  <link href="https://chasethedevil.github.io/favicon.png" rel="icon">

  
  
  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil &middot; Chase the Devil" />

  <meta name="description" content="">
  <meta name="keywords" content="">
  
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-365717-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>
<body class="theme-base-00">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1>Chase the Devil</h1>
      <p class="lead">Technical blog for Fabien.</p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/about/">About</a></li>
      
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/post/">Posts</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>  
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

    
  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/adjoint-delta-for-monte-carlo/">Adjoint Delta for Monte-Carlo</a>
      </h1>
      <span class="post-date">Feb 25, 2014 &middot; 1 minute read &middot; <a href="https://chasethedevil.github.io/post/adjoint-delta-for-monte-carlo/#disqus_thread">Comments</a>
      </span>
      
      <p>In an earlier post, I have been quickly exploring <a href="http://chasethedevil.github.io/post/adjoint-algorithmic-differentiation-for-black-scholes/">adjoint differentiation</a> in the context of analytical Black-Scholes. Today, I tried to mix it in a simple Black-Scholes Monte-Carlo as described in <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCsQFjAA&amp;url=http%3A%2F%2Fwww.luca-capriotti.net%2Fpdfs%2FFinance%2Fjcf_capriotti_press_web.pdf&amp;ei=rNMMU4_wGKjt0gWQpYGIAQ&amp;usg=AFQjCNFovkw47-Y1WrIKkt-m5FQ1lhmqYA&amp;sig2=vmiqHzd6SJuq5Fp2TlPjdA&amp;bvm=bv.61725948,d.d2k">L. Capriotti paper</a>, and measured the performance to compute delta compared to a numerical single sided finite difference delta.<br /><br />I was a bit surprised that even on a single underlying, without any real optimization, adjoint delta was faster by a factor of nearly 40%. I suspect this is mostly due to exp evaluations being /2.<br /><br />On a basket of 4 assets, the adjoint method was 3.25x faster.<br /><br />It&rsquo;s quick to have such results on basic payoffs: it took me a few hours and worked on the first run, even though my Monte-Carlo is slightly different from the Capriotti paper. It is much more challenging to have it working across a wide variety of payoffs, and to automatize some of it.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/svi-on-top-of-sabr/">SVI on top of SABR</a>
      </h1>
      <span class="post-date">Feb 20, 2014 &middot; 1 minute read &middot; <a href="https://chasethedevil.github.io/post/svi-on-top-of-sabr/#disqus_thread">Comments</a>
      </span>
      
      <p>Several papers show that the limit for large strikes of <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;ved=0CDUQFjAB&amp;url=http%3A%2F%2Farxiv.org%2Fabs%2F1002.3633&amp;ei=GjUGU5uVIeu00wXEwoCwBw&amp;usg=AFQjCNHvnJ9xYAv60R4GSUbMORRI9_-7Zg&amp;sig2=iqplpcXauJBLJ9DIw71vWA&amp;bvm=bv.61725948,d.d2k">Heston is SVI</a>.<br /><br />Interestingly, I stumbled onto a surface where the Hagan SABR fit was perfect as well as the SVI fit, while the Heston fit was not.<br /><br />Originally, I knew that, on this data, the SVI fit was perfect. Until today, I just never tried to fit a lognormal SABR on the same data. I did a small test with random values of the SABR parameters alpha, rho, nu, and found out that in deed, the SVI fit is always perfect on SABR.<br /><br />Is this just because the Taylor expansion of SVI will match the Taylor expansion of SABR up to the fourth order? It seems that the wings are also not too far off in general so there could be more to it.<br /><br />Gatheral actually devised an SVI formula that uses SABR like variables <a href="http://mfe.baruch.cuny.edu/wp-content/uploads/2013/01/OsakaSVI2012.pdf">in a talk here</a>.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-QNLwJnVGPUE/UwY9EwCkZ6I/AAAAAAAAHA4/DP6MstmUqg4/s1600/Screenshot+from+2014-02-20+18:36:06.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-QNLwJnVGPUE/UwY9EwCkZ6I/AAAAAAAAHA4/DP6MstmUqg4/s1600/Screenshot+from+2014-02-20+18:36:06.png" height="79" width="320" /></a></div><br /><br />Of course, the reverse is not true. SVI has more parameters and provides in general a better fit than SABR.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/smart-initial-guess-for-schobel-zhu/">Smart Initial Guess for Schobel-Zhu</a>
      </h1>
      <span class="post-date">Feb 19, 2014 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/smart-initial-guess-for-schobel-zhu/#disqus_thread">Comments</a>
      </span>
      
      <p>With a <a href="http://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/">small time expansion</a>, it is easy to derive a reasonable initial guess, without resorting to some global minimizer.<br /><br />Like <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCgQFjAA&amp;url=http%3A%2F%2Fpage.math.tu-berlin.de%2F~jacquier%2Findex_files%2FJacquier%2520-%2520SmallTimeHeston2.pdf&amp;ei=72D7Ur6NHeqP0AX7soFo&amp;usg=AFQjCNGkx9ifAh3UQQI4UE_pD8osCzH7Rg&amp;sig2=lIcs-s2yrxWZsxidkQlxOA&amp;bvm=bv.61190604,d.d2k">Forde &amp; al did for Heston</a>, one can find the 5 Schobel-Zhu parameters through 5 points at coordinates (0,0), (x0,t1), (-x0,t1), (x0,t2), (-x0,t2), where x0 is a chosen the log-moneyness, for example, 0.1 and t1, t2 relatively short expiries (for example, 0.1, 0.25).<br /><br />We can truncate the small time expansion so that the polynomial in (x,t) is fully captured by those 5 points. In practice, I have noticed that using a more refined expansion with more terms resulted not only in more complex formulas to lookup the original stochastic volatility parameters, but also in an increased error, because of the redundancy of parameters in the polynomial expansion. My previous Schobel-Zhu expansion becomes just:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-uBWPjGvFZtU/UwTk03igscI/AAAAAAAAHAo/u4unVlkOFG0/s1600/Screenshot+from+2014-02-19+18:07:07.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-uBWPjGvFZtU/UwTk03igscI/AAAAAAAAHAo/u4unVlkOFG0/s1600/Screenshot+from+2014-02-19+18:07:07.png" height="137" width="320" /></a></div><br />In practice, I have found that the procedure works rather well.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-SAv0EczOlvA/UwTkNixNOfI/AAAAAAAAHAg/LE4yfQZfC3s/s1600/Screenshot+from+2014-02-19+18:04:33.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-SAv0EczOlvA/UwTkNixNOfI/AAAAAAAAHAg/LE4yfQZfC3s/s1600/Screenshot+from+2014-02-19+18:04:33.png" height="116" width="400" /></a></div>On some more extreme surfaces, where theta=0, the error in kappa and theta is higher. Interestingly, I received a few real world surfaces like this, where theta=0, which I found a bit puzzling. I wondered if it was because those surfaces were preprocessed with SABR, that has no mean reversion, but I could not fit those exactly with SABR.<br /><br /><b>Update March 2014</b> - this is now described in my paper <a href="http://ssrn.com/abstract=2362968">Fourier Integration and Stochastic Volatility Calibration</a>.&nbsp;</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/a-look-at-small-time-expansions-for-heston/">A Look at Small Time Expansions for Heston</a>
      </h1>
      <span class="post-date">Feb 12, 2014 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/a-look-at-small-time-expansions-for-heston/#disqus_thread">Comments</a>
      </span>
      
      <p>Small time expansions for Heston can be useful during the calibration of the implied volatility surface, in order to find an initial guess for a local minimizer (for example, Levenberg-Marquardt). Even if they are not so accurate, they capture the dynamic of the model parameters, and that is often enough.<br /><br />In 2011, Forde et al. proposed <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CCgQFjAA&amp;url=http%3A%2F%2Fpage.math.tu-berlin.de%2F~jacquier%2Findex_files%2FJacquier%2520-%2520SmallTimeHeston2.pdf&amp;ei=72D7Ur6NHeqP0AX7soFo&amp;usg=AFQjCNGkx9ifAh3UQQI4UE_pD8osCzH7Rg&amp;sig2=lIcs-s2yrxWZsxidkQlxOA&amp;bvm=bv.61190604,d.d2k">a second order small time expansion</a> around the money, which I found to work well for calibration. More recently, Lorig et al. proposed <a href="http://arxiv.org/abs/1306.5447">different expansions up to order-3</a> around the money. I already looked at the later in my <a href="http://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/">previous post</a>, applying the idea to Schobel-Zhu.<br /><br />I noticed, however, that on some surfaces, the Lorig expansion was quickly very inaccurate (LPP1 for order-1, LPP2 for order-2, LPP3 for order-3). Those surfaces seem to be the ones were the Feller condition is largely violated. In practice, in my set of volatility surfaces for 10 different equities/indices, the best fit is always produced by Heston parameters where the Feller condition is violated.<br /><div class="separator" style="clear: both; text-align: center;"></div><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-86ukJOiiEq8/UvtkhCljuKI/AAAAAAAAHAI/J7349pkWjsU/s1600/heston_expansions_order3a.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-86ukJOiiEq8/UvtkhCljuKI/AAAAAAAAHAI/J7349pkWjsU/s1600/heston_expansions_order3a.png" height="378" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">T=0.5, Feller condition largely violated</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-fO0cCblLkFk/UvtkjiYK1PI/AAAAAAAAHAQ/8jwHVPg0Tp8/s1600/heston_expansions_order3b.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-fO0cCblLkFk/UvtkjiYK1PI/AAAAAAAAHAQ/8jwHVPg0Tp8/s1600/heston_expansions_order3b.png" height="378" width="400" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">T=0.5, Feller condition slightly violated</td></tr></tbody></table><br /><br />Out of curiosity, I calibrated my surfaces feeding the order-1 approximation to the differential evolution, in order to find my initial guess, and it worked for all surfaces.<br />The order-3 formula, even though it is more precise at the money, was actually more problematic for calibration: it failed to find a good enough initial guess in some cases, maybe because the reference data should be truncated, to possibly keep the few shortest expiries, and close to ATM strikes.<br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/">A Small-Time Schobel-Zhu Expansion</a>
      </h1>
      <span class="post-date">Feb 10, 2014 &middot; 1 minute read &middot; <a href="https://chasethedevil.github.io/post/a-small-time-schobel-zhu-expansion/#disqus_thread">Comments</a>
      </span>
      
      <p>The paper &ldquo;<a href="http://arxiv.org/abs/1306.5447">implied vol for any local stochastic vol model</a>&rdquo; from Lorig et al. presents a very generic and simple formula to compute implied volatility expansions up to order-2 (there is actually an order-3 formula available in their Mathematica CDF file).<br /><br />I tried it on the <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;cad=rja&amp;ved=0CDIQFjAB&amp;url=http%3A%2F%2Fssrn.com%2Fabstract%3D100831&amp;ei=3gr5UtzkOYm90QWD7IDwBA&amp;usg=AFQjCNFY9anH_AU0A5pWRX4Qdo6Kp2CjEg&amp;sig2=teGVgsV4uneROlzZCuUFBw&amp;bvm=bv.60983673,d.d2k">Schobel-Zhu</a> stochastic volatility model. This model is an interesting alternative to Heston. I found that, in practice, the implied volatility surface <a href="http://chasethedevil.github.io/post/heston-schobel-zhu-bates-double-heston-fit/">fit was as good</a>, while the <a href="http://chasethedevil.blogspot.fr/2014/01/brownian-bridge-or-not-with-heston.html">simulation under the QE scheme</a> is quite faster (and simpler) than Heston. Here is the result of applying their technique on Schobel-Zhu:<br /><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-7FEfNo0V6b4/UvkLxXhipFI/AAAAAAAAG_k/DaVO2Ed_tCs/s1600/SZ_EXP1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-7FEfNo0V6b4/UvkLxXhipFI/AAAAAAAAG_k/DaVO2Ed_tCs/s1600/SZ_EXP1.png" height="250" width="320" /></a></div>And this is how it behaves on some realistic input:<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://3.bp.blogspot.com/-Uf1ud5lKlpk/UvkMHxoDhGI/AAAAAAAAG_s/fzwZCCQuOY0/s1600/Screenshot+from+2014-02-10+18:16:06.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://3.bp.blogspot.com/-Uf1ud5lKlpk/UvkMHxoDhGI/AAAAAAAAG_s/fzwZCCQuOY0/s1600/Screenshot+from+2014-02-10+18:16:06.png" height="288" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">T=0.1</td></tr></tbody></table><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://4.bp.blogspot.com/-xjOTdJKFcKs/UvkMY331XSI/AAAAAAAAG_0/dUfc-ZYLLjg/s1600/Screenshot+from+2014-02-10+18:28:32.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://4.bp.blogspot.com/-xjOTdJKFcKs/UvkMY331XSI/AAAAAAAAG_0/dUfc-ZYLLjg/s1600/Screenshot+from+2014-02-10+18:28:32.png" height="288" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">T=0.5</td></tr></tbody></table>In practice, while not extremely good, it seems to be enough for Calibration to find an initial guess via differential evolution.<br /><br /><b>Update March 2014</b> - this is now described in my paper <a href="http://ssrn.com/abstract=2362968">Fourier Integration and Stochastic Volatility Calibration</a>.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/an-ssd-instead-of-a-laptop/">An SSD instead of a laptop</a>
      </h1>
      <span class="post-date">Feb 4, 2014 &middot; 1 minute read &middot; <a href="https://chasethedevil.github.io/post/an-ssd-instead-of-a-laptop/#disqus_thread">Comments</a>
      </span>
      
      <p>Last week, my work laptop died after spilling out some water on its keyboard inadvertently. Fortunately, its SSD was intact.<br /><br />As the laptop SSD connector (SATA) and power follow the desktop computers standards, and as I use Linux, I just plugged the SSD to my home desktop and booted off the SSD. I had to change slightly the X configuration but otherwise everything worked. Linux is great for that.<br /><br />The same way, I just plugged the SSD to the desktop at work and it worked. Instead of carrying a laptop, I carry now my small &amp; ultra-light SSD.<br /><br />The experience is so good, that it seems to me it should be an option to everybody. Before, hard drives were very sensitive to travel, but now with SSDs, I don&rsquo;t really see why we should carry a screen and a keyboard unless we use them (for example in a travel). Also I find that I actually notice the speed difference between my desktops and former laptop, which I never really paid too much attention to before.<br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/brownian-bridge-or-not-with-heston-quadratic-exponential-qmc/">Brownian Bridge or Not with Heston Quadratic Exponential QMC</a>
      </h1>
      <span class="post-date">Jan 24, 2014 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/brownian-bridge-or-not-with-heston-quadratic-exponential-qmc/#disqus_thread">Comments</a>
      </span>
      
      <p>At first I did not make use of the Brownian Bridge technique in Heston QMC, because the variance process is not simulated like a Brownian Motion under the <a href="http://www.google.com/url?q=http://www.javaquant.net/papers/LeifAndersenHeston.pdf&amp;sa=U&amp;ei=p9jjUtPJK8uUhQfb_YGgAw&amp;ved=0CB4QFjAA&amp;sig2=EjKPr39tR0ni1vq5gK9mkA&amp;usg=AFQjCNGQyqSaDu2kl6_KpP-s-KwMvJ6hPg">Quadratic Exponential algorithm from Andersen</a>.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-kWmb0WWAYzA/UuPX4UMySRI/AAAAAAAAG-4/cBcjRgfTc5s/s1600/Screenshot+from+2014-01-25+16:26:05.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-kWmb0WWAYzA/UuPX4UMySRI/AAAAAAAAG-4/cBcjRgfTc5s/s1600/Screenshot+from+2014-01-25+16:26:05.png" /></a></div><br />It is, however, perfectly possible to use the Brownian Bridge on the asset process. Does it make a difference? In my small test, it does not seem to make a difference. An additional question would be, is it better to take first N for the asset and next N for the variance or vice versa or intertwined? Intertwined would seem the most natural (this is what I used without Brownian Bridge, but for simplicity I did Brownian bridge on first N).<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-WN5frRWHix4/UuKyR69BtbI/AAAAAAAAG-g/BTXm5K2XOQo/s1600/heston_bnp_sobol2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-WN5frRWHix4/UuKyR69BtbI/AAAAAAAAG-g/BTXm5K2XOQo/s1600/heston_bnp_sobol2.png" height="222" width="320" /></a></div><br /><br />By contrast, Schobel-Zhu QE scheme can make full use of the Brownian Bridge technique, in the asset process as well as in the variance process. Here is a summary of the volatility process under the QE scheme from <a href="http://www.google.com/url?q=http://arno.uvt.nl/show.cgi%3Ffid%3D99534&amp;sa=U&amp;ei=itjjUo2jD6Wa0AXqzYHgCQ&amp;ved=0CB4QFjAA&amp;sig2=KdYdo3sAFjV6fwPS4Gak0A&amp;usg=AFQjCNEZ8DRGCf4EXOxCXs3oPc_98628hA">van Haastrecht</a>:<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-kYpBO8PfEkw/UuPX_40DnbI/AAAAAAAAG_A/v7QAN_lX9oM/s1600/Screenshot+from+2014-01-25+16:26:23.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-kYpBO8PfEkw/UuPX_40DnbI/AAAAAAAAG_A/v7QAN_lX9oM/s1600/Screenshot+from+2014-01-25+16:26:23.png" /></a></div><br />Another nice property of Schobel-Zhu is that the QE simulation is as fast as Euler, and therefore 2.5x faster than the Heston QE.<br /><br />I calibrated the model to the same surface, and the QMC price of a ATM call option seems to have a similar accuracy as Heston QMC. But we can see that the Brownian Bridge does increase accuracy in this case. I was surprised that accuracy was not much better than Heston, but maybe it is because I did yet not implement the Martingale correction, while I did so in the Heston case.<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/--mK4u1K8nOk/UuKyR2y6FHI/AAAAAAAAG-k/QSOjDwosqLo/s1600/sz_bnp_sobol3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/--mK4u1K8nOk/UuKyR2y6FHI/AAAAAAAAG-k/QSOjDwosqLo/s1600/sz_bnp_sobol3.png" height="222" width="320" /></a></div><br /><br /></p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/adjoint-algorithmic-differentiation-for-black-scholes/">Adjoint Algorithmic Differentiation for Black-Scholes</a>
      </h1>
      <span class="post-date">Jan 21, 2014 &middot; 1 minute read &middot; <a href="https://chasethedevil.github.io/post/adjoint-algorithmic-differentiation-for-black-scholes/#disqus_thread">Comments</a>
      </span>
      
      <p><a href="http://en.wikipedia.org/wiki/Automatic_differentiation">Adjoint algorithmic differentiation</a> is particularly interesting in finance as we often encounter the case of a function that takes many input (the market data) and returns one output (the price) and we would like to also compute sensitivities (greeks) to each input.<br /><br />As I am just starting around it, to get a better grasp, I first tried to apply the idea to the analytic knock out barrier option formula, by hand, only to find out I was making way too many errors by hand to verify anything. So I tried the simpler vanilla Black-Scholes formula. I also made various errors, but managed to fix all of them relatively easily.<br /><br />I decided to compare how much time it took to compute price, delta, vega, theta, rho, rho2 between single sided finite difference and the adjoint approach. Here are the results for 1 million options:<br /><br /><blockquote class="tr_bq">FD time=2.13s<br />Adjoint time=0.63s</blockquote><br /><b>It works well</b>, but doing it by hand is crazy and too error prone. It might be simpler for Monte-Carlo payoffs however.<br /><br />There are not many Java tools that can do reverse automatic differentiation, I found <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;cad=rja&amp;ved=0CFAQFjAE&amp;url=http%3A%2F%2Fcluster.grid.pub.ro%2Fwiki%2Findex.php%2FADiJaC_-_Automatic_Differentiation_of_Java_Classfiles&amp;ei=SmDeUtDLCYrG0QWrlIHQDw&amp;usg=AFQjCNHLMwobO6u5jSoUifCdHvE2yPZ6oQ&amp;sig2=wFbGRYjgLenCNGRbrQ1gKQ&amp;bvm=bv.59568121,d.d2k">some thesis</a> on it, with an interesting byte code oriented approach (one difficulty is that you need to reverse loops, while statements).</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/placing-the-strike-on-the-grid-and-payoff-smoothing-in-finite-difference-methods-for-vanilla-options/">Placing the Strike on the Grid and Payoff Smoothing in Finite Difference Methods for Vanilla Options</a>
      </h1>
      <span class="post-date">Jan 12, 2014 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/placing-the-strike-on-the-grid-and-payoff-smoothing-in-finite-difference-methods-for-vanilla-options/#disqus_thread">Comments</a>
      </span>
      
      <p>Pooley et al., in <a href="https://cs.uwaterloo.ca/~paforsyt/report.pdf">Convergence Remedies for non-smooth payoffs in option pricing</a> suggest that placing the strike on the grid for a Vanilla option is good enough:<br /><br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-CIS-yTdMn7k/UtKy6HtMIhI/AAAAAAAAG-I/Hef_w7gTcJ0/s1600/pooley_vanilla_smooth.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-CIS-yTdMn7k/UtKy6HtMIhI/AAAAAAAAG-I/Hef_w7gTcJ0/s1600/pooley_vanilla_smooth.png" height="48" width="640" /></a></div><br />At the same time, Tavella and Randall show in their book that numerically, placing the strike in the middle of two nodes leads to a more accurate result. My own numerical experiments confirm Tavella and Randall suggestion.<br /><br />In reality, what Pooley et al. really mean, is that quadratic convergence is maintained if the strike is on the grid for vanilla payoffs, contrary to the case of discontinuous payoffs (like digital options) where the convergence decreases to order 1. So it&rsquo;s ok to place the strike on the grid for a vanilla payoff, but it&rsquo;s not optimal, it&rsquo;s still better to place it in the middle of two nodes. Here are absolute errors in a put option price:<br /><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">on grid, no smoothing&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.04473021824995271</span><br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">on grid, Simpson smoothing&nbsp;&nbsp;&nbsp; 0.003942854282069419<br />on grid, projection smoothing 0.044730218065351934<br />middle, no smoothing&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.004040359609906119</span><br /><br />As expected (and mentioned in Pooley et al.), the projection does not do anything here. When the grid size is doubled, the convergence ratio of all methods is the same (order 2), but placing the strike in the middle still increases accuracy significantly.<br /><br />Here is are the same results, but for a digital put option:<br /><span style="font-family: &quot;Courier New&quot;,Courier,monospace;">on grid, no smoothing &nbsp; &nbsp; &nbsp; &nbsp; 0.03781319921461046<br />on grid, Simpson smoothing&nbsp;&nbsp;&nbsp; 8.289052335705427E-4<br />on grid, projection smoothing 1.9698293587372406E-4<br />middle, no smoothing&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.5122153011418744E-4</span><br /><br />Here only the 3 last methods are of order-2 convergence, and projection is in deed the most accurate method, but placing the strike in the middle is really not that much worse, and much simpler.<br /><br />A disadvantage of Simpson smoothing (or smoothing by averaging), is that it breaks put-call parity (see the paper &ldquo;<a href="http://papers.ssrn.com/abstract=2362969">Exact Forward and Put Call Parity with TR-BDF2</a>&rdquo;) <br /><br />I think the emphasis in their paper on &ldquo;no smoothing is required&rdquo; for vanilla payoffs can be misleading. I hope I have clarified it in this post.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/coordinate-transform-of-the-andreasen-huge-sabr-pde--spline-interpolation/">Coordinate Transform of the Andreasen Huge SABR PDE &amp; Spline Interpolation</a>
      </h1>
      <span class="post-date">Jan 8, 2014 &middot; 3 minute read &middot; <a href="https://chasethedevil.github.io/post/coordinate-transform-of-the-andreasen-huge-sabr-pde--spline-interpolation/#disqus_thread">Comments</a>
      </span>
      
      <p>Recently, I noticed <a href="http://chasethedevil.github.io/post/arbitrage-free-sabr---another-view-on-hagan-approach/">how close</a> are the two PDE based approaches from Andreasen-Huge and Hagan for an arbitrage free SABR. Hagan gives a local volatility very close to the one Andreasen-Huge use in the forward PDE in call prices. A multistep Andreasen-Huge (instead of their one step PDE method) gives back prices and densities nearly equal to Hagan density based approach.<br /><br />Hagan proposed in some unpublished paper a coordinate transformation for two reasons: the ideal range of strikes for the PDE can be very large, and concentrating the points where it matters should improve stability and accuracy. The transform itself can be found in the <a href="http://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;ved=0CC0QFjAA&amp;url=http%3A%2F%2Fwww.andersen-piterbarg-book.com%2F&amp;ei=dYzNUrG6Eo7n7Aamp4GwAQ&amp;usg=AFQjCNE3sdrH2B8EDg40Gocp8FB-QEtnew&amp;sig2=aoDaRX5-zTolem9mUrEumw&amp;bvm=bv.58187178,d.ZGU">Andersen-Piterbarg book</a> &ldquo;Interest Rate Modeling&rdquo;, and is similar to the famous log transform, but for a general local volatility function (phi in the book notation).<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://3.bp.blogspot.com/-7-b4VC2HYRM/Us57Fo7GZII/AAAAAAAAG80/GfE-IoMhstg/s1600/piterbarg_lv_transform1.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://3.bp.blogspot.com/-7-b4VC2HYRM/Us57Fo7GZII/AAAAAAAAG80/GfE-IoMhstg/s1600/piterbarg_lv_transform1.png" /></a></div><br /><br />There are two ways to transform Andreasen Huge PDE:<br /><ul><li>through a non-uniform grid: the input strikes are directly transformed based on a uniform grid in the inverse transformed grid (paying attention to still put the strike in the middle of two points). This is detailed in the Andersen-Piterbarg book.</li></ul><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"><a href="http://1.bp.blogspot.com/-YMhf3KlpAsU/Us57KVQxxnI/AAAAAAAAG9A/2LUUoS8wK94/s1600/piterbarg_lv_transform2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://1.bp.blogspot.com/-YMhf3KlpAsU/Us57KVQxxnI/AAAAAAAAG9A/2LUUoS8wK94/s1600/piterbarg_lv_transform2.png" height="66" width="320" /></a></div><br /><ul><li>through a variable transform in the PDE: this gives a slightly different PDE to solve. One still needs to convert then a given strike, to the new PDE variable. This kind of transform is detailed in the <a href="http://eu.wiley.com/WileyCDA/WileyTitle/productCd-0471197602.html">Tavella-Randall book</a> &ldquo;Pricing Financial Instruments: the Finite Difference Method&rdquo;, for example.</li></ul><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-nF2JZ13ITig/Us57x_lQ_BI/AAAAAAAAG9E/V37fO67-X6I/s1600/tavella_lv_transform3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-nF2JZ13ITig/Us57x_lQ_BI/AAAAAAAAG9E/V37fO67-X6I/s1600/tavella_lv_transform3.png" height="157" width="320" /></a></div><br /><ul></ul>Both are more or less equivalent. I would expect the later to be slightly more precise but I tried the former as it is simpler to test if you have non uniform parabolic PDE solvers.<br /><br />It works very well, but I found an interesting issue when computing the density (second derivative of the call price): if one relies on a Hermite kind of spline (Bessel/Parabolic or Harmonic), the density wiggles around. The C2 cubic spline solves this problem as it is C2. Initially I thought those wiggles could be produced because the interpolation did not respect monotonicity and I tried a Hyman monotonic cubic spline out of curiosity, it did not change anything (in an earlier version of this post I had a bug in my Hyman filter) as it preserves monotonicity but not convexity. The wiggles are only an effect of the approximation of the derivatives value.<br /><div class="separator" style="clear: both; text-align: center;"><a href="http://4.bp.blogspot.com/-bV004iraP1Y/Us6ur0FR3eI/AAAAAAAAG94/rcYDqrQpH28/s1600/ah_dens3.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"><img border="0" src="http://4.bp.blogspot.com/-bV004iraP1Y/Us6ur0FR3eI/AAAAAAAAG94/rcYDqrQpH28/s1600/ah_dens3.png" height="449" width="640" /></a></div><br /><div class="separator" style="clear: both; text-align: center;"></div><div class="separator" style="clear: both; text-align: center;"></div>Initially, I did not notice this on the uniform discretization mostly because I used a large number of strikes in the PDE (here I use only 50 strikes) but also because the effect is somewhat less pronounced in this case.<br /><br />I also discovered a bug in my non uniform implementation of Hagan Density PDE, I forgot to take into account an additional dF/dz factor when the density is integrated. As a result, the density was garbage when computed by a numerical difference.<br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-J6HOoAs43qE/Us6tIN6FeqI/AAAAAAAAG9c/K4DndmXBtRs/s1600/hagan_lv_spline_density2.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-J6HOoAs43qE/Us6tIN6FeqI/AAAAAAAAG9c/K4DndmXBtRs/s1600/hagan_lv_spline_density2.png" height="217" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">HaganDensity denotes the transformed PDE on density approach. Notice the non-sensical spikes</td></tr></tbody></table><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-HzGDaqZ596I/Us6tIEX3KLI/AAAAAAAAG9Y/npyaXX52KRY/s1600/density_transform_bad.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-HzGDaqZ596I/Us6tIEX3KLI/AAAAAAAAG9Y/npyaXX52KRY/s1600/density_transform_bad.png" height="280" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">&ldquo;Bad&rdquo; Call prices around the forward with Hagan Density PDE. Notice the jumps.</td></tr></tbody></table>&nbsp;<table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-C8kixBPkBU8/Us6tIJXHA9I/AAAAAAAAG9U/ilSafRrVrOY/s1600/density_transform_good.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-C8kixBPkBU8/Us6tIJXHA9I/AAAAAAAAG9U/ilSafRrVrOY/s1600/density_transform_good.png" height="280" width="320" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;"><div style="text-align: left;">No jumps anymore after the dF/dZ fit </div></td></tr></tbody></table><br /><div style="text-align: left;"><b>Update March 2014</b> - I have now a paper with Matlab code &ldquo;<a href="http://ssrn.com/abstract=2402001">Finite Difference Techniques for Arbitrage Free SABR</a>&ldquo;<br />&nbsp;<table cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: 0px; margin-right: auto; text-align: left;"><tbody></tbody></table></div></p>

      
    </div>
    
    

<ul class="pagination">
    
    <li>
        <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li
    >
    <a href="/page/10/" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="disabled"><span aria-hidden="true">&hellip;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/10/">10</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    class="active"><a href="/page/11/">11</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/12/">12</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="disabled"><span aria-hidden="true">&hellip;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/38/">38</a></li>
    
    
    <li
    >
    <a href="/page/12/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li>
        <a href="/page/38/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "chasethedevil";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<div class="content container" style="padding-top: 0rem;"-->
 <a href="https://twitter.com/share" class="twitter-share-button"{count} data-hashtags="chasethedevil" data-size="large">Tweet</a>
 <a style="font-size:75%;" href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent(window.location); return false"><i class="fa fa-reddit fa-2x" aria-hidden="true"></i>Submit to reddit</a> 
<table style="border-collapse: collapse;">
     <tr style="padding: 0px; margin: 0px; border: none;">
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">&copy; 2006-16 <a href="http://chasethedevil.github.io/about/">Fabien</a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 0px;"><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding: 0px; margin: 0px; border: none;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</td></tr></table>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</div>

</body>
</html>

