<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head>
  <link href="https://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="generator" content="Hugo 0.83.1" />

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Chase the Devil</title>
  <meta name="description" content="A personal, independent, technical blog" />

  
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/print.css" media="print">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/syntax.css">
  <link type="text/css" rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Abril+Fatface|PT+Sans:400,400i,700">
<link href="https://fonts.googleapis.com/css2?family=UnifrakturMaguntia&display=swap" rel="stylesheet">
 <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">


  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/favicon.png">

  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil" />
  <script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

  <body class=" ">
  <aside class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <a href="https://chasethedevil.github.io/"><h1 style="font-family: 'UnifrakturMaguntia', cursive;font-weight: normal;">Chase the Devil</h1></a>
      <p class="lead">
       A personal, independent, technical blog 
      </p>
    </div>

    <nav>
      <ul class="sidebar-nav">
        <li><a href="https://chasethedevil.github.io/">Blog</a> </li>
        <li><a href="/about/"> About </a></li><li><a href="/post/"> Posts </a></li>
      </ul>

        <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>
 </nav>

    <p>&copy; 2021. All rights reserved. </p>
  </div>
</aside>

    <main class="content container">
    <div class="posts">
<article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/are-tradional-banks-ready-for-the-21st/">Are traditional banks ready for the 21st century?</a>
  </h1>
  <time datetime="2021-06-12T07:56:42&#43;0100" class="post-date">Sat, Jun 12, 2021</time>
  <p>This is a follow up on my parents phishing scam.</p>
<p>After several weeks, my parents and I were finally able to have a real world meeting with the advisor at the bank. The advisor is a young woman with an obvious background in sales.</p>
<p>In order to process the paperwork around the reimbursement of the phishing scam, the main issue was the request of the original phishing e-mail by the bank, as my mother had deleted the e-mail. It turns out, that in Thunderbird, deleted e-mails are not deleted on disk until an operation of compactification of the mailbox is done. I was thus able to recover the deleted e-mail. Interestingly, the deleted e-mail was not in the trash file, but directly in the inbox file.</p>
<p>At first, I sent the message source as PDF, along with a screenshot to the bank. The bank asked to forward the e-mail instead. Interestingly, it turns out that once a phishing e-mail is registered in the various anti-phishing filters, it is not possible to forward (directly or in attachment) or copy paste the email as most servers (including the bank servers) will detect the new email as potential phishing and directly reject the e-mail (reject error).</p>
<p>So the standard process of the bank is not really appropriate. It can be followed only during the very short period (more luck than anything) where the phishing has not yet been registered in the anti-phishing filters. I noticed by a simple Google search that many other institution follow a similar process, where they ask to forward the phishing e-mail to a specific e-mail address.</p>
<p>The good news so far is that officially, the advisor pushed the fraud case forward, although it is not entirely clear at this point if it will be processed properly. What shocked me more was the speech of the bank advisor. First, she scared us by telling stories of various credit card frauds (obviously not related to our bank credentials fraud). When she mentioned insurances against credit card frauds, without selling them yet to us, her goal became clear. Then she thought comforting that this kind of fraud only happens once, because once you are confronted to a fraud, you would then be more careful and not make the same mistake anymore, not a convincing argument at all in my views. She indirectly kept blaming my mother for entering her credentials, but was much less clear about the strong authentication at the bank, especially when I explained that, usually, at another bank, I receive a text message with a unique code to enter each time I try to wire money towards a new account, something this bank obviously did not implement properly. Strong authentication is now part of the European law (<a href="https://www.legifrance.gouv.fr/codes/section_lc/LEGITEXT000006072026/LEGISCTA000035407258/#LEGISCTA000035407332">DSP-2</a>). Then she found every single argument to not close some of the accounts of my parents (they have far too many pointless accounts at this bank). And finally she tried to sell us some special managed account for stock trading (managed by the bank entirely, with the money from my parents), claiming the economy was really great in these COVID-19 times.</p>
<p>Overall there is a real important problem with bank frauds in the 21st century. The system currently in place expects that most people, including 80 years old, must be tech experts, who know how to carefully look at any suspicious email header, such as the from field email address (which could also be better forged than the phishing email my parents received). It expects that everybody carefully checks the http address in the browser (which may also interestingly forged via UTF-8 codes). It relies on somewhat buggy phone applications, which constantly change, and are different for every bank. It expects that most people never click on a link, but then banks themselves send emails with links to promote various products they sell. Banks should really think of adopting a more unified, standard approach to authentication, such as <a href="https://freeotp.github.io/">FreeOTP</a>, based on <a href="https://www.ietf.org/rfc/rfc4226.txt">HOTP</a> and <a href="https://www.ietf.org/rfc/rfc6238.txt">TOTP</a>.</p>
<p>My mother became so paranoid that she does not recognize a valid message from the bank as a normal, standard communication from the bank anymore.
And we are left me with a bank advisor who is not far of being a fraudster him/herself. One may wonder if things would really be much worse with a bitcoin wallet.</p>
<p>By the time I am writing this, my parents were fully reimbursed by the bank, the phishing e-mail was really all they needed.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/yesterday-pirates-took-over-my-parents-bank-account/">Yesterday, Pirates Took Over My Parents Bank Account</a>
  </h1>
  <time datetime="2021-03-10T07:56:42&#43;0100" class="post-date">Wed, Mar 10, 2021</time>
  <p>This is the story of their hack.</p>
<p>Yesterday evening, I received a call from my mother, frantic over the phone. She says she sees alerts of withdrawals from her bank account on her phone, with new alerts every 5 minutes or so. I try to ask her if she clicked recently on some e-mail related to her bank. She is so panicked that I don&rsquo;t manage to have an answer. While trying to understand if those alerts are real or not, my wife suggests immediately that my mother should call her bank. On the phone, I ask</p>
<ul>
<li>did you call the bank? You should really call the bank right now if you did not.</li>
<li>I don&rsquo;t have any number to call them, she replies.</li>
</ul>
<p>After a 5 seconds Google search, my wife finds a number to call in case of phishing at this bank. I start spelling the number to my mother. Before I finish my mother replies</p>
<ul>
<li>ah this number does not work.</li>
<li>so you had already this number and tried to call it? I ask</li>
<li>yes, it does not work.</li>
</ul>
<p>She starts shouting and asks me to come over. I hang up and tell her I will call back shortly, when she is calmer. I call her back 1 minute later and tell her I will come over.</p>
<p>In the meantime, my wife attempts to call the number. She stumbles upon some bot asking for bank credentials or alternatively if she wants to speak to a person. She opts for a person, and indeed, ends up with someone hanging up the phone without having the chance to say a word. She then calls the international number, just below that first number. Bingo, someone helpful is here. She asks the person to call my parents.</p>
<p>When I arrive at my parents place, the person from the bank had reached to my mother, and closed internet access to her bank account to the great relief of everyone. Then, I search the computer, her phone, her tablet, for any text message or e-mail that was suspicious that day. I could not find any. She did receive some legitimate emails from the bank, but only alerts around what was happening in the evening. It started with a message of a new device being allowed to access the bank account website.</p>
<p>I then have the idea to look into the browser history. What is the first page of the day being consulted, around noon?</p>
<p>A phishing website with my mother&rsquo;s bank name as title.</p>
<p>Then I try to find out how she managed to stumble upon that site. I don&rsquo;t find anything. And when I ask her, it&rsquo;s not entirely clear at first, there may have been another email she received. She may have clicked on that email. And she may have given various personal information on, what she believed to be, the bank website. Ok, the classic phishing story then. I tell my parents that they know they should never click on a link in an e-mail. My father then asks &ldquo;but what do you mean exactly by a link?&rdquo;. I fail to understand the true meaning of the question at the time, and show him what is a link exactly and elaborate further.</p>
<p>It does not stop there. Out of curiosity, I look at the whois information for this phishing web site. It&rsquo;s on godaddy, there is not much information, except
some arab name servers, and the country of registration is Saudi Arabia. When I mention this to my father later on, he says:</p>
<ul>
<li>This might be a coincidence, but yesterday, I gave two checks (of the same bank) to the guy in charge of the repairs (or replacement?) of the water softener I had contacted. He has an arabic name.</li>
</ul>
<p>I know his tendencies to be &ldquo;racist&rdquo;, and tell him it probably does not have any relation. And then we think a bit more about the situation, and there is indeed a strange coincidence, as the phishing e-mail (which I never saw since my mother may have deleted it on purpose) was &ldquo;from&rdquo; the same bank, only 1 day later. How could the hackers know my parents bank? They did not receive any phishing e-mail for any other bank. The time and place point towards some sort of targeting.</p>
<p>I go back home, and we further discuss with my wife about all this. And she asks me:</p>
<ul>
<li>If the two are related, how could the water softener guys have the e-mail address of your parents?</li>
</ul>
<p>Good question. I call my father and ask him. It turns out he had received an e-mail (a SPAM) from the water softener company and replied to it. This is how he contacted them. And perhaps, this explains why he wanted to know more about what &ldquo;clicking on a link&rdquo; means. I guess he knows now.</p>
<p>Although I have no real proof, I am quite confident the water softener SPAM and the bank hack are very closely related. I did not think phishing was so &ldquo;targeted&rdquo;, and again it is my wife, who told me that targeting is apparently common in phishing. All this targeting makes me think of another story, involving an 80-years old member of the family, where the special forces broke into his house around 3 a.m. a few months back, shouting &ldquo;target, target&rdquo;, pointing their big guns, and arresting everybody in the house. But that&rsquo;s a story for another time.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/reghai_remarkable_coincidences/">Remarkable Coincidences, Bad Book?</a>
  </h1>
  <time datetime="2020-11-21T07:56:42&#43;0100" class="post-date">Sat, Nov 21, 2020</time>
  <p>I stumbled upon a new  short book <a href="https://link.springer.com/book/10.1007%2F978-3-030-57496-3">Financial Models in Production</a> from O. Kettani and A. Reghai. A page attracted my attention</p>
<figure><img src="/post/reghai_coincidences.png"/><figcaption>
            <h4>A page from Kettani and Reghai&#39;s book.</h4>
        </figcaption>
</figure>

<p>This is the same example as I used on <a href="/post/implied-volatility-from-black-scholes-price/">my blog</a>, where I also present the Li&rsquo;s SOR method combined with the good initial guess from Stefanica. The idea has also been expanded on in <a href="https://jherekhealy.github.io">Jherek Healy&rsquo;s book</a>. What is shocking is that, beside reusing my example, <strong>they reuse my timing</strong> for Jäckel and my implementation is in <a href="https://golang.org">Google Go</a>, with a timing done on some older laptop. The numbers given are thus highly inconsistent. Of course, none of this is mentioned anywhere, and the book does not reference my blog.</p>
<p>I also find the description of how they improve the implied volatility algorithm (detailed on the next page) to not make much sense. After this kind of stuff, you can&rsquo;t really trust anything that is in the book&hellip;</p>
<p>Worst perhaps, is that the authors advertise their &ldquo;novel&rdquo; technique in otherwise decent talks and conferences, such as <a href="https://www.mathfinance.com/newsletter-october-2020-mathfinance-conference-recap/">the one from mathfinance</a>. Here is a quote</p>
<blockquote>
<p>Enforced Numerical Monotonicity (ENM) beats Jäckel’s implied volatility calculations – an implied vol calculator that never breaks and automatically fits vanilla option prices.</p>
</blockquote>
<p>It is really unfortunate that the world we live in encourages such boasting. Papers always need  to present some novel ideas to be published, but there is too often no check on whether the idea actually works, or is worth it. The temptation to make exagerated claims is very high for authors. In the end, it becomes not so easy to sort out the good from the bad.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/bad-papers-polynomial-roots/">Bad papers and the roots of high degree polynomials</a>
  </h1>
  <time datetime="2020-11-07T07:56:42&#43;0100" class="post-date">Sat, Nov 7, 2020</time>
  <p>I was wondering what were exactly the eigenvalues of the Mersenne-Twister random number generator transition matrix. An <a href="https://arxiv.org/abs/1403.5355">article</a> by K. Savvidy sparked my interest on this.
This article mentioned a poor entropy (sum of log of eigenvalues amplitudes which are greater than 1), with eigenvalues falling almost on the unit circle.</p>
<p>The eigenvalues are also the roots of the characteristic polynomial. It turns out, that for jumping ahead in the random number sequence, we use the characteristic polynomial. There is a twist however,
we use it in F2 (modulo 2), for entropy, we are interested in the characteristic polynomial in Z (no modulo), specified in Appendix A of <a href="https://dl.acm.org/doi/10.1145/272991.272995">the Mersenne-Twister paper</a>. The roots of the two polynomials are of course very different.</p>
<p>Now the degree of the polynomial is 19937, which is quite high. I searched for some techniques to compute quickly the roots, and found the paper <a href="https://www.sciencedirect.com/science/article/abs/pii/S1877750316304641">&ldquo;Efficient high degree polynomial root finding
using GPU&rdquo;</a>, whose main idea is relatively simple: use <a href="https://en.wikipedia.org/wiki/Aberth_method">the Aberth method</a>, with a Gauss-Seidel like iteration (instead of a Jacobi like iteration) for parallelization. Numerical issues are supposedly
handled by taking the log of the polynomial and its derivative in the formulae.</p>
<p>When I tried this, I immediately encountered numerical issues due to the limited precision of 64-bit floating point numbers. How to evaluate the log of the polynomial (and its derivative) in a stable way? It&rsquo;s just not a simple problem at all.
Furthermore, the method is not particularly fast either compared to some other alternatives, such as calling eigvals on <a href="https://en.wikipedia.org/wiki/Companion_matrix">the companion matrix</a>, a formulation which tends to help avoiding limited precision issues. And it requires a very good initial guess (in my case, on the unit circle, anything too large blows up).</p>
<p>The authors in the paper do not mention which polynomials they actually have tested, only the degree of some &ldquo;full polynomial&rdquo; and some &ldquo;sparse polynomial&rdquo;, and claim their technique works with full polynomials of degree 1 000 000 ! This may be true for some very specific polynomial where the log gives an accurate value, but is just plain false for the general case.</p>
<p>I find it a bit incredible that this gets published, although I am not too surprised since the bar for publication is low for many journals (see <a href="https://quantsrus.github.io/post/on-the-quality-of-research-publications/">this enlightening post</a> by J. Healy),  and even for more serious journals, referees almost never actually try the method in question, so they have to blindly trust the results and focus mostly on style/presentation of ideas.</p>
<p>Fortunately, some papers are very good, such as <a href="https://arxiv.org/abs/1611.02435">Fast and backward stable computation of roots of polynomials, Part II: backward error analysis; companion matrix and companion pencil</a>. In this case, the authors even provide <a href="https://github.com/jverzani/AMRVW.jl">a library in Julia</a>, so the claims can be easily verified, and without surprise, it works very well, and is (very) fast. It also supports multiple precision, if needed. For the specific case of the Mersenne-Twister polynomial, it leads to the correct entropy value, working only with 64-bit floats, even though many eigenvalues have a not-so-small error. It is still relatively fast (compared to a standard LinearAlgebra.eigvals) using quadruple precision (128-bits), and there, the error in the eigenvalues is small.</p>
<p>Overall, I found with this method an entropy of 10.377 (quite different from what is stated in K. Savvidy paper), although the plot of the distribution looks similar (but with a different scale: the total number of eigenvalues reported in K. Savvidy paper just does not add up to 19937, which is somewhat puzzling). A naive companion matrix solution led to 10.482. More problematic, if we look directly for the eigenvalues of the Mersenne-Twister transition matrix (Appendix A of the MT paper), we find 10.492, perhaps it is again an issue with the limited precision of 64-bits here.</p>
<figure><img src="/post/mt19937_hist64_poly128roots.png"/><figcaption>
            <h4>Distribution of the eigenvalues of the Mersenne-Twister.</h4>
        </figcaption>
</figure>

<p>Below is the Mersenne-Twister polynomial, expressed in Julia code.
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#007020;font-weight:bold">using</span> DynamicPolynomials
<span style="color:#007020;font-weight:bold">import</span> AMRVW
<span style="color:#007020;font-weight:bold">using</span> Quadmath

<span style="color:#555;font-weight:bold">@polyvar</span> t
n <span style="color:#666">=</span> <span style="color:#40a070">624</span>
m <span style="color:#666">=</span> <span style="color:#40a070">397</span>
cp <span style="color:#666">=</span> DynamicPolynomials<span style="color:#666">.</span>Polynomial((t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">31</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">30</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">29</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">28</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">27</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">26</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">24</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">23</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">18</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">17</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">15</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">11</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">6</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">3</span><span style="color:#666">+</span>(t<span style="color:#666">^</span>n<span style="color:#666">+</span>t<span style="color:#666">^</span>m)<span style="color:#666">*</span>(t<span style="color:#666">^</span>(n<span style="color:#666">-</span><span style="color:#40a070">1</span>)<span style="color:#666">+</span>t<span style="color:#666">^</span>(m<span style="color:#666">-</span><span style="color:#40a070">1</span>))<span style="color:#666">^</span><span style="color:#40a070">2</span><span style="color:#666">+</span><span style="color:#40a070">1</span>)

c <span style="color:#666">=</span> zeros(Float128,DynamicPolynomials<span style="color:#666">.</span>degree(terms(cp)[<span style="color:#40a070">1</span>])<span style="color:#666">+</span><span style="color:#40a070">1</span>)
<span style="color:#007020;font-weight:bold">for</span> te <span style="color:#007020;font-weight:bold">in</span> terms(cp)
  c[DynamicPolynomials<span style="color:#666">.</span>degree(te)<span style="color:#666">+</span><span style="color:#40a070">1</span>] <span style="color:#666">=</span> coefficient(te)
<span style="color:#007020;font-weight:bold">end</span>
v128 <span style="color:#666">=</span> AMRVW<span style="color:#666">.</span>roots(c)
sum(x <span style="color:#666">-&gt;</span> log(abs(x)),filter(x <span style="color:#666">-&gt;</span> abs(x) <span style="color:#666">&gt;</span> <span style="color:#40a070">1</span>, v128))</code></pre></div></p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/disaster-capitalism/">Disaster Capitalism - Summer Reading Review</a>
  </h1>
  <time datetime="2020-11-06T20:56:42&#43;0100" class="post-date">Fri, Nov 6, 2020</time>
  <p>Several years ago, I read the book <em>No Logo</em> from Naomi Klein. I did not find it particularly good, but it did raise a valid concern overall.
This summer I read <em>Shock Therapy - The rise of disaster capitalism</em>. It suffers from some of the same flaws as <em>No Logo</em>, namely a lot of repetition of the same idea. Here, the underlying idea is that neoliberalism does not work in practice, and often ends up being some kind of corporatism. At the same time, it is suggested that some mild socialism is often much better for the people, although, the latter is not backed by concrete examples in the book. The former is backed by numerous documents, and is analyzed accross time and countries. It starts with Chili under Pinochet, the prototypical example that force is required to impose neoliberalism, then moves around South America in general, with some cases where a strong inflation, may be enough for the people to accept neoliberalism. Then it continues with China under Deng Xiao Ping, which I find a bit too much of a stretch to make a case about any kind of neoliberalism. Russia under Yeltsin is next, and it ends with the war in Irak and the USA.</p>
<p>The most interesting chapters are probably the first one, and the one about Irak. The first chapter explains the creation of the shock therapy treament by psychatrists and how it morphed to become a CIA &ldquo;interrogation&rdquo; technique. The chapter on Irak explains in details how people high up in the government reduced the public military staff/budget, and at the same time increased significantly the budget for contractors/external companies, which were closely linked to  members of the government. It also makes you understand why it ended up being such a massive failure, even though it was presented as a Marshall plan for the middle east by the American government.</p>
<p>The worst chapters are definitely the introduction and the conclusion. The introduction is just not interesting, and the conclusion is saying that things are becoming better for the socialists, with the changes in South America (Chavez, Ecuador, Bolivia), all of which did not really stand the test of time, since the book was written.</p>
<p>Some annoying facts I found is that Milton Friedman is often made to be some sort of devil and Jeffrey Sachs is portrayed during the first half as his acolyte, and then he appears much more balanced when the author has an actual interview with him. The author however did not rewrite the previous chapters, so there is some sort of inconsistency there.</p>
<p>More annoying is that no positive aspect of neoliberalism ideas is presented, and socialism is often presented as a better alternative, without any proof. There are so many daily life examples that show where socialism is worse than liberalism. Recently, I had to contact a company for issues on my roof. The owner of this small company did not hesitate to say</p>
<blockquote>
<p>&ldquo;It is difficult to find people for this kind of job, because it is not always easy with the cold or the heat. People prefer to work at the city hall, where they are always three to do anything: one to carry the tools, one to watch, and one to actually do the work. In my company, we have to do everything alone&rdquo;.</p>
</blockquote>
<p>Another example that struck me recently is how bad are the school books. Although those are not written by the public workers, they need some sort of approval by those, and it ends up being a very small circle who can actually have those books accepted and distributed to schools. Only a few books are accepted and those will sell in the 10K+ quantity easily. In contrast, holiday children study books, which the parents are free to buy or not at any shop, are amazingly good. Indeed, if they were bad, almost nobody would buy them.</p>
<p>That being said, I don&rsquo;t think liberalism is always good and socialism always bad either, there is probably a delicate balance somewhere.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/mar9-cac40-crash/">March 9, 2020 crash - where will CAC40 go?</a>
  </h1>
  <time datetime="2020-03-09T21:56:42&#43;0100" class="post-date">Mon, Mar 9, 2020</time>
  <p>The stock market crashed by more than 7% on March 9, 2020. It is one of the most important drop since September 2001.
I looked at BNP warrant prices on the CAC40 French index, with a maturity of March 20, 2020 , to see what they would tell about the market direction on the day of the crash. This is really a not-so-scientific experiment.</p>
<p>The quotes I got were quite noisy. I applied a few different techniques to imply the probability density from the option prices:</p>
<ul>
<li>The one-step Andreasen-Huge with some regularization. The regularization is a bit too mild, although, in terms of implied vol, this was the worst fit  among the techniques.</li>
<li>The stochastic collocation towards a septic polynomial, no regularization needed here. The error in implied volatilities is similar to Andreasen-Huge, even though the implied density is much smoother. I however discovered a small issue with the default optimal monotonic fit, and had to tweak a little bit the optimal polynomial, more on this later in this post.</li>
<li>Some RBF collocation of the implied vols. Best fit, with regularization, and very smooth density, which however becomes negative in the high strikes.</li>
<li>Some experimental Andreasen-Huge like technique, with a minimal grid and good regularization.</li>
</ul>
<figure><img src="/post/cac40_mar9_dens.png"/><figcaption>
            <h4>Implied probability density for March 20, CAC40 warrants.</h4>
        </figcaption>
</figure>

<p>The implied forward price was around 4745.5. Interestingly, this corresponds to the first small peak visible on the blue and red plots. The strongest peak
is located a little beyond 5000, which could mean that the market believes that the index will go back up above 5000. This does not mean that you should buy however, as there are other, more complex explanations. For example, the peak could be a latent phenomenon related to the previous days.</p>
<p>Now here is how the plot is with the &ldquo;raw&rdquo; optimal collocation polynomial:
<figure><img src="/post/cac40_mar9_dens_0.png"/><figcaption>
            <h4>Implied probability density for March 20, CAC40 warrants with raw optimal polynomial collocation.</h4>
        </figcaption>
</figure>
</p>
<p>Notice the spurious peak. In terms of implied volatility, this corresponds to a strange, unnatural angle in the smile. The reason for this unnatural peak lies in the details of the stochastic collocation technique: the polynomial we fit is monotonic, but ends up with slope close to zero at some point in order to better fit the data. If the slope is exactly zero, there is a discontinuity in the density. Here the very low slope tranlates to the peak. The fix is simply to impose a floor on the slope (although it may not be obvious in advance to know how much this floor should be).</p>
<figure><img src="/post/cac40_mar9_collo.png"/><figcaption>
            <h4>Collocation polynomials for March 20, CAC40 warrants.</h4>
        </figcaption>
</figure>

<p>And for the curious, here are the implied vol plots:</p>
<figure><img src="/post/cac40_mar9_vol.png"/><figcaption>
            <h4>Implied vol fits for March 20, CAC40 warrants.</h4>
        </figcaption>
</figure>


  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/42/">42</a>
  </h1>
  <time datetime="2019-12-05T20:56:42&#43;0100" class="post-date">Thu, Dec 5, 2019</time>
  <p>Today my 6-years old son came with a math homework. The stated goal was to learn the different ways to make 10 out of smaller numbers. I was impressed. Immediately, I wondered</p>
<blockquote>
<p>how many ways are there to make 10 out of smaller numbers?</p>
</blockquote>
<p>This is one of the beauties of maths: a very simple problem, which a 6-years old can understand, may actually be quite fundamental. If you want to solve this in the general case, for any number instead of 10, you end up with the <a href="https://en.wikipedia.org/wiki/Partition_(number_theory)#Restricted_part_size_or_number_of_parts">partition function</a>. And in order to find this, you will probably learn recurrence relations. So what is the answer for 10?</p>
<blockquote>
<p>42</p>
</blockquote>
<p>Then I looked at one exercise they did in class, which was simply to find different ways to pay 10 euros with bills of 10, 5 and coins of 2 and 1 euro(s).</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/python-numba-overrated/">Numba, Pypy Overrated?</a>
  </h1>
  <time datetime="2019-02-12T20:56:42&#43;0100" class="post-date">Tue, Feb 12, 2019</time>
  <p>Many benchmarks show impressive performance gains with the use
of <a href="https://numba.pydata.org/">Numba</a> or <a href="https://www.pypy.org/">Pypy</a>. Numba allows to compile just-in-time some specific methods, while Pypy takes
the approach of compiling/optimizing the full python program: you use it just like the standard
python runtime. From those benchmarks, I imagined that those  tools would improve my 2D Heston PDE solver
performance easily. The initialization part of my program contains embedded for loops over several 10Ks elements.
To my surprise, numba did not improve anything (and I had to isolate the code, as it would
not work on 2D numpy arrays manipulations that are vectorized). I surmise it does not play well
with scipy sparse matrices.
Pypy did not behave better, the solver became actually slower than with the standard python
interpreter, up to twice as slow, for example, in the case of the main solver loop which only does matrix multiplications and LU solves sparse systems. I did not necessarily expect any performance improvement in this specific loop, since it only consists in a few calls to expensive scipy calculations. But I did not expect a 2x performance drop either.</p>
<p>While I am sure that there are good use cases, especially for numba, I was a bit disappointed
that it likely would require to significantly change my code to have any effect (possibly to not do the initialization with scipy sparse matrices, but then, it is not so clear how). Also, I
find <a href="https://www.ibm.com/developerworks/community/blogs/jfp/entry/A_Comparison_Of_C_Julia_Python_Numba_Cython_Scipy_and_BLAS_on_LU_Factorization?lang=en">most</a> <a href="https://modelingguru.nasa.gov/docs/DOC-2676">benchmarks</a> dumb. For example, the 2D ODE solver of the latter uses a simple dense 2D numpy array. On real code,
things are not as simple.</p>
<p>Next I should try Julia again out of curiosity. I tried it <a href="/post/modern-programming-language-for-monte-carlo/">several years ago</a> in the context of a simple Monte-Carlo simulation and my experiment at the time
was not all that encouraging, but it may be much better at building PDE solvers and not too much work to port my python code. I am curious to see if it ends up being faster, and whether the accessible LU solvers are any good. If Julia delivers, it&rsquo;s a bit of a shame for python, since it has so many excellent high quality numerical libraries. Also when I look back at my old Monte-Carlo test, I bet it would benefit greatly from numba, somewhat paradoxically, compared to my current experiment.</p>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/about/">About</a>
  </h1>
  <time datetime="2018-12-17T10:05:07&#43;0100" class="post-date">Mon, Dec 17, 2018</time>
  <p>I just moved my blog to a static website, created with <a href="https://gohugo.io/">Hugo</a>, I explain the reasons why <a href="/post/moved-to-hugo/">here</a>.
You can find more about me on my <a href="https://fr.linkedin.com/in/fabien-le-floc-h-8aa306">linkedin profile</a>.
In addition you might find the following interesting:</p>
<ul>
<li><a href="http://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1514784">List of quantitative finance papers</a> I have freely available on SSRN</li>
<li><a href="/lefloch_trbdf2_draft.pdf">TR-BDF2 for Stable American Option Pricing</a>. This is the first draft, not the final version that was published in the Journal of Computational Finance.</li>
<li><a href="/lefloch_sabr_slides.pdf">Presentation on finite difference techniques for arbitrage-free SABR</a> I gave at the conference on models and numerics in financial mathematics at the Lorentz center in 2015.</li>
<li><a href="/lefloch_exact_log.pdf">Exact Forward for Finite-Difference Schemes on the Log-transformed Black-Scholes PDE</a>.</li>
<li><a href="/lefloch_volatility_asymptotics.pdf">Asymptotic bounds of the normal volatility</a>.</li>
</ul>

  
</article><article class="post">
  <h1 class="post-title">
    <a href="https://chasethedevil.github.io/post/quadprog-nans/">Fixing NaNs in Quadprog</a>
  </h1>
  <time datetime="2018-10-07T20:56:42&#43;0100" class="post-date">Sun, Oct 7, 2018</time>
  <p>Out of curiosity, I tried <a href="https://github.com/cran/quadprog">quadprog</a> as <a href="https://quantsrus.github.io/post/state_of_convex_quadratic_programming_solvers/">open-source quadratic programming convex optimizer</a>, as it is looks fast, and the code stays relatively simple. I however stumbled on cases where the algorithm would return NaNs even though my inputs seemed straighforward. Other libraries such as CVXOPT did not have any issues with those inputs.</p>
<p>Searching on the web, I found that I was not the only one to stumble on this kind of issue with quadprog. In particular, in 2014, Benjamen Tyner <a href="http://r.789695.n4.nabble.com/quadprog-solve-QP-sometimes-returns-NaNs-td4697548.html">gave a simple example in R</a>, where solve.QP returns NaNs while the input is very simple: an identity matrix with small perturbations out of the diagonal. Here is a copy of his example:</p>
<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-R" data-lang="R">    <span style="color:#06287e">library</span>(quadprog)

    n <span style="color:#666">&lt;-</span> <span style="color:#40a070">66L</span>

    <span style="color:#06287e">set.seed</span>(<span style="color:#40a070">6860</span>)
    X <span style="color:#666">&lt;-</span> <span style="color:#06287e">matrix</span>(<span style="color:#40a070">1e-20</span>, n, n)
    <span style="color:#06287e">diag</span>(X) <span style="color:#666">&lt;-</span> <span style="color:#40a070">1</span>
    Dmat <span style="color:#666">&lt;-</span> <span style="color:#06287e">crossprod</span>(X)
    y <span style="color:#666">&lt;-</span> <span style="color:#06287e">seq_len</span>(n)
    dvec <span style="color:#666">&lt;-</span> <span style="color:#06287e">crossprod</span>(X, y)

    Amat <span style="color:#666">&lt;-</span> <span style="color:#06287e">diag</span>(n)
    bvec <span style="color:#666">&lt;-</span> y <span style="color:#666">+</span> <span style="color:#06287e">runif</span>(n)

    sol <span style="color:#666">&lt;-</span> <span style="color:#06287e">solve.QP</span>(Dmat, dvec, Amat, bvec, meq <span style="color:#666">=</span> n)

    <span style="color:#06287e">print</span>(sol<span style="color:#666">$</span>solution) <span style="color:#60a0b0;font-style:italic"># this gives all NaNs</span></code></pre></div>
<p>Other people stumbled on <a href="https://stats.stackexchange.com/questions/259993/why-would-quadratic-program-in-svm-not-work-for-very-large-or-very-small-lambda">similar</a> issues.</p>
<p>In my specific case, I was able to debug the quadprog algorithm and find the root cause: two variables \(g_c\) and \(g_s\) can become very small, and their square becomes essentially zero, creating a division by zero. If, instead of computing \( \frac{g_s^2}{g_c^2} \) we compute \( \left(\frac{g_s}{g_c}\right)^2 \), then the division by zero is avoided as the two variables are of the same order.</p>
<figure><img src="/post/quadprog_nan_fix.png"/><figcaption>
            <h4>Sample code change [on github](https://github.com/cran/quadprog/pull/1/commits/7f51915f7c662c7fac3d4e2ab067cfbc292767f8).</h4>
        </figcaption>
</figure>

<p>While it probably does not catter for all the possible NaN use cases, it did fix all the cases I stumbled upon.</p>

  
</article>
</div>

<p style="text-align:right; width:50%;  display: inline-block;"><a href="/page/2/">Next</a></p>
    </main>

    
      
    
  </body>
</html>
