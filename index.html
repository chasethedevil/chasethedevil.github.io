<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
	<meta name="generator" content="Hugo 0.37" />
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Chase the Devil &middot; Chase the Devil</title>

  
  <link href="https://fonts.googleapis.com/css?family=UnifrakturMaguntia" rel="stylesheet">  
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/poole.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/poole-overrides.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde-overrides.css">
  <link rel="stylesheet" href="https://chasethedevil.github.io/css/hyde-x.css">
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css">
  

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://chasethedevil.github.io/touch-icon-144-precomposed.png">
  <link href="https://chasethedevil.github.io/favicon.png" rel="icon">

  
  
  
  <link href="https://chasethedevil.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Chase the Devil &middot; Chase the Devil" />

  <meta name="description" content="">
  <meta name="keywords" content="">
  
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML'></script>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-365717-1', 'auto');
    ga('send', 'pageview');
  </script>
  
</head>
<body class="theme-base-00">
<div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      
      <h1>Chase the Devil</h1>
      <p class="lead">Technical blog for Fabien.</p>
    </div>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/">Blog</a></li>
      
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/about/">About</a></li>
      
      <li class="sidebar-nav-item"><a href="https://chasethedevil.github.io/post/">Posts</a></li>
      
    </ul>

    <ul class="sidebar-nav">
      <li class="sidebar-nav-item">
      <script type="text/javascript">document.write("<a href=\"mail" + "to:" + new Array("fabien","2ipi.com").join("@") + "?subject=your%20blog\">" + '<i class="fa fa-envelope fa-3x"></i>' + "</" + "a>");</script>  
      
      
      
      
      
      
      <a href="https://twitter.com/logos01"><i class="fa fa-twitter-square fa-3x"></i></a>
      
      <a href="https://chasethedevil.github.io/index.xml" type="application/rss+xml"><i class="fa fa-rss-square fa-3x"></i></a>
      </li>
    </ul>

    

    
  </div>
</div>


<div class="content container">
  <div class="posts">
    
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/senior-developers-dont-know-oo-anymore/">Senior Developers Don&#39;t Know OO Anymore</a>
      </h1>
      <span class="post-date">Mar 8, 2018 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/senior-developers-dont-know-oo-anymore/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/programming">programming</a><a class="label" href="https://chasethedevil.github.io/categories/java">java</a>
      </span>
      
      <p>It has been a while since the good old object-oriented (OO) programming is not trendy anymore. Functional programming or more dynamic programming (Python-based) have been the trend for a while officially, with an excursion in template based programming for C++ guys. Those are not strict categories: Python can be used in a very OO way, but it&rsquo;s not how it is marketed or considered by the community.</p>

<p>Recently, I have seen some of the ugliest refactoring in my life as a programmer, done by someone with at least 10 years of experience programming in Java. It is a good illustration because the piece of code is particularly simple (although I won&rsquo;t bother with implementation details). The original code was a simple boolean method on an object such as</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#007020;font-weight:bold">public</span> <span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">Dog</span>
    <span style="color:#007020;font-weight:bold">public</span> <span style="color:#902000">boolean</span> <span style="color:#06287e">isHappy</span><span style="color:#666">()</span> <span style="color:#666">{</span> <span style="color:#666">...</span> <span style="color:#666">}</span>
    <span style="color:#007020;font-weight:bold">public</span> <span style="color:#902000">void</span> <span style="color:#06287e">setHappy</span><span style="color:#666">(</span><span style="color:#902000">boolean</span> isHappy<span style="color:#666">)</span> <span style="color:#666">{</span> <span style="color:#666">...</span> <span style="color:#666">}</span></code></pre></div>

<p>The methods were marked deprecated, and instead, new &ldquo;utility&rdquo; methods replaced it:</p>

<div class="highlight"><pre style="background-color:#f0f0f0;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-java" data-lang="java"><span style="color:#007020;font-weight:bold">public</span> <span style="color:#007020;font-weight:bold">class</span> <span style="color:#0e84b5;font-weight:bold">DogUtil</span>
    <span style="color:#007020;font-weight:bold">public</span> <span style="color:#007020;font-weight:bold">static</span> <span style="color:#902000">boolean</span> <span style="color:#06287e">isHappy</span><span style="color:#666">(</span>Dog dog<span style="color:#666">)</span> <span style="color:#666">{</span> <span style="color:#666">...</span> <span style="color:#666">}</span>
    <span style="color:#007020;font-weight:bold">public</span> <span style="color:#007020;font-weight:bold">static</span> <span style="color:#902000">void</span> <span style="color:#06287e">setHappy</span><span style="color:#666">(</span>Dog dog<span style="color:#666">,</span> <span style="color:#902000">boolean</span> isHappy<span style="color:#666">)</span> <span style="color:#666">{</span> <span style="color:#666">...</span> <span style="color:#666">}</span></code></pre></div>

<p>This is really breaking OO and moving back to procedural programming.</p>

<p>In a big (but not that big in reality) company, it is quite a challenge to avoid such code transformations. The code might be written by a team with a different manager, managers try to play nice to each other. And is it really worth fighting over such a trivial thing? if some low level (in the company hierarchy) programmer reports this, he is more likely to be labeled as a black sheep. Most managers prefer white sheeps.</p>

<p>More generally software is like entropy: it can start from a simple and clean state, but eventually it will always grow complex and somewhat ugly. And you end up with the Cobol syndrome, where people don&rsquo;t really know anymore what the software is doing, can&rsquo;t replace it as it is used (but nobody can tell exactly which parts), and &ldquo;developers&rdquo; do only small fixes and evolutions (patches) in an obsolete language on a system they don&rsquo;t really understand.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices/">Implying the Probability Density from Market Option Prices</a>
      </h1>
      <span class="post-date">Feb 13, 2018 &middot; 7 minute read &middot; <a href="https://chasethedevil.github.io/post/implying-the-probability-density-from-market-option-prices/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a>
      </span>
      
      <p>In the <a href="/post/spx500_bets_after_rates_hike/">previous post</a>, I showed a plot of the probability implied from SPW options before and after the big volatility change of last week.
I created it from a least squares spline fit of the market mid implied volatilities (weighted by the inverse of the bid-ask spread). While it looks reasonable, the underlying
technique is not very robust. It is particularly sensitive to the number of options strikes used as spline nodes.</p>

<p>Below I vary the number of nodes, by considering nodes at every N market strikes, for different values of N.</p>


<figure>
    
        <img src="/post/spw_density_spline_nodes.png" />
    
    
    <figcaption>
        <h4>probability density of the SPX implied from 1-month SPW options with nodes located at every N market strike, for different values of N. Least squares spline approach</h4>
        
    </figcaption>
    
</figure>


<p>With \(N \leq 6\), the density has large wiggles, that go into the negative half-plane. As expected, a large N produces a flatter and smoother density. It is not
obvious which value of N is the most appropriate.</p>

<p>Another technique is to fit directly a weighted sum of Gaussian densities, of fixed standard deviation, where the weights are calibrated to the market option prices. This is
described in various papers and books from Wystup such as <a href="https://mathfinance.com/wp-content/uploads/2017/06/FXSmileModelling.pdf">this one</a>. He calls it the kernel slice approach.
If we impose that the weights are positive and sum to one, the resulting model density will integrate to one and be positive.</p>

<p>It turns out that the price of a Vanilla option under this model is just the sum of vanilla options prices under the Bachelier model with shifted forwards (each &ldquo;optionlet&rdquo;
forward corresponds to a peak on the market strike axis). So it is easy and fast to compute. But more importantly, the problem of finding the weights is linear. In deed, the typical
measure to minimize is:
$$ \sum_{i=0}^{n} w_i^2 \left( C_i^M -\sum_{j=1}^m Q_j C_j^B(K_i) \right)^2 $$
where \( w_i \) is a market weight related to the bid-ask spread,  \(  C_i^M \) is the market option price with strike \( K_i \), \( C_j^B(K_i) \) is the j-th Bachelier
optionlet price with strike \( K_i \) and \( Q_j \) is the optionlet weight we want to optimize.</p>

<p>The minimum is located where the gradient is zero.
$$  \sum_{i=0}^{n} 2 w_i^2 C_k^B(K_i)  \left( C_i^M -\sum_{j=1}^m Q_j C_j^B(K_i) \right) = 0 \text{ for } k=1,&hellip;,m $$
It is a linear and can be rewritten in term of matrices as \(A Q = B\) but we have the additional constraints
$$ Q_j \geq 0 $$
$$ \sum_j Q_j = 1 $$</p>

<p>The last constraint can be easily added with a Lagrange multiplier (or manually by elimination). The positivity constraint requires more work. As the problem is convex,
the solution must lie either inside or on a boundary. So we need to explore each case where \(Q_k = 0\) for one or several k in 1,&hellip;m.
In total we have \(2^{m-1}-1\) subsets to explore.</p>

<p><em>How to list all the subsets of \( \{1,&hellip;,m\} \)?</em> It turns out it is very easy by using a <a href="https://www.quora.com/Given-an-array-of-size-n-how-do-you-find-all-the-possible-subsets-of-the-array-of-size-k">bijection of each subset with the binary representation</a> of \( {0,&hellip;,2^m} \). We then just need
to increment a counter for 1 to \( 2^m \) and transform the binary representation to our original set elements. Each element of the subset corresponds to a 1 in the binary representation.</p>

<p>Now this works well if m is not too large as we need to solve \(2^{m-1}-1\) linear systems.
I actually found amazing, it took only a few minutes for m as high as 26 without any particular optimization. For m larger we need to be more clever.
One possibility is to solve the unconstrained problem, and put all the negative quantities to 0  in the result, then solve again this new problem on those boundaries and repeat
until we find a solution. This simple algorithm works often well, but not always. There exists specialized algorithms that are much better and nearly as fast.
Unfortunately I was too lazy to code them. So I improvised on the <a href="http://en.wikipedia.org/Simplex">Simplex</a>. The problem can be transformed into something solvable by the Simplex algorithm.
We maximize the function \( -\sum_j Z_j \) with the constraints
$$ A Q - I Z = B $$
$$ Q_j \geq 0 $$
$$ Z_j \geq 0 $$
where I is the identity matrix. The additonal Z variables are slack variables, just here to help transform the problem. This is a trick I found on a <a href="https://www.researchgate.net/post/How_to_get_the_positive_solution_x_of_a_linear_equation_Axb_if_A_is_a_non-negative_rectangular_matrix">researchgate forum</a>. The two problems
are not fully equivalent, but they are close enough that the Simplex solution is quite good.</p>

<p>With the spline, we minimize directly bid-ask weighted volatilities. With the kernel slice approach, the problem is linear only terms of call prices. We could use a non-linear solver
with a good initial guess. Instead, I prefer to transform the weights so that the optimal solution on weighted prices is similar to the optimal solution on weighted volatilities.
For this, we can just compare the gradients of the two problems:
$$ \sum_{i=0}^{n} 2 {w}_i^2  \frac{\partial C}{\partial \xi}(\xi, K_i)   \left( C_i^M - C(\xi, K_i) \right) $$
with
$$ \sum_{i=0}^{n} 2 {w^\sigma_i}^2\frac{\partial \sigma}{\partial \xi}(\xi, K_i)  \left( \sigma_i^M - \sigma(\xi, K_i)\right) $$
As we know that
$$ \frac{\partial C}{\partial \xi} =  \frac{\partial \sigma}{\partial \xi} \frac{\partial C}{\partial \sigma} $$
we approximate \( \frac{\partial C}{\partial \sigma} \) by the market Black-Scholes Vega and
\( \left( C_i^M - C(\xi, K_i) \right) \) by \( \frac{\partial C}{\partial \xi} (\xi_{opt}-\xi) \),
\( \left( \sigma_i^M - \sigma(\xi, K_i) \right) \) by \( \frac{\partial \sigma}{\partial \xi} (\xi_{opt}-\xi) \)
to obtain
$$ {w}_i \approx \frac{1}{ \frac{\partial C_i^M}{\partial \sigma_i^M} } {w^\sigma_i}  $$</p>

<p>Now it turns out that the kernel slice approach is quite sensitive to the choice of nodes (strikes), but not as much as to the choice of number of nodes. Below is
the same plot as with the spline approach, that is we choose every N market strike as node. For N=4, the density is composed of the sum of m/4 Gaussian densities. We
optimized the kernel bandwidth (here the standard deviation of each Gaussian density), and found that it was relatively insensitive to the number of nodes,
in our case around 33.0 (in general it is expected to be about three times the order the distance between two consecutive strikes, which is 5 to 10 in our case), a smaller value will translate to
narrower peaks.</p>


<figure>
    
        <img src="/post/spw_density_kernel_nodes.png" />
    
    
    <figcaption>
        <h4>probability density of the SPX implied from 1-month SPW options with nodes located at every N market strike, for different values of N. Kernel slice approach.</h4>
        
    </figcaption>
    
</figure>


<p>Even if we consider here more than 37 nodes (m=75 market strikes), the optimal solution actually use only 13 nodes, as all the other nodes have a calibrated weight of 0.
The fit can be much better by adding nodes at
f * 0.5, f * 0.8, f * 0.85, f * 0.9, f * 0.95, f * 0.98, f, f * 1.02, f * 1.05, f * 1.1, f * 1.2, f * 1.5, where f is the forward price, even though the optimal solution
will only use 13 nodes again. We can see this by looking at the implied volatility.</p>


<figure>
    
        <img src="/post/spw_vol_kernel2.png" />
    
    
    <figcaption>
        <h4>implied volatility of the SPX implied from 1-month SPW options with nodes located at every 2 market strike.</h4>
        
    </figcaption>
    
</figure>


<p>Using only the market nodes does not allow to capture right wing of the smile. The density is quite different between the two.</p>


<figure>
    
        <img src="/post/spw_density_kernel2.png" />
    
    
    <figcaption>
        <h4>density of the SPX implied from 1-month SPW options with nodes located at every 2 market strike.</h4>
        
    </figcaption>
    
</figure>


<p>I found (surprisingly) that even those specific nodes by themselves (without any market strike) work better than using all market strikes (without those nodes), but
then we impose where the peaks will be located eventually.</p>

<p>It is interesting to compare the graph with the one before the volatility jump:</p>


<figure>
    
        <img src="/post/spw_density_janfeb_kernel2.png" />
    
    
    <figcaption>
        <h4>density of the SPX implied from 1-month SPW options with nodes located at every 2 market strike.</h4>
        
    </figcaption>
    
</figure>


<p>So in calm markets, the density is much smoother and has really only one main mode/peak.</p>

<p>It is possible to use other kernels than the Gaussian kernel. The problem to solve would be exactly the same. It is not clear what would be the advantages
of another kernel, except, possibly, speed to solve the linear system in O(n) operations for a compact kernel spanning at most 3 nodes (which would translate to a tridiagonal system).</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/spx500_bets_after_rates_hike/">Where is the S&amp;P 500 going to end?</a>
      </h1>
      <span class="post-date">Feb 6, 2018 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/spx500_bets_after_rates_hike/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a>
      </span>
      
      <p>Yesterday the American stocks went a bit crazy along with the VIX that jumped from 17.50 to 38. It&rsquo;s not exactly clear why, the news mention that the Fed might raise its interest rates, the bonds yield have been recently increasing substantially, and the market self-correcting
after stocks grew steadily for months in a low VIX environment.</p>

<p>I don&rsquo;t exactly follow the SPX/SPW options daily. But I had taken a snapshot two weeks ago when the market was quiet. We can imply the probability density from the market option prices.
It&rsquo;s not an exact science. Here I do this with a least-squares spline on the implied volatilities (the least squares smoothes out the noise). I will show another approach in a subsequent post.</p>


<figure>
    
        <img src="/post/spw_density.png" />
    
    
    <figcaption>
        <h4>probability density of the SPX implied from 1-month SPW options.</h4>
        
    </figcaption>
    
</figure>


<p>We can clearly see two bumps and a smaller third one further away in the left tail. This means that the market participants expect the SPX500 to go mostly to 2780 (slightly below where the spx future used to be) one month from now.
Some market participants are more cautious and believe it could hover around 2660. Finally a few pessimists think more of 2530.</p>

<p>Option traders like to look at the implied volatilities (below).</p>


<figure>
    
        <img src="/post/spw_vol.png" />
    
    
    <figcaption>
        <h4>implied volatilities of 1-month SPW options.</h4>
        
    </figcaption>
    
</figure>


<p>On the graph above, it&rsquo;s really not clear that there is some sort of trimodal distribution. There is however an extremely sharp edge, that we normally see only for much shorter maturities. The vols are interpolated with
a cubic spline above, not with a least-squares spline, in order to show the edge more clearly.</p>

<p>This is a bit reminiscent of the Brexit bets where Iain Clark shows <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=3&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwjG3r-RtZLZAhVE1hQKHXrfACAQFghGMAI&amp;url=http%3A%2F%2Fwww.mdpi.com%2F2227-9091%2F5%2F3%2F35%2Fpdf&amp;usg=AOvVaw1aThssEEa8as5Lui41T6Fj">two modes in the probability density of the GBP/USD</a>.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/discrete_sine_transform_fft/">Discrete Sine Transform via the FFT</a>
      </h1>
      <span class="post-date">Feb 5, 2018 &middot; 3 minute read &middot; <a href="https://chasethedevil.github.io/post/discrete_sine_transform_fft/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a><a class="label" href="https://chasethedevil.github.io/categories/math">math</a>
      </span>
      
      <p>Several months ago, I had a quick look at <a href="https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2585529">a recent paper</a> describing how to use
Wavelets to price options under stochastic volatility models with a known characteristic function.
The more classic method is to use some numerical quadrature directly on the Fourier integral as described <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2362968">in this paper</a> for example.
When I read the paper, I was skeptical about the Wavelet approach, since it looked complicated, and with many additional parameters.</p>

<p>I recently took a closer look and it turns out my judgment was bad. The additional parameters can be easily automatically and reliably set
by very simple rules that work well (<a href="https://ssrn.com/abstract=2705699">a subsequent paper</a> by the same author, which applies the method to Bermudan options, clarifies this).
The method is also not as complex as I first imagined. And more importantly, the FFT makes it fast. It is quite amazing to see
the power of the FFT in action. It really is because of the FFT that the Shannon Wavelet method is practical.</p>

<p>Anyway one of the things that need to be computed are the payoff coefficients, and one expression is just the sum of a <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">discrete Cosine transform</a> (DCT) and a discrete Sine transform (DST).
I was wondering then
about a simple way to use the FFT for the Sine transform. There are many papers around how to use the FFT to compute the Cosine transform. A technique
that is efficient and simple is the one of <a href="https://www.google.fr/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwirtpu5upHZAhUFOBQKHZnHBFoQFgg2MAA&amp;url=http%3A%2F%2Feelinux.ee.usm.maine.edu%2Fcourses%2Fele486%2Fdocs%2Fmakhoul.fastDCT.pdf&amp;usg=AOvVaw0b3sdSzaT-A9fRAGWZbUcP">Makhoul</a>.</p>

<p>The coefficients that need to be computed for all k can be represented by the following equation
$$  V_{k} = \sum_{j=0}^{N-1} a_j \cos\left(\pi k\frac{j+\frac{1}{2}}{N}\right) + b_j \sin\left(\pi k\frac{j+\frac{1}{2}}{N}\right) $$
with \( N= 2^{\bar{J}-1} \) for some positive integer \( \bar{J} \).
Makhoul algorithm to compute the DCT of size N with one FFT of size N consists in</p>

<ul>
<li>initialize the FFT coefficients \(c_j\) with:
$$  c_j = a_{2j} \quad\,,\quad    c_{N-1-j} = a_{2j+1} \quad \text{ for } j = 0,&hellip;, \frac{N}{2}-1 $$</li>
<li>and then from the result of the FFT \( hat{c} \), the DCT coefficients \( \hat{a} \) are
$$ \hat{a}_k = \Re\left[ \hat{c}_j e^{-i \pi\frac{k}{2N}} \right]\,. $$</li>
</ul>

<p>Makhoul does not specify the equivalent formula for the DST, but we can do something similar.</p>

<ul>
<li>We first initialize the FFT coefficients \( c_j \) with:
$$ c_j = b_{2j} \quad\,,\quad c_{N-1-j} = -b_{2j+1} \quad \text{ for } j = 0,&hellip;, \frac{N}{2}-1 $$</li>
<li>and then from the result of the FFT \(\hat{c}\), the DST coefficients \(\hat{b}\) are
$$\hat{b}_k = -\Im\left[ \hat{c}_j e^{-i \pi\frac{k}{2N}} \right]\,. $$</li>
</ul>

<p>For maximum performance, the two FFTs can reuse the same sine and cosine tables. And the last step of the DCT and DST can be combined together.</p>

<p>Another approach would be to compute a single FFT of size 2N as we can rewrite the coefficients as
$$  V_{k} = \Re\left[e^{-i \pi \frac{k}{2N}} \sum_{j=0}^{2N-1} (a_j + i b_j) e^{-2i\pi k\frac{j}{2N}} \right] $$
with \(a_j = b_j =0 \) for \( j \geq N \)</p>

<p>In fact the two are almost equivalent, since a FFT of size 2N is <a href="https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm">decomposed</a> internally into two FFTs of size N.</p>

<p>With this in mind we can improve a bit the above to merge the two transforms together:</p>

<ul>
<li>We first initialize the FFT coefficients \( c_j \) with:
$$ c_j = a_{2j} + i b_{2j} \quad\,,\quad c_{N-1-j} = a_{2j+1} -i b_{2j+1} \quad \text{ for } j = 0,&hellip;, \frac{N}{2}-1 $$</li>
<li>and then from the result of the FFT \(\hat{c}\), the coefficients are
$$V_k = \Re\left[ \hat{c}_j e^{-i \pi\frac{k}{2N}} \right]\,. $$</li>
</ul>

<p>And we have computed the coefficients with a single FFT of size N.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/quantitative_finance_books/">Quantitative Finance Books Citing My Papers</a>
      </h1>
      <span class="post-date">Dec 9, 2017 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/quantitative_finance_books/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a>
      </span>
      
      <p>I would have never really expected that when I started writing papers, but little by little there is a growing list of books citing <a href="https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1514784">my papers</a>:</p>

<ul>
<li><a href="https://www.amazon.com/Applied-Quantitative-Finance-Equity-Derivatives/dp/1977557872/ref=sr_1_1?ie=UTF8&amp;qid=1512751819&amp;sr=8-1&amp;keywords=jherek+healy">Applied Quantitative Finance for Equity Derivatives</a> by <a href="https://jherekhealy.github.io">Jherek Healy</a>: the most recent book on equity derivatives refers to several of my papers. In contrast with many other books, the author goes beyond and provides additional insights on the papers.</li>
<li><a href="https://www.amazon.com/Interest-Rate-Derivatives-Explained-Engineering/dp/1137360186/ref=sr_1_1?ie=UTF8&amp;qid=1512825081&amp;sr=8-1&amp;keywords=Interest+Rate+Derivatives+Explained%3A+Volume+2%3A+Term+Structure+and+Volatility+Modelling">Interest Rate Derivatives Explained: Volume 2: Term Structure and Volatility Modelling</a> by Jörg Kienitz and Peter Casper. It refers to the paper &ldquo;finite difference techniques for arbitrage-free SABR&rdquo;, written in collaboration with Gary Kennedy.</li>
<li><a href="https://www.amazon.com/Interest-Rate-Derivatives-Explained-Engineering/dp/1137360062/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1512824387&amp;sr=1-1">Interest Rate Derivatives Explained: Volume 1: Products and Markets</a> by Jörg Kienitz. It refers to my paper on curve interpolation (there is a mistake in the actual reference given inside the book,about arbitrage-free SABR, which unrelated to the text). I like how this book gives real world market data related to the products considered.</li>
<li><a href="https://www.amazon.com/Interest-Rate-Modelling-Multi-Curve-Framework/dp/1137374659/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1512825258&amp;sr=1-1&amp;keywords=henrard+interest">Interest Rate Modelling in the Multi-Curve Framework: Foundations, Evolution and Implementation</a> by <a href="http://multi-curve-framework.blogspot.fr/">Marc Henrard</a>. It refers to the paper about yield curve interpolation. This is one of the rare books to present curve construction in depth.</li>
</ul>

<p>There are also some Springer books which are typically a collection of papers on a specific subject (which I find less interesting).</p>

<ul>
<li><a href="https://www.amazon.com/Methods-Computational-Finance-Mathematics-Industry/dp/3319612816/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1512825785&amp;sr=1-1&amp;keywords=Novel+Methods+in+Computational+Finance">Novel Methods in Computational Finance</a>. Jörg Kienitz refers to my paper on arbitrage free SABR in chapter 4.</li>
<li><a href="https://www.amazon.com/Innovations-Derivatives-Markets-Adjustments-Proceedings/dp/331933445X/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1512825510&amp;sr=1-1&amp;keywords=Innovations+in+Derivatives+Markets">Innovations in Derivatives Markets: Fixed Income Modeling, Valuation Adjustments, Risk Management, and Regulation</a>. Christian Fries refers to my paper on curve interpolation in chapter 10.</li>
</ul>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/google_phones_are_overrated/">Google phones are overrated</a>
      </h1>
      <span class="post-date">Oct 2, 2017 &middot; 3 minute read &middot; <a href="https://chasethedevil.github.io/post/google_phones_are_overrated/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/hardware">hardware</a>
      </span>
      
      <p>It is a relatively common belief that the vanilla Android experience is better, as it runs smoother. The Samsung Touchwiz is often blamed for making things slow and not more practical.</p>

<p>I have had a Nexus 6 for a couple of years and I noticed the slowdowns after each update, up to a point where it sometimes took a few seconds to open the phone app, or to display the keyboard. I freed up storage, removed some apps but this did not make any difference. This is more or less the same experience that people have with the Samsung devices if <a href="https://www.reddit.com/r/Android/comments/73necm/with_the_note_8_samsung_no_longer_delivers/">reddit comments</a> are to be believed.</p>

<p>The other myth is that Google phones will be updated for a longer time. Prior to the Nexus 6, I had a Galaxy Nexus, which Google stopped supporting after less than 2 years. The Nexus 6 received security update until this October, that is nearly 2 years for me and 2.5 years for early buyers.</p>

<p>In comparison Apple updates its phones for much longer and a 4 years old iphone 5s still runs smoothly. Fortunately for Android phones, there are the alternative roms. Being desperate with the state of my Nexus phone, I installed <a href="http://get.aospa.co/">paranoid android</a>. I am surprised at how good it is. My phone feels like new again, and as good as any flagship I would purchase today. To my great surprise I did not find any clear step by step installation process for Paranoid Android. I just followed the <a href="https://wiki.lineageos.org/devices/shamu/install">detailed steps for LineageOS</a> (CyanogenMod descendent), but with the paranoid android zip file instead of the LineageOS one. I have some trouble to understand how some open source ROM can be much nicer than the pure Google Android ROM, but it is. I have had no crash/reboot (which became more common as well with the years), plus it&rsquo;s still updated regularly. Google does not set a good standard by not supporting its own devices better.</p>

<p>There is however one thing that Google does well, it&rsquo;s the camera app. The HDR+ mode makes my Nexus 6 take great pictures, even compared to new android phones or iphones. I am often amazed at the pictures I manage to take, and others are also amazed at how good they look (especially since they look often better on the Nexus 6 screen than on a computer monitor). Initially I remember the camera to be not so great, but some update that came in 2016 transformed the phone into a fantastic shooter. It allowed me to take very nice pictures in difficult conditions, see for example <a href="https://photos.app.goo.gl/s2IHVtKMzRkxDY1q1">this google photo gallery</a>. Fortunately it&rsquo;s still possible to install the app in the Google Play store on Paranoid Android. They should really make it open-source and easier to adapt it to other android phones.</p>


<figure>
    <a href="https://photos.google.com/share/AF1QipOGPpDIYCAYJ_636MtjEGWQHj6da0EukBqwoAGMYvuMoWGGJ8EjCx4ADVNffqulPA?key=YjF4VnRGRGlqNlgtbS1Cb0U0WFo3djl5NEdUSk5R&amp;source=ctrlq.org">
        <img src="https://lh3.googleusercontent.com/JjEGDeF4uiw1FPFVVDotOPNeN-GPr_5s8-n0ud7Ioio8GvegtJqJ_C6AinmV0plNBnEINZEVr6LZvHb7I68HbGaZcTRUlldsxHoXZVGSLJAYZHqEM94JnDINlVVEWSOvP39Qwj4dWw" />
    </a>
    
    <figcaption>
        <h4>A photo made with the Google camera app on the Nexus 6.</h4>
        
    </figcaption>
    
</figure>


      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/svn_is_dead/">SVN is dead</a>
      </h1>
      <span class="post-date">Sep 26, 2017 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/svn_is_dead/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/programming">programming</a>
      </span>
      
      <p>A few years ago, when <a href="https://git-scm.com/">Git</a> was rising fast and <a href="https://subversion.apache.org/">SVN</a> was already not hype anymore, a friend thought that SVN was for many organizations better suited than Git, with the following classical arguments, which were sound at the time:</p>

<ol>
<li>Who needs decentralization for a small team or a small company working together?</li>
<li>‎SVN is proven, works well and is simple to use and put in place.</li>
</ol>

<p>Each argument is in reality not so strong. It becomes clear now that Git is much more established.</p>

<p>Regarding the first argument, a long time ago some people had trouble with CVS as it introduced the idea of merging instead of locking files. Git represents a similar paradigm shift between the centralized and the decentralized. It can scare people in not so rational ways. You could lock files with CVS as you did with visual sourcesafe or any other crappy old source control system. It&rsquo;s just that people favored merges as it was effectively more convenient and more productive. You can also use Git with a centralized workflow. Another more scary paradigm shift with Git is to move away from the idea that branches are separate folders. With Git you just switch branches as it is instantaneous even though, again, you could use it in the old fashioned SVN way.</p>

<p>Now onto the second argument, SVN is proven to work well. But so is Cobol. Today it should be clear that SVN is essentially dead. Most big projects move or have moved to git. Tools work better with Git, even <a href="https://www.eclipse.org/">Eclipse</a> works natively with Git but requires buggy plugins for SVN. New developers don&rsquo;t know SVN.</p>

<p>I heard other much worse arguments against Git since. For example, some people believed that, with Git, they could lose some of their code changes. This was partially due to sensational news article such as the <a href="https://www.theregister.co.uk/2017/02/01/gitlab_data_loss/">Gitlab.com data loss</a>, where in reality some administrator deleted some directory and had non-working backups. As a result, some Git repositories were deleted, but in reality it&rsquo;s a common data loss situation, unrelated to the use of Git as version control system. This Stackoverflow question gives a nice overview of <a href="https://stackoverflow.com/questions/21048765/what-can-cause-data-loss-in-git">data loss risks with Git</a>.</p>

<p>What I feel is true however is that Git is more complex than SVN, because it is more powerful and more flexible. But if you adopt a simple workflow, it&rsquo;s not necessarily more complicated.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/the_neural_network_in_your_cpu/">The Neural Network in Your CPU</a>
      </h1>
      <span class="post-date">Aug 6, 2017 &middot; 3 minute read &middot; <a href="https://chasethedevil.github.io/post/the_neural_network_in_your_cpu/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/programming">programming</a>
      </span>
      
      <p>Machine learning and artificial intelligence are the current hype (again). In their new Ryzen processors, <a href="http://www.anandtech.com/Gallery/Album/5197#18">AMD advertises the Neural Net Prediction</a>. It turns out this is was already used in their older (2012) Piledriver architecture used for example in the <a href="http://www.anandtech.com/show/5831/amd-trinity-review-a10-4600m-a-new-hope">AMD A10-4600M</a>. It is also present in recent Samsung processors such as <a href="https://www.theregister.co.uk/2016/08/22/samsung_m1_core/">the one powering the Galaxy S7</a>. What is it really?</p>

<p>The basic idea can be traced to a paper from Daniel Jimenez and Calvin Lin <a href="https://www.cs.utexas.edu/~lin/papers/hpca01.pdf">&ldquo;Dynamic Branch Prediction with Perceptrons&rdquo;</a>, more precisely described in the subsequent paper <a href="http://taco.cse.tamu.edu/pdfs/tocs02.pdf">&ldquo;Neural methods for dynamic branch prediction&rdquo;</a>. Branches typically occur  in <code>if-then-else</code> statements. <a href="https://en.wikipedia.org/wiki/Branch_predictor">Branch prediction</a> consists in guessing which code branch, the <code>then</code> or the <code>else</code>, the code will execute, thus allowing to precompute the branch in parallel for faster evaluation.</p>

<p>Jimenez and Lin rely on a simple single-layer perceptron neural network whose input are the branch outcome (global or hybrid local and global) histories and the output predicts which branch will be taken. In reality, because there is a single layer, the output y is simply a weighted average of the input (x, and the constant 1):</p>

<p>$$ y = w_0 + \sum_{i=1}^n x_i w_i $$</p>

<p>\( x_i = \pm 1 \) for a taken or not taken. \( y &gt; 0 \) predicts to take the branch.</p>

<p>Ideally, each static branch is allocated its own perceptron. In practice, a hash of the branch address is used.</p>

<p>The training consists in updating each weight according to the actual branch outcome t : \( w_i = w_i + 1 \) if \( x_i = t \) otherwise \( w_i = w_i - 1 \). But this is done only if the predicted outcome is lower than the training (stopping) threshold or if the branch was mispredicted. The threshold keeps from overtraining and allow to adapt quickly to changing behavior.</p>

<p>The perceptron is one of those algorithms created by a psychologist. In this case, the culprit is Frank Rosenblatt. Another more recent algorithm created by a psychologist is the <a href="https://en.wikipedia.org/wiki/Particle_swarm_optimization">particle swarm optimization</a> from James Kennedy. As <a href="https://quantsrus.github.io/post/particle_swarm_optimization/">in the case of</a> particle swarm optimization, there is not a single well defined perceptron, but many variations around some key principles. A reference seems to be the perceptron from H.D. Block, probably because he describes the perceptron in terms closer to code, while Rosenblatt was really describing a perceptron machine.</p>

<p>The perceptron from H.D. Block is slightly more general than the perceptron used for branch prediction:</p>

<ul>
<li>the output can be -1, 0 or 1. The output is zero if the weighted average is below a threshold (a different constant from the training threshold of the branch prediction perceptron).</li>
<li>reinforcement is not done on inactive connections, that is for \( x_i = 0 \).</li>
<li>a learning rate \( \alpha \) is used to update the weight: \( w_i += \alpha t x_i \)</li>
</ul>

<p>The perceptron used for branch prediction is quite different from the deep learning neural networks fad, which have many more layers, with some feedback loop. The challenge of those is the training: when many layers are added to the perceptron, the gradients of each layer activation function multiply in the backpropagation algorithm. This makes the &ldquo;effective&rdquo; gradient at the first layers to be very small, which translates to tiny changes in the weights, making training not only very slow but also likely stuck in a sub-optimal local minimum. Beside the <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">vanishing gradient</a> problem, there is also the <a href="https://en.wikipedia.org/wiki/Catastrophic_interference">catastrophic interference</a> problem to pay attention to. Those issues are today dealt with the use of <a href="http://neuralnetworksanddeeplearning.com/chap6.html">specific strategies to train / structure the network</a> combined with raw computational power that was unavailable in the 90s.</p>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/benham_disc_in_web_canvas/">Benham disc in web canvas</a>
      </h1>
      <span class="post-date">Jul 10, 2017 &middot; 3 minute read &middot; <a href="https://chasethedevil.github.io/post/benham_disc_in_web_canvas/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a>
      </span>
      
      <p>Around 15 years ago, I wrote a small Java applet to try and show the <a href="https://en.wikipedia.org/wiki/Benham%27s_top">Benham disk</a> effect. Even back then applets were already passé and Flash would have been more appropriate. These days, no browser support Java applets anymore, and very few web users have Java installed. Flash also mostly disappeared. The <a href="https://www.w3schools.com/html/html5_canvas.asp">web canvas</a> is today&rsquo;s standard allowing to embbed animations in a web page.</p>

<p>This effect shows color perception from a succession of black and white pictures. It is a computer reproduction from the Benham disc with ideas borrowed from &ldquo;Pour La Science Avril/Juin 2003&rdquo;.
Using a delay between 40 and 60ms, the inner circle should appear <font color="#770000">red</font>, the one in the middle
<font color="#000077">blue</font> and the outer one <font color="#007700">green</font>. When you reverse the rotation direction,
blue and red circles should be inverted.</p>

<form>
  Delay: <input type="number" name="delay" value="60" id="delayInput"> Reverse <input type="checkbox" value="false" id="reverseInput" onclick="javascript:reverse()"> <input type="button" value="Start" onclick="javascript:startStop()" id="startButton">
</form>

<canvas id="myCanvas" width="480" height="480" style="border:1px solid #000000;">
</canvas> 

<script type="text/javascript">
var c = document.getElementById("myCanvas");
  c.style.width ='100%';
  c.style.height='100%';
  // ...then set the internal size to match
  c.width  = c.offsetWidth;
  c.height = c.offsetWidth;
var x=c.width/2;
var y=x;
linewidth = c.width / 100;
var g = c.getContext("2d");

function paintImage(g, x,y,startArcAngle) {
var radius = 0.9;
var r = radius*x; endAngle = 2*Math.PI/3+startArcAngle;
g.beginPath();
g.arc(x, y, r, Math.PI/3+startArcAngle, endAngle, false);
g.lineWidth = linewidth;
g.strokeStyle = "black";
g.stroke();

radius = 0.8; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, Math.PI/3+startArcAngle, endAngle, false);
g.stroke();

radius = 0.7; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, Math.PI/3+startArcAngle, endAngle, false);
g.stroke();

radius = 0.6; r = radius*x; endAngle = Math.PI/3+startArcAngle;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.5; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.4; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1, 0+startArcAngle, endAngle, false);
g.stroke();

//  paintImage(g, startArcAngle, 60, 0.3); //red -180 to -60
radius = 0.3; r = radius*x; endAngle = Math.PI+startArcAngle;// if (endAngle > Math.PI*2) endAngle = endAngle - 2*Math.PI 
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();
        
radius = 0.2; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();

radius = 0.1; r = radius*x;
g.beginPath();
g.arc(x, y, r + 1,  2*Math.PI/3+startArcAngle, endAngle, false); 
g.stroke();

g.beginPath();
g.arc(x, y, x,  Math.PI+startArcAngle, Math.PI*2+startArcAngle, false); 
g.fill();
}

var delay = 40;
var currentAnimate = 0;
var animationStartTime = window.performance.now();
var currentIndex = 3;
var angles = [0.0, 2*Math.PI/3, 4*Math.PI/3];

var offscreenCanvas = [document.createElement('canvas'),document.createElement('canvas'),document.createElement('canvas')];
for (var i in offscreenCanvas) {
  offscreenCanvas[i].width = c.offsetWidth;
  offscreenCanvas[i].height = c.offsetWidth;
  g = offscreenCanvas[i].getContext("2d");
  paintImage(g, x, y, angles[i]);
}
g = c.getContext("2d");

//function animate0() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y,  0.0);
//  currentAnimate = setTimeout(animate1, delay);
//}
//function animate1() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y,  2*Math.PI/3);
//  currentAnimate = setTimeout(animate2, delay);
//}
//function animate2() {
//  g.clearRect(0,0,c.width, c.height);
//  paintImage(g,x, y, 4*Math.PI/3);
//  currentAnimate= setTimeout(animate0, delay);
//}

window.requestAnimationFrame = window.requestAnimationFrame || window.mozRequestAnimationFrame ||
                              window.webkitRequestAnimationFrame || window.msRequestAnimationFrame;


function animateContinuous(time) {
  var index = Math.floor(((time - animationStartTime) % (3*delay))/delay);
  if (index < 0) index = 0
  if (index != currentIndex) {
    //g.clearRect(0,0,c.width, c.height);
    //paintImage(g, x, y, angles[index]);
    var offscreenContext = offscreenCanvas[index].getContext('2d');
    var image = offscreenContext.getImageData(0,0,c.width,c.height); 
    g.putImageData(image, 0, 0);       
    currentIndex = index;
  }
  currentAnimate = requestAnimationFrame(animateContinuous);
}

function reverse() {
  //tmp = angles[2]; angles[2] = angles[0]; angles[0] = tmp;
  tmp = offscreenCanvas[2]; offscreenCanvas[2] = offscreenCanvas[0]; offscreenCanvas[0] = tmp;
}

function startStop() {
  var elem = document.getElementById("startButton");
  var delayElem = document.getElementById("delayInput");
 if (elem.value=="Stop") {
    elem.value = "Start";
    //clearTimeout(currentAnimate);
    window.cancelAnimationFrame(currentAnimate);
    currentAnimate = 0;
  } else {
    elem.value = "Stop";
    delay = delayElem.value;
    animationStartTime = window.performance.now();
    //animate0();
    currentAnimate = requestAnimationFrame(animateContinuous);
  }
}
</script>

      
    </div>
    
    <div class="post">
      <h1 class="post-title">
        <a href="https://chasethedevil.github.io/post/quantitative_finance_blogs/">Blogs on Quantitative Finance</a>
      </h1>
      <span class="post-date">Jun 21, 2017 &middot; 2 minute read &middot; <a href="https://chasethedevil.github.io/post/quantitative_finance_blogs/#disqus_thread">Comments</a>
      
      <br/>
      <a class="label" href="https://chasethedevil.github.io/categories/quant">quant</a>
      </span>
      
      <p>There are not many blogs on quantitative finance that I read. Blogs are not so popular anymore with the advent of the various social networks (facebook, stackoverflow, google plus, reddit, &hellip;). Here is a small list:</p>

<ul>
<li><a href="https://www.clarusft.com/blog/">Clarus FT</a>: often interesting statistics on the swap market, clearing, plus the <a href="https://www.clarusft.com/author/gary/">more technical articles from Gary</a>.</li>
<li><a href="https://quantsrus.github.io/">Quants R Us</a>: A relatively new blog with a promising starting post analyzing <a href="https://quantsrus.github.io/post/andreasen_huge_spline/">Andreasen-Huge one-step local-volatility algorithm with a Spline</a></li>
<li><a href="https://quantlib.wordpress.com/author/petercaspers/">Fooling around with Quantlib</a>: the blog from Peter Caspers, also relevant  to non-Quantlib professionals has original insights such as <a href="https://quantlib.wordpress.com/2015/09/19/smile-dynamics-by-densities/">Smile dynamics by densities</a> or the <a href="https://quantlib.wordpress.com/2015/08/23/supernatural-libor-coupons/">Supernatural Libor Coupons</a>. Unfortunately it is not so active anymore.</li>
<li><a href="http://www.implementingquantlib.com">Implementing Quantlib</a>: the blog from Luigi Ballabio, which explains many of the design decisions in Quantlib. Very interesting for developer of financial libraries, see for example <a href="http://www.implementingquantlib.com/2017/04/fd-solvers.html">the fd solvers</a>.</li>
<li><a href="https://hpcquantlib.wordpress.com/">HPC Quantlib</a> from Klaus Spanderen. Yes lots of quantlib blogs, but this one is actually not much focused on quantlib. It goes into great details about some numerical techniques, see for example the <a href="https://hpcquantlib.wordpress.com/2017/05/07/newer-semi-analytic-heston-pricing-algorithms/">analysis of Heston pricing algorithm</a></li>
<li><a href="http://oxfordstrat.com/rd-blog/">Oxford Strat</a>. It is a different kind of subject: too many trading strategies but some interesting data, for example <a href="http://oxfordstrat.com/data/global-market-correlations/">global market correlations</a> and <a href="http://oxfordstrat.com/ideas/sharpe-ratio/">ideas</a>.</li>
<li><a href="https://forum.wilmott.com/">Wilmott forums</a> not a blog, but it sometimes (not often) has interesting discussions and can be a good way to connect.</li>
</ul>

<p>Another way to find out what&rsquo;s going on in the quantitative finance world is to scan regularly recent papers on <a href="https://arxiv.org/list/q-fin/recent">arxiv</a>, <a href="http://www.ssrn.com">SSRN</a> or the suggestions of <a href="http://scholar.google.com">Google scholar</a>.</p>

      
    </div>
    
    

<ul class="pagination">
    
    <li>
        <a href="/" aria-label="First"><span aria-hidden="true">&laquo;&laquo;</span></a>
    </li>
    
    <li
    class="disabled">
    <a href="" aria-label="Previous"><span aria-hidden="true">&laquo;</span></a>
    </li>
    
    
    
    
    
    
        
        
    
    
    <li
    class="active"><a href="/">1</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/2/">2</a></li>
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/3/">3</a></li>
    
    
    
    
    
    
        
        
    
    
    <li class="disabled"><span aria-hidden="true">&hellip;</span></li>
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    
    
    
    
    
        
        
    
    
    <li
    ><a href="/page/38/">38</a></li>
    
    
    <li
    >
    <a href="/page/2/" aria-label="Next"><span aria-hidden="true">&raquo;</span></a>
    </li>
    
    <li>
        <a href="/page/38/" aria-label="Last"><span aria-hidden="true">&raquo;&raquo;</span></a>
    </li>
    
</ul>

  </div>
</div>


<script type="text/javascript">
var disqus_shortname = "chasethedevil";
(function () {
    var s = document.createElement('script'); s.async = true;
    s.type = 'text/javascript';
    s.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
}());
</script>

<div class="content container" style="padding-top: 0rem;"-->
 <a href="https://twitter.com/share" class="twitter-share-button"{count} data-hashtags="chasethedevil" data-size="large">Tweet</a>
 <a style="font-size:75%;" href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent(window.location); return false"><i class="fa fa-reddit fa-2x" aria-hidden="true"></i>Submit to reddit</a> 
<table style="border-collapse: collapse;">
     <tr style="padding: 0px; margin: 0px; border: none;">
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">&copy; 2006-16 <a href="http://chasethedevil.github.io/about/">Fabien</a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 0px;"><a rel="license" href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative Commons License" style="padding: 0px; margin: 0px; border: none;" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /></a></td>
     <td style="vertical-align: middle;padding: 0px; margin: 0px; border: none;font-size: 60%;">This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</td></tr></table>
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
</div>

</body>
</html>

