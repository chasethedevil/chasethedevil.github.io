<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>math on Chase the Devil</title>
    <link>https://chasethedevil.github.io/categories/math/</link>
    <description>Recent content in math on Chase the Devil</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright 2006-2018 Fabien Le Floc&#39;h. This work is licensed under a Creative Commons Attribution 4.0 International License.</copyright>
    <lastBuildDate>Sat, 09 Apr 2022 21:56:42 +0100</lastBuildDate><atom:link href="https://chasethedevil.github.io/categories/math/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Monte-Carlo Parallelization: to vectorize or not?</title>
      <link>https://chasethedevil.github.io/post/monte-carlo-vectorization-or-not/</link>
      <pubDate>Sat, 09 Apr 2022 21:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/monte-carlo-vectorization-or-not/</guid>
      <description>When writing a Monte-Carlo simulation to price financial derivative contracts, the most straightforward is to code a loop over the number of paths, in which each path is fully calculated. Inside the loop, a payoff function takes this path to compute the present value of the contract on the given path. The present values are recorded to lead to the Monte-Carlo statistics (mean, standard deviation). I ignore here any eventual callability of the payoff which may still be addressed with some work-arounds in this setup.</description>
    </item>
    
    <item>
      <title>More Automatic Differentiation Awkwardness</title>
      <link>https://chasethedevil.github.io/post/more-automatic-differentiation-awkwardness/</link>
      <pubDate>Tue, 04 Jan 2022 21:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/more-automatic-differentiation-awkwardness/</guid>
      <description>This blog post from Jherek Healy presents some not so obvious behavior of automatic differentiation, when a function is decomposed into the product of two parts where one part goes to infinity and the other to zero, and we know the overall result must go to zero (or to some other specific number). This decomposition may be relatively simple to handle for the value of the function, but becomes far less trivial to think of in advance, at the derivative level.</description>
    </item>
    
    <item>
      <title>Quadprog in Julia</title>
      <link>https://chasethedevil.github.io/post/quadprog-in-julia/</link>
      <pubDate>Sun, 21 Nov 2021 13:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/quadprog-in-julia/</guid>
      <description>As described on wikipedia, a quadratic programming problem with n variables and m constraints is of the form $$ \min(-d^T x + 1/2 x^T D x) $$ with the constraints \( A^T x \geq b_0 \), were \(D\) is a \(n \times n\)-dimensional real symmetric matrix, \(A\) is a \(n \times m\)-dimensional real matrix, \( b_0 \) is a \(m\)-dimensional vector of constraints, \( d \) is a \(n\)-dimensional vector, and the variable \(x\) is a \(n\)-dimensional vector.</description>
    </item>
    
    <item>
      <title>Bad papers and the roots of high degree polynomials</title>
      <link>https://chasethedevil.github.io/post/bad-papers-polynomial-roots/</link>
      <pubDate>Sat, 07 Nov 2020 07:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/bad-papers-polynomial-roots/</guid>
      <description>I was wondering what were exactly the eigenvalues of the Mersenne-Twister random number generator transition matrix. An article by K. Savvidy sparked my interest on this. This article mentioned a poor entropy (sum of log of eigenvalues amplitudes which are greater than 1), with eigenvalues falling almost on the unit circle.
The eigenvalues are also the roots of the characteristic polynomial. It turns out, that for jumping ahead in the random number sequence, we use the characteristic polynomial.</description>
    </item>
    
    <item>
      <title>42</title>
      <link>https://chasethedevil.github.io/post/42/</link>
      <pubDate>Thu, 05 Dec 2019 20:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/42/</guid>
      <description>Today my 6-years old son came with a math homework. The stated goal was to learn the different ways to make 10 out of smaller numbers. I was impressed. Immediately, I wondered
 how many ways are there to make 10 out of smaller numbers?
 This is one of the beauties of maths: a very simple problem, which a 6-years old can understand, may actually be quite fundamental. If you want to solve this in the general case, for any number instead of 10, you end up with the partition function.</description>
    </item>
    
    <item>
      <title>Discrete Sine Transform via the FFT</title>
      <link>https://chasethedevil.github.io/post/discrete_sine_transform_fft/</link>
      <pubDate>Mon, 05 Feb 2018 13:56:42 +0100</pubDate>
      
      <guid>https://chasethedevil.github.io/post/discrete_sine_transform_fft/</guid>
      <description>Several months ago, I had a quick look at a recent paper describing how to use Wavelets to price options under stochastic volatility models with a known characteristic function. The more classic method is to use some numerical quadrature directly on the Fourier integral as described in this paper for example. When I read the paper, I was skeptical about the Wavelet approach, since it looked complicated, and with many additional parameters.</description>
    </item>
    
  </channel>
</rss>
